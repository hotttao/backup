---
title: 1.4 消费者客户端
date: 2020-04-03
categories:
    - 存储
tags:
    - Kafka
---
Kafka 的生产者客户端

<!-- more -->
## 1. 消费者客户端概述
接下来我们将介绍 kafka 消费者客户端，内容包括:
1. 消费者与消费者组
2. 消费者客户端开发，包括
    - 主题订阅
    - 反序列化
    - 消费者拦截器
    - 消息消费和消息确认
    - 再均衡

与生产者客户端一样，消费者客户端也分成两个版本，我们只介绍新版本，并依旧使用 Python 语言来编写示例代码。

## 2. 消费者与消费者组
kafka 通过消费者组（Consumer Group）来同时实现消息传递的两种模式: 负载均衡和扇出。当消息发布到主题后，只会被投递给订阅它的**每个消费组**中的**一个消费者**。消费者组中的每个消费者只能消费所分配到的分区中的消息。换言之，每一个分区只能被一个消费组中的一个消费者所消费。通过消费者客户端参数**partition.assignment.strategy**可以来设置消费者与订阅主题之间的分区分配策略，分区分配策略的细节我们之后在深入学习 kafka 相关原理时会详细讲解。

消费者组是一个逻辑上的概念，每一个消费者只隶属于一个消费组。每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，通过消费者客户端参数**group.id**来配置，默认值为空字符串。

## 2. 消费者客户端开发
一个正常的消费逻辑需要具备以下几个步骤：
1. 配置消费者客户端参数及创建相应的消费者实例。
2. 订阅主题
3. 拉取消息并消费
4. 消息确认，即提交消费位移
5. 关闭消费者实例

```python
from confluent_kafka import Consumer

conf = {'bootstrap.servers': "host1:9092,host2:9092",
        'group.id': "foo",
        'auto.offset.reset': 'smallest'}

consumer = Consumer(conf)

running = True

def basic_consume_loop(consumer, topics):
    try:
        # 订阅主题，一个或多个
        consumer.subscribe(topics)

        while running:
            msg = consumer.poll(timeout=1.0)
            if msg is None: continue

            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    # End of partition event
                    sys.stderr.write('%% %s [%d] reached end at offset %d\n' %
                                     (msg.topic(), msg.partition(), msg.offset()))
                elif msg.error():
                    raise KafkaException(msg.error())
            else:
                msg_process(msg)
    finally:
        # Close down consumer to commit final offsets.
        consumer.close()

def shutdown():
    running = False
```

### 2.1 必要的连接参数
Kafka消费者客户端有四个参数是必填的
1. bootstrap.servers：
    - 作用: 该参数用来指定生产者客户端连接Kafka集群所需的broker地址清单
    - 默认: 默认值为 ""
    - 格式: 具体的内容格式为host1：port1，host2：port2
    - 说明: 不需要指定所有的broker地址，因为消费者会从给定的broker里查找到其他broker的信息
2. group.id:
    - 作用: 消费者隶属的消费者组名称
    - 默认: 默认值为 ""，设置为空，则会报出异常
    - 说明: 需要设置成具有一定的业务意义的名称
3. key.deserializer: 指定键的反序列化器
4. value.deserializer: 指定值的反序列化器
5. client.id:
    - 作用: 设定KafkaConsumer对应的客户端id
    - 默认: 默认值为 ""，非必须参数
    - 说明: 客户端不设置，则KafkaConsumer会自动生成一个非空字符串，内容形式如“consumer-1”

Python kafka 客户端实现与 Java 略有不同，自定义反序列化器是通过Producer子类实现的，还有一些使用特殊序列化协议的序列化/反序列化器。

### 2.2 订阅主题和分区
`consumer.subscribe(topics[, on_assign=None][, on_revoke=None])`
- 作用: 主题订阅
- topics: 
    - 指定订阅的主题，一个或多个
    - 如果前后两次订阅了不同的主题，以最后一次的为准
    - 正则表达式的主题名称需要以 "^" 开头
    - 如果在订阅主题之后，又有人创建了新的主题，并且与正则表达式的主题匹配，消费者可以消费到新添加的主题中的消息
    - 在Kafka 和其他系统之间进行数据复制时，这种正则表达式的方式就显得很常见
- on_assign:
    - 可调用函数，用于在 partition re-assignment 成功后提供自定义偏移量
- on_revoke: 
    - 可调用函数，用于在再均衡开始前，提供对偏移量的处理，并提交至服务端

```Python
# 1. 正则表达式的主题名称
consumer.subscribe(["^my_topic.*", "^another[0-9]-?[a-z]+$", "not_a_regex"])
```

`consumer.assign(partitions)`
- 作用: 直接订阅主题的分区
- partitions: TopicPartition 的 List 指定需要订阅的分区集合

`TopicPartition(topic [, partition][, offset])`
- 作用: 保存主题单个分区的类
- topic: 所属主题
- partition: 分区ID
- offset: 初始分区偏移量

`consumer.assignment()`
- 作用: 返回主题的分区元数据，类型为 TopicPartition 的 List

`consumer.unsubscribe()`
- 作用: 删除当前订阅

subscribe(topics)、正则表达式订阅的方式subscribe(Pattern)和指定分区的订阅方式 assign(TopicPartition)分表代表了三种不同的订阅状态：AUTO_TOPICS、AUTO_PATTERN和USER_ASSIGNED。这三种状态是互斥的，在一个消费者中只能使用其中的一种，否则会报错。

通过 subscribe（）方法订阅主题具有消费者自动再均衡的功能，在多个消费者的情况下可以根据**分区分配策略**来自动分配各个**消费者与分区的关系**。当消费组内的消费者增加或减少时，分区分配关系会自动调整，以实现消费负载均衡及故障自动转移。而通过assign()方法订阅分区时，是不具备消费者自动均衡的功能的。

### 2.3 反序列化

### 2.4 消费者拦截器
消费者拦截器主要在消费到消息或在提交消费位移时进行一些定制化的操作。暂时还未在 confluent kafka 中找到消费者拦截器的设置方式。

## 3. 消息消费
**Kafka中的消费是基于拉模式的**。如示例所示，消费的过程是不断调用 poll() 方法，poll 返回的是所订阅主题(分区)上的一组消息。

`consumer.poll([timeout=None])`
- 作用: 一次消费一个消息
- 返回: Message 或者 None
    - 对于poll（）方法而言，如果某些分区中没有可供消费的消息，那么此分区对应的消息拉取的结果就为空
    - 如果订阅的所有分区中都没有可供消费的消息，那么poll（）方法返回为空的消息集合。
- timeout: 
    - 控制poll 方法的阻塞时间，在消费者的缓冲区里没有可用数据时会发生阻塞
    - timeout的设置取决于应用程序对响应速度的要求，比如需要在多长时间内将控制权移交给执行轮询的应用线程
    - 如果应用线程唯一的工作就是从Kafka中拉取并消费消息，则可以将这个参数设置为最大值Long.MAX_VALUE。

`classconfluent_kafka.Message`
- 作用: 返回的消息包装类

`consumer.consume([num_messages=1][, timeout=-1])`
- 作用: 一次消费多条消息
- 返回: list(Message)
- 参数:
    - num_messages: 一次获取的最大消息数量，默认为 1
    - timeout: 获取消息时的超时时间

到目前为止，可以简单地认为poll（）方法只是拉取一下消息而已，但就其内部逻辑而言并不简单，它涉及消费位移、消费者协调器、组协调器、消费者的选举、分区分配的分发、再均衡的逻辑、心跳等内容，在后面的章节中会循序渐进地介绍这些内容。

### 3.1 位移提交
每个消息在 Kafka 分区中都有一个 offset，相当于唯一ID，表示消息在分区中对应的位置。对于消费者，也有一个offset，消费者使用offset来表示消费到分区中某个消息所在的位置。

在每次调用poll（）方法时，它返回的是还没有被消费过的消息集。要做到这一点，就需要记录上一次消费时的消费位移。保存消费者位移的目的是为了在消费者重启或者再均衡之后，消费者知道从何处开始消费。

在旧消费者客户端中，消费位移是存储在ZooKeeper中的。而在新消费者客户端中，消费位移存储在Kafka内部的主题 **__consumer_offsets** 中。把将消费位移存储起来（持久化）的动作称为“提交”，消费者在消费完消息之后需要执行消费位移的提交。

如下图所示，假设消费者已经消费了 x 位置的消息:
1. 我们称消费者的消费位移为 x，用 lastConsumedOffset 标识
2. 消费者需要提交的消费位移是 x+1，即 position，它表示下一条需要拉取的消息的位置
3. 还有一个committed offset的概念，它表示已经提交过的消费位移

![消费位移](/images/kafka/commit_position.jpg)


位移提交的具体时机很有讲究，这决定了是可能造成重复消费和还是可能造成消息丢失。

位移提交有两种，手动提交和自动提交。自动提交由以下两个参数控制:
1. `enable.auto.commit`: 默认值为 True 表示自动提交
2. `auto.commit.interval.ms`: int 表示自动提交的周期间隔，默认值为 5s

在默认的方式下，消费者每隔5秒会将拉取到的每个分区中最大的消息位移进行提交。自动位移提交的动作是在poll（）方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交，如果可以，那么就会提交上一次轮询的位移。

自动提交消费位移的方式非常简便，但随之而来的是重复消费和消息丢失的问题(注意是都有可能发生，因为消息会缓存在客户端)。与此同时，自动位移提交也无法做到精确的位移管理。因此大多数情况下，我们需要手动位移提交。

手动提交可以细分为同步提交和异步提交。同步异步提交与 commit 方法有关

`comsumer.commit([message=None][, offsets=None][, asynchronous=True])`
- 作用: 提交位移
- 参数:
    - message: 提交位移等于 消息的偏移量 + 1
    - offsets: list(TopicPartition)，主题列表 + 分区 + 提交偏移量
    - asynchronous: 是否异步提交，默认是 True 异步提交
- 注意: 
    - message 与 offset 是互斥的，如果都没有设置，则提交当前批次对应的 position 值
    - 大多数情况下我们是按照分区的粒度划分提交位移的界限，此时需要 offsets 参数

#### 同步位移提交

```python
def consume_loop(consumer, topics):
    try:
        consumer.subscribe(topics)

        msg_count = 0
        while running:
            msg = consumer.poll(timeout=1.0)
            if msg is None: continue

            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    # End of partition event
                    sys.stderr.write('%% %s [%d] reached end at offset %d\n' %
                                     (msg.topic(), msg.partition(), msg.offset()))
                elif msg.error():
                    raise KafkaException(msg.error())
            else:
                msg_process(msg)
                msg_count += 1
                if msg_count % MIN_COMMIT_COUNT == 0:
                    consumer.commit(async=False)
    finally:
        # Close down consumer to commit final offsets.
        consumer.close()
```

#### 异步位移提交
commit_completed 为异步提交设置有一个回调函数，用于处理异步提交失败的情况。我们可以在这个回调函数中进行位移提交的重试。但这样有可能覆盖掉后面发起的位移提交。为此我们可以设置一个递增的序号来维护异步提交的顺序，每次位移提交之后就增加序号相对应的值。在遇到位移提交失败需要重试的时候，可以检查所提交的位移和序号的值的大小，如果前者小于后者，则说明有更大的位移已经提交了，不需要再进行本次重试；如果两者相同，则说明可以进行重试提交。

在一般情况下，位移提交失败的情况很少发生，不重试也没有关系，后面的提交也会有成功的。重试会增加代码逻辑的复杂度，不重试会增加重复消费的概率。如果消费者正常退出或发生再均衡的情况，那么可以在退出或再均衡执行之前使用同步提交的方式做最后的把关。

```python
from confluent_kafka import Consumer

def commit_completed(err, partitions):
    if err:
        print(str(err))
    else:
        print("Committed partition offsets: " + str(partitions))

conf = {'bootstrap.servers': "host1:9092,host2:9092",
        'group.id': "foo",
        'default.topic.config': {'auto.offset.reset': 'smallest'},
        'on_commit': commit_completed}

consumer = Consumer(conf)

def consume_loop(consumer, topics):
    try:
        consumer.subscribe(topics)

        msg_count = 0
        while running:
            msg = consumer.poll(timeout=1.0)
            if msg is None: continue

            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    # End of partition event
                    sys.stderr.write('%% %s [%d] reached end at offset %d\n' %
                                     (msg.topic(), msg.partition(), msg.offset()))
                elif msg.error():
                    raise KafkaException(msg.error())
            else:
                msg_process(msg)
                msg_count += 1
                if msg_count % MIN_COMMIT_COUNT == 0:
                    consumer.commit(async=True)
    finally:
        # Close down consumer to commit final offsets.
        consumer.close()
```

### 3.2 控制或关闭消费
consumer 还提供了了方法用来，暂停和恢复消息拉取，以及最终关闭消费以释放资源。

`consumer.pause(partitions)`
- 作用: 暂停对传入的分区进行消费
- 参数:
    - partitions: list(TopicPartition)，要暂停的主题分区列表

`consumer.esume(partitions)`
- 作用: 恢复对传入的分区的消费
- 参数:
    - partitions: list(TopicPartition)，要暂停的主题分区列表

`consumer.close()`
- 作用:
    - 停止消费
    - 离开消费者群体
    - 提交最终的位移

### 3.3 指定位移消费
在 Kafka 中每当消费者查找不到所记录的消费位移时，就会根据消费者客户端参数 **auto.offset.reset** 的配置来决定从何处开始进行消费：

auto.offset.reset
- 作用: 找不到消费者位移时，配置消费的起点
- 可选值:
    - latest: 表示从分区末尾开始消费消息
    - earliest: 从起始处，也就是0开始消费
    - None: 查到不到消费位移的时候报错
除了查找不到消费位移，位移越界也会触发 auto.offset.reset 参数的执行

consumer.seek 方法可以让我们更精确的控制消费的位移起点。

`consumer.seek(partition)`
- 作用: 执行消费的分区位移起点
- 参数:
    - partition:  TopicPartition，主题+分区+位移
- 说明: 
    - seek（）方法只能重置消费者分配到的分区的消费位置，而分区的分配是在 poll（）方法的调用过程中实现的
    - 也就是说执行seek（）方法之前需要先执行一次poll（）方法，等到分配到分区之后才可以重置消费位置
    - 对未分配到的分区执行seek（）方法，会报错

```python
# 1. seek 设置从末尾消费消息

```

#### 根据时间设置位移起点
有时候我们并不知道特定的消费位置，却知道一个相关的时间点，consumer.offsets_for_times 方法，通过 timestamp 来查询与此对应的分区位置。

`consumer.offsets_for_times(partitions[, timeout=None])`
- 作用: 
    - 根据时间戳来查询对应的分区位置
    - 每个分区返回的偏移量是其时间戳大于或等于相应分区中给定时间戳的最早偏移量
    - 如果提供的时间戳超过分区中最后一条消息的时间戳，则返回值-1
- 返回: list(TopicPartition) 
- 参数:
    - partitions: list(TopicPartition)
    - timeout: 超时时间

最后 seek() 方法也为我们提供了将消费位移保存在外部存储介质中的能力，还可以配合再均衡监听器来提供更加精准的消费能力。

### 3.4 再均衡
再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。不过在再均衡发生期间，消费组内的消费者是无法读取消息的。

另外，当一个分区被重新分配给另一个消费者时，消费者当前的状态也会丢失。一般情况下，应尽量避免不必要的再均衡的发生。

`consumer.subscribe(topics[, on_assign=None][, on_revoke=None])` 中的 on_assign 和 on_revoke 参数就是再均衡监听器，用来设定发生再均衡动作前后的一些准备或收尾的动作。
on_revoke:
- 调用: 在再均衡开始之前和消费者停止读取消息之后被调用
- 作用: 可以通过这个回调方法来处理消费位移的提交，以此来避免一些不必要的重复消费现象的发生
- 参数: list(TopicPartition) ，表示再均衡之前分配到的分区

on_assign:
- 调用: 会在重新分配分区之后和消费者开始读取消费之前被调用
- 作用: 可以通过这个回调方法设置新的位移起点
- 参数: list(TopicPartition) ，表示再均衡之后分配到的分区

再均衡监听器还可以配合外部存储使用，在此不再赘述。

### 3.5 消费者的多线程(进程)实现
前面我们说过，一个分区只能被一个消费者进行消费，因此消费者的并发上限是分区数量。要想更快的进行消息处理，只能是一个线程接收消息，多个线程处理消息，但这对位移提交有比较高的编码要求。可以参考 TCP 中的滑动窗口，以固定的窗口为单位进行消息处理和位移提交。参考实现如下:

```python
# 1. 消费者的多进程实现
```

## 4. 重要的消费者参数
消费者也有很多配置参数，这些参数涉及到 **程序的可用性和性能** 重要的列示如下:
1. bootstrap.servers：
    - 作用: 该参数用来指定生产者客户端连接Kafka集群所需的broker地址清单
    - 默认: 默认值为 ""
    - 格式: 具体的内容格式为host1：port1，host2：port2
    - 说明: 不需要指定所有的broker地址，因为消费者会从给定的broker里查找到其他broker的信息
2. group.id:
    - 作用: 消费者隶属的消费者组名称
    - 默认: 默认值为 ""，设置为空，则会报出异常
    - 说明: 需要设置成具有一定的业务意义的名称
3. key.deserializer: 指定键的反序列化器
4. value.deserializer: 指定值的反序列化器
5. client.id:
    - 作用: 设定KafkaConsumer对应的客户端id
    - 默认: 默认值为 ""，非必须参数
    - 说明: 客户端不设置，则KafkaConsumer会自动生成一个非空字符串，内容形式如“consumer-1”
2. fetch.min.bytes:
    - 作用: 
        - 配置Consumer在一次拉取请求（调用poll（）方法）中能从Kafka中拉取的最小数据量
        - 如果返回给Consumer的数据量小于这个参数所配置的值，那么它就需要进行等待，直到数据量满足这个参数的配置大小
    - 默认: 默认值为1（B）
    - 说明: 可以适当调大这个参数的值以提高一定的吞吐量，不过也会造成额外的延迟（latency）
2. fetch.max.bytes:
    - 作用: 配置Consumer在一次拉取请求中从Kafka中拉取的最大数据量
    - 默认: 默认值为 52428800（B），也就是 50MB
    - 说明: 
        - 如果在第一个非空分区中拉取的第一条消息大于该值，那么该消息将仍然返回
        - 也就是说如果这个参数设置的值比任何一条写入Kafka中的消息要小，仍然是可以正常消费的
    - 相关: Kafka中所能接收的最大消息的大小通过服务端参数message.max.bytes（对应于主题端参数max.message.bytes）来设置
2. fetch.max.wait.ms:
    - 作用: 和fetch.min.bytes参数的等待时间，指定Kafka最长的等待时间
    - 默认: 默认值为500（ms）
    - 说明: 
2. max.partition.fetch.bytes:
    - 作用: 配置从每个分区里返回给Consumer的最大数据量
    - 默认: 默认值为1048576（B），即1MB
    - 说明: 
        - fetch.max.bytes 用来限制一次拉取中整体消息的大小，此参数用来限制一次拉取中每个分区的消息大小
        - 同样，如果这个参数设定的值比消息的大小要小，那么也不会造成无法消费
2. max.poll.records:
    - 作用: 配置Consumer在一次拉取请求中拉取的最大消息数
    - 默认: 默认值为500（条）
    - 说明:
2. connections.max.idle.ms:
    - 作用: 指定多久之后关闭闲置的连接
    - 默认: 默认值是540000（ms），即9分钟
    - 说明:
2. exclude.internal.topics:
    - 作用: 
        - 指定Kafka中的内部主题是否可以向消费者公开
        - 设置为true，那么只能使用subscribe（Collection）的方式而不能使用subscribe（Pattern）的方式来订阅内部主题
        - 设置为false则没有这个限制
    - 默认: 默认值为true
    - 说明:
2. receive.buffer.bytes:
    - 作用: 设置Socket接收消息缓冲区（SO_RECBUF）的大小
    - 默认: 默认值为65536（B），即64KB，如果设置为-1，则使用操作系统的默认值
    - 说明:
2. gsend.buffer.bytes:
    - 作用: 设置Socket发送消息缓冲区（SO_SNDBUF）的大小
    - 默认: 默认值为131072（B），即128KB，如果设置为-1，则使用操作系统的默认值
    - 说明:
2. request.timeout.ms:
    - 作用: 配置Consumer等待请求响应的最长时间
    - 默认: 默认值为30000（ms）
    - 说明:
2. metadata.max.age.ms
    - 作用: 这个参数用来配置元数据的过期时间
    - 默认: 默认值为300000（ms），即5分钟
    - 说明: 如果元数据在此参数所限定的时间范围内没有进行更新，则会被强制更新，即使没有任何分区变化或有新的broker加入
2. reconnect.backoff.ms:
    - 作用: 配置尝试重新连接指定主机之前的等待时间（也称为退避时间），避免频繁地连接主机
    - 默认: 默认值为50（ms）
    - 说明: 这种机制适用于消费者向broker发送的所有请求
2. retry.backoff.ms:
    - 作用: 来配置尝试重新发送失败的请求到指定的主题分区之前的等待（退避）时间，避免在某些故障情况下频繁地重复发送
    - 默认: 默认值为100（ms）
    - 说明: 
2. isolation.level:
    - 作用: 用来配置消费者的事务隔离级别
    - 可选值: read_uncommitted 和 read_committed 表示消费者所消费到的位置
        - read_committed: 消费者会忽略事务未提交的消息，即只能消费到 LSO（LastStableOffset）的位置
        - read_uncommitted: 消费者可以消费到HW（High Watermark）处的位置
    - 默认: 默认情况下为 read_uncommitted
    - 说明:
