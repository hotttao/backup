---
weight: 1
title: "Huggingface Datasets"
date: 2025-07-17T9:00:00+08:00
lastmod: 2025-07-17T9:00:00+08:00
draft: false
author: "å®‹æ¶›"
authorLink: "https://hotttao.github.io/"
description: "Huggingface Datasets"
featuredImage: 

tags: ["huggingface"]
categories: ["langchain"]

lightgallery: true

toc:
  auto: false
---

è¿™ä¸€èŠ‚æˆ‘ä»¬æ¥å­¦ä¹  Huggingface Transformers åº“ã€‚

## 1. Transformers
### 1.1 ç»„æˆ

Hugging Face çš„ **Transformers** æ˜¯ä¸€ä¸ª **NLP / CV / Audio é€šç”¨é¢„è®­ç»ƒæ¨¡å‹åº“**ï¼Œä¸»è¦ç”±ä»¥ä¸‹å‡ éƒ¨åˆ†ç»„æˆï¼š

| æ¨¡å—                              | ä½œç”¨                                                                                            |
| ------------------------------- | --------------------------------------------------------------------------------------------- |
| **Model Hub æ¥å£**                | æä¾›ä¸ Hugging Face Hub çš„é›†æˆï¼Œæ–¹ä¾¿åŠ è½½/ä¸Šä¼ æ¨¡å‹ï¼ˆå¦‚ `AutoModel.from_pretrained("bert-base-uncased")`ï¼‰ã€‚       |
| **Auto Classes**                | ç»Ÿä¸€çš„å…¥å£ç±»ï¼Œæ ¹æ®æ¨¡å‹åç§°è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ¶æ„ï¼ˆå¦‚ `AutoTokenizer`, `AutoModel`, `AutoModelForSequenceClassification`ï¼‰ã€‚ |
| **Tokenizer**                   | åˆ†è¯å™¨æ¨¡å—ï¼Œå°†æ–‡æœ¬è½¬æˆ tokenï¼Œå†è½¬æˆæ¨¡å‹å¯ç”¨çš„ `input_ids`ã€‚åŒæ—¶è´Ÿè´£åå‘è§£ç ã€‚                                              |
| **Model Classes**               | ä¸åŒä»»åŠ¡çš„æ¨¡å‹å®šä¹‰ï¼ˆBERT, GPT, T5, CLIP ç­‰ï¼‰ï¼Œå¹¶ä¸”ç»†åˆ†ä¸ºä¸åŒä¸‹æ¸¸ä»»åŠ¡ï¼ˆåˆ†ç±»ã€ç”Ÿæˆã€é—®ç­”ç­‰ï¼‰ã€‚                                      |
| **Pipelines**                   | é«˜å±‚å°è£…çš„ä»»åŠ¡æ¥å£ï¼Œå¦‚ `pipeline("sentiment-analysis")`ï¼Œå‡ è¡Œä»£ç å®Œæˆæ¨ç†ã€‚                                        |
| **Trainer / TrainingArguments** | æä¾›äº†è®­ç»ƒ/è¯„ä¼°/å¾®è°ƒçš„é«˜å±‚ APIï¼Œæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒã€‚                                                                   |
| **Datasets / Tokenizers é›†æˆ**    | ä¸ `datasets`ã€`tokenizers` ç­‰ Hugging Face ç”Ÿæ€æ— ç¼ç»“åˆã€‚                                              |

---

### 1.2 æ ¸å¿ƒæŠ½è±¡

Transformers çš„è®¾è®¡å“²å­¦æ˜¯ï¼š
**Tokenizer â†’ Model â†’ Pipeline**

* **Tokenizer (åˆ†è¯å™¨)**

  * è¾“å…¥ï¼šåŸå§‹æ–‡æœ¬
  * è¾“å‡ºï¼š`input_ids`, `attention_mask` ç­‰å¼ é‡

* **Model (æ¨¡å‹ç±»)**

  * è¾“å…¥ï¼š`input_ids` ç­‰å¼ é‡
  * è¾“å‡ºï¼šéšè—å±‚ã€logitsã€loss ç­‰
  * ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š

    * **Encoder-only**ï¼ˆå¦‚ BERTï¼Œç”¨äºåˆ†ç±»ã€æ£€ç´¢ï¼‰
    * **Decoder-only**ï¼ˆå¦‚ GPTï¼Œç”¨äºç”Ÿæˆï¼‰
    * **Encoder-Decoder**ï¼ˆå¦‚ T5/BARTï¼Œç”¨äºç¿»è¯‘ã€æ‘˜è¦ï¼‰

* **Pipeline (ä»»åŠ¡æµæ°´çº¿)**

  * è¾“å…¥ï¼šæ–‡æœ¬ï¼ˆæˆ–å›¾åƒ/éŸ³é¢‘ï¼‰
  * è‡ªåŠ¨è°ƒç”¨åˆ†è¯å™¨ + æ¨¡å‹ + åå¤„ç†ï¼Œå¾—åˆ°ç»“æœ
  * é€‚åˆå¿«é€Ÿæ¨ç† demoï¼Œä½†è®­ç»ƒ/å¾®è°ƒä¸€èˆ¬ç›´æ¥ç”¨ `Trainer`

---

### 1.3 åŸºç¡€ä½¿ç”¨

ä¸‹é¢ç»™ä½ å‡ ä¸ªå¸¸è§çš„å…¥é—¨ç¤ºä¾‹ï¼š

#### åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ & åˆ†è¯å™¨

```python
from transformers import AutoTokenizer, AutoModel

# åŠ è½½ tokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# åŠ è½½æ¨¡å‹
model = AutoModel.from_pretrained("bert-base-uncased")

# ç¼–ç æ–‡æœ¬
inputs = tokenizer("Hello Hugging Face!", return_tensors="pt")

# å‰å‘è®¡ç®—
outputs = model(**inputs)

print(outputs.last_hidden_state.shape)  # [batch_size, seq_len, hidden_size]
```

---

#### ä½¿ç”¨ Pipeline å¿«é€Ÿæ¨ç†

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")

result = classifier("I love using Hugging Face Transformers!")
print(result)
# [{'label': 'POSITIVE', 'score': 0.9998}]
```

---

#### ä¸‹æ¸¸ä»»åŠ¡æ¨¡å‹

```python
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)
```

è¿™é‡Œçš„ `AutoModelForSequenceClassification` å°±æ˜¯ä¸º **æ–‡æœ¬åˆ†ç±»** å°è£…å¥½çš„æ¨¡å‹å¤´ã€‚

---

#### å¾®è°ƒè®­ç»ƒï¼ˆä½¿ç”¨ Trainerï¼‰

```python
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    per_device_train_batch_size=8,
    num_train_epochs=3,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,  # ğŸ¤— datasets æ ¼å¼
    eval_dataset=eval_dataset,
)

trainer.train()
```


### 1.4 pipeline å‚æ•°

```python
def pipeline(
    task: Optional[str] = None,
    model: Optional[Union[str, "PreTrainedModel", "TFPreTrainedModel"]] = None,
    config: Optional[Union[str, PretrainedConfig]] = None,
    tokenizer: Optional[Union[str, PreTrainedTokenizer, "PreTrainedTokenizerFast"]] = None,
    feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None,
    image_processor: Optional[Union[str, BaseImageProcessor]] = None,
    processor: Optional[Union[str, ProcessorMixin]] = None,
    framework: Optional[str] = None,
    revision: Optional[str] = None,
    use_fast: bool = True,
    token: Optional[Union[str, bool]] = None,
    device: Optional[Union[int, str, "torch.device"]] = None,
    device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None,
    torch_dtype: Optional[Union[str, "torch.dtype"]] = "auto",
    trust_remote_code: Optional[bool] = None,
    model_kwargs: Optional[dict[str, Any]] = None,
    pipeline_class: Optional[Any] = None,
    **kwargs: Any,
) -> Pipeline:
    pass
```

| å‚æ•°                  | ç±»å‹                                                | å«ä¹‰                                                                |
| ------------------- | ------------------------------------------------- | ----------------------------------------------------------------- |
| `task`              | `str`                                             | æŒ‡å®šä»»åŠ¡ç±»å‹ï¼Œå¦‚ `"text-generation"`, `"summarization"` ç­‰ã€‚                |
| `model`             | `str` \| `PreTrainedModel` \| `TFPreTrainedModel` | æ¨¡å‹ ID æˆ–æ¨¡å‹å®ä¾‹ã€‚è‹¥ä¸ä¼ ï¼Œä¼šåŠ è½½ `task` çš„é»˜è®¤æ¨¡å‹ã€‚                                 |
| `config`            | `str` \| `PretrainedConfig`                       | æ¨¡å‹é…ç½®å¯¹è±¡æˆ– IDã€‚æ§åˆ¶æ¨¡å‹ç»“æ„å’Œè¶…å‚æ•°ã€‚                                            |
| `tokenizer`         | `str` \| `PreTrainedTokenizer`                    | æ–‡æœ¬åˆ†è¯å™¨ï¼Œç”¨äº NLP ä»»åŠ¡ã€‚                                                  |
| `feature_extractor` | `str` \| `PreTrainedFeatureExtractor`             | ç‰¹å¾æå–å™¨ï¼ˆç”¨äºè¯­éŸ³/å›¾åƒè¾“å…¥ï¼‰ã€‚                                                 |
| `image_processor`   | `str` \| `BaseImageProcessor`                     | å›¾åƒé¢„å¤„ç†å™¨ã€‚                                                           |
| `processor`         | `str` \| `ProcessorMixin`                         | å¤šæ¨¡æ€è¾“å…¥çš„é¢„å¤„ç†å™¨ï¼ˆæ¯”å¦‚å›¾æ–‡ç»“åˆï¼‰ã€‚                                               |
| `revision`          | `str`                                             | æ¨¡å‹ç‰ˆæœ¬ï¼ˆGit åˆ†æ”¯/Tag/Commit IDï¼‰ï¼Œé»˜è®¤ `"main"`ã€‚                           |
| `use_fast`          | `bool`                                            | æ˜¯å¦ä½¿ç”¨å¿«é€Ÿåˆ†è¯å™¨ï¼ˆ`tokenizers` Rust å®ç°ï¼‰ã€‚                                  |
| `token`             | `str` \| `bool`                                   | Hugging Face Hub æˆæƒ tokenï¼ˆTrue è¡¨ç¤ºä½¿ç”¨ `hf auth login` é‡Œçš„ tokenï¼‰ã€‚    |
| `device`            | `int` \| `str` \| `torch.device`                  | æŒ‡å®šè¿è¡Œè®¾å¤‡ï¼Œå¦‚ `"cpu"`, `"cuda:0"`, `"mps"`ï¼ˆMac M1/M2ï¼‰ã€‚                 |
| `device_map`        | `str` \| `dict`                                   | å¤§æ¨¡å‹çš„åˆ†å¸ƒå¼éƒ¨ç½²ç­–ç•¥ï¼ˆAccelerate åº“æ”¯æŒï¼‰ã€‚                                      |
| `torch_dtype`       | `str` \| `torch.dtype`                            | PyTorch ç²¾åº¦ç±»å‹ï¼Œæ”¯æŒ `"float32"`, `"float16"`, `"bfloat16"`, `"auto"`ã€‚ |
| `trust_remote_code` | `bool`                                            | æ˜¯å¦å…è®¸æ‰§è¡Œ Hugging Face Hub ä¸Šçš„è‡ªå®šä¹‰ Python ä»£ç ã€‚                          |
| `model_kwargs`      | `dict`                                            | é¢å¤–ä¼ é€’ç»™ `from_pretrained` çš„å‚æ•°ï¼ˆå¦‚ `low_cpu_mem_usage=True`ï¼‰ã€‚          |
| `pipeline_class`    | `Any`                                             | å¼ºåˆ¶æŒ‡å®šè¦ä½¿ç”¨çš„ `Pipeline` ç±»ã€‚                                            |
| `kwargs`            | `dict`                                            | ä¼ é€’ç»™å…·ä½“ pipeline çš„å…¶ä»–å‚æ•°ï¼ˆä¸åŒä»»åŠ¡æ”¯æŒä¸åŒï¼‰ã€‚                                   |

---


#### `task`ï¼ˆä»»åŠ¡ç±»å‹æšä¸¾ï¼‰

| å–å€¼                                               | å¯¹åº” Pipeline                           | åŠŸèƒ½              |
| ------------------------------------------------ | ------------------------------------- | --------------- |
| `"text-generation"`                              | `TextGenerationPipeline`              | æ–‡æœ¬ç”Ÿæˆï¼ˆå¦‚ GPT æ¨¡å‹ï¼‰ã€‚ |
| `"text2text-generation"`                         | `Text2TextGenerationPipeline`         | æ–‡æœ¬åˆ°æ–‡æœ¬ç”Ÿæˆï¼ˆå¦‚ T5ï¼‰ã€‚  |
| `"summarization"`                                | `SummarizationPipeline`               | æ–‡æœ¬æ‘˜è¦ã€‚           |
| `"translation_xx_to_yy"`                         | `TranslationPipeline`                 | ç¿»è¯‘ï¼ˆxxâ†’yyï¼‰ã€‚      |
| `"text-classification"` / `"sentiment-analysis"` | `TextClassificationPipeline`          | æ–‡æœ¬åˆ†ç±»/æƒ…æ„Ÿåˆ†æã€‚      |
| `"token-classification"` / `"ner"`               | `TokenClassificationPipeline`         | å‘½åå®ä½“è¯†åˆ«ã€‚         |
| `"question-answering"`                           | `QuestionAnsweringPipeline`           | é—®ç­”ã€‚             |
| `"fill-mask"`                                    | `FillMaskPipeline`                    | æ©ç å¡«å……ï¼ˆBERT ç±»æ¨¡å‹ï¼‰ã€‚ |
| `"feature-extraction"`                           | `FeatureExtractionPipeline`           | æå–å‘é‡è¡¨ç¤ºã€‚         |
| `"zero-shot-classification"`                     | `ZeroShotClassificationPipeline`      | é›¶æ ·æœ¬æ–‡æœ¬åˆ†ç±»ã€‚        |
| `"automatic-speech-recognition"`                 | `AutomaticSpeechRecognitionPipeline`  | è¯­éŸ³è½¬æ–‡æœ¬ã€‚          |
| `"text-to-audio"` / `"text-to-speech"`           | `TextToAudioPipeline`                 | æ–‡æœ¬è½¬è¯­éŸ³ã€‚          |
| `"audio-classification"`                         | `AudioClassificationPipeline`         | éŸ³é¢‘åˆ†ç±»ã€‚           |
| `"zero-shot-audio-classification"`               | `ZeroShotAudioClassificationPipeline` | é›¶æ ·æœ¬éŸ³é¢‘åˆ†ç±»ã€‚        |
| `"image-classification"`                         | `ImageClassificationPipeline`         | å›¾åƒåˆ†ç±»ã€‚           |
| `"object-detection"`                             | `ObjectDetectionPipeline`             | ç›®æ ‡æ£€æµ‹ã€‚           |
| `"image-segmentation"`                           | `ImageSegmentationPipeline`           | å›¾åƒåˆ†å‰²ã€‚           |
| `"image-to-text"`                                | `ImageToTextPipeline`                 | å›¾åƒæè¿°ã€‚           |
| `"image-to-image"`                               | `ImageToImagePipeline`                | å›¾åƒåˆ°å›¾åƒè½¬æ¢ã€‚        |
| `"zero-shot-image-classification"`               | `ZeroShotImageClassificationPipeline` | é›¶æ ·æœ¬å›¾åƒåˆ†ç±»ã€‚        |
| `"zero-shot-object-detection"`                   | `ZeroShotObjectDetectionPipeline`     | é›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹ã€‚        |
| `"document-question-answering"`                  | `DocumentQuestionAnsweringPipeline`   | æ–‡æ¡£é—®ç­”ã€‚           |
| `"table-question-answering"`                     | `TableQuestionAnsweringPipeline`      | è¡¨æ ¼é—®ç­”ã€‚           |
| `"video-classification"`                         | `VideoClassificationPipeline`         | è§†é¢‘åˆ†ç±»ã€‚           |
| `"visual-question-answering"`                    | `VisualQuestionAnsweringPipeline`     | è§†è§‰é—®ç­”ã€‚           |
| `"mask-generation"`                              | `MaskGenerationPipeline`              | ç”Ÿæˆå›¾åƒæ©ç ã€‚         |
| `"depth-estimation"`                             | `DepthEstimationPipeline`             | æ·±åº¦ä¼°è®¡ã€‚           |
| `"image-feature-extraction"`                     | `ImageFeatureExtractionPipeline`      | æå–å›¾åƒ embeddingã€‚ |
| `"image-text-to-text"`                           | `ImageTextToTextPipeline`             | å›¾åƒ+æ–‡æœ¬ â†’ æ–‡æœ¬ã€‚     |

---

#### `framework`ï¼ˆæ¡†æ¶æšä¸¾ï¼‰

| å–å€¼     | å«ä¹‰               |
| ------ | ---------------- |
| `"pt"` | ä½¿ç”¨ PyTorch       |
| `"tf"` | ä½¿ç”¨ TensorFlow    |
| `None` | è‡ªåŠ¨æ£€æµ‹ï¼ˆä¼˜å…ˆ PyTorchï¼‰ |

---

#### `device_map`ï¼ˆè®¾å¤‡åˆ†é…ç­–ç•¥ï¼‰

| å–å€¼             | å«ä¹‰                                         |
| -------------- | ------------------------------------------ |
| `"auto"`       | ä½¿ç”¨ Accelerate è‡ªåŠ¨æ¨ç†è®¾å¤‡åˆ†é…ï¼ˆå¤§æ¨¡å‹åˆ†ç‰‡åˆ° CPU/GPU/ç£ç›˜ï¼‰ã€‚ |
| `"sequential"` | æŒ‰å±‚é¡ºåºåˆ†é…ã€‚                                    |
| `"balanced"`   | å°½é‡å‡è¡¡åˆ†é…ã€‚                                    |
| `dict`         | æ‰‹åŠ¨æŒ‡å®šæ¯å±‚æ”¾åœ¨å“ªä¸ªè®¾å¤‡ã€‚                              |

---

#### `torch_dtype`ï¼ˆç²¾åº¦ç±»å‹ï¼‰

| å–å€¼              | å«ä¹‰                        |
| --------------- | ------------------------- |
| `"float32"`     | å•ç²¾åº¦ï¼Œæœ€é«˜ç²¾åº¦ï¼Œæ˜¾å­˜å ç”¨å¤§ã€‚           |
| `"float16"`     | åŠç²¾åº¦ï¼Œå¸¸ç”¨äºæ¨ç†ï¼ŒåŠ é€Ÿ & èŠ‚çœæ˜¾å­˜ã€‚      |
| `"bfloat16"`    | bfloat16 ç²¾åº¦ï¼Œå…¼å®¹ TPU/æ–° GPUã€‚ |
| `"auto"`        | è‡ªåŠ¨é€‰æ‹©ï¼ˆæ ¹æ®æ¨¡å‹æƒé‡ & ç¡¬ä»¶ï¼‰ã€‚        |
| `torch.float16` | ç­‰ä»·äº `"float16"`ã€‚          |


## 2. ä½¿ç”¨ç¤ºä¾‹

å­¦ä¹ èµ„æ–™:
1. [å´æ©è¾¾è€å¸ˆ Huggingface è¯¾ç¨‹](https://www.bilibili.com/video/BV1UQt9zsEUx/?p=4&vd_source=e51cd6df2226be5b731e6a1a575eb5b2)
2. [è¯¾ç¨‹ä»£ç ](https://github.com/ksm26/Open-Source-Models-with-Hugging-Face)

### 2.1 å¯¹è¯
Natural Language Processing

```python
from transformers import pipeline
from transformers import Conversation
# conversational ç°ç‰ˆæœ¬å« text-generation
chatbot = pipeline(task="conversational",
                   model="facebook/blenderbot-400M-distill")
user_message = """
What are some fun activities I can do in the winter?
"""
conversation = Conversation(user_message)
conversation = chatbot(conversation)
# Add a message to the conversation
conversation.add_message(
    {"role": "user",
     "content": """What else do you recommend?"""
    })
conversation = chatbot(conversation)
```

### 2.2 ç¿»è¯‘å’Œæ‘˜è¦
Translation and Summarization

```python
# ç¿»è¯‘
from transformers import pipeline
# Create the translator pipeline using a model from Meta
translator = pipeline(task="translation",
                      model="facebook/nllb-200-distilled-600M",
                      torch_dtype=torch.bfloat16)
text = """\
My puppy is adorable, 
Your kitten is cute.
Her panda is friendly.
His llama is thoughtful. 
We all have nice pets!"""

text_translated = translator(text,
                             src_lang="eng_Latn",
                             tgt_lang="fra_Latn")

# summary
summarizer = pipeline(task="summarization",
                      model="facebook/bart-large-cnn",
                      torch_dtype=torch.bfloat16)
text = """Paris is the capital and most populous city of France, with
          an estimated population of 2,175,601 residents as of 2018,
          in an area of more than 105 square kilometres (41 square
          miles). The City of Paris is the centre and seat of
          government of the region and province of Ãle-de-France, or
          Paris Region, which has an estimated population of
          12,174,880, or about 18 percent of the population of France
          as of 2017."""
summary = summarizer(text,
                     min_length=10,
                     max_length=100)
```


### 2.3 embedding å’Œæ–‡æœ¬ç›¸ä¼¼åº¦æ£€æµ‹
Sentence Embeddings

```python
from sentence_transformers import SentenceTransformer
from sentence_transformers import util

model = SentenceTransformer("all-MiniLM-L6-v2")

sentences1 = ['The cat sits outside',
              'A man is playing guitar',
              'The movies are awesome']
embeddings1 = model.encode(sentences1, convert_to_tensor=True)

sentences2 = ['The dog plays in the garden',
              'A woman watches TV',
              'The new movie is so great']
embeddings2 = model.encode(sentences2, 
                           convert_to_tensor=True)

# ä½™æ—‹ç›¸ä¼¼åº¦
cosine_scores = util.cos_sim(embeddings1,embeddings2)
for i in range(len(sentences1)):
    print("{} \t\t {} \t\t Score: {:.4f}".format(sentences1[i],
                                                 sentences2[i],
                                                 cosine_scores[i][i]))
```

### 2.4 é›¶æ ·æœ¬éŸ³é¢‘åˆ†ç±»

Zero-Shot Audio Classification

```python
from datasets import load_dataset, load_from_disk
from datasets import Audio

dataset = load_dataset("ashraq/esc50",
                      split="train[0:10]")
# dataset = load_from_disk("./models/ashraq/esc50/train")
audio_sample = dataset[0]
# æŸ¥çœ‹éŸ³é¢‘é‡‡æ ·ç‡
audio_sample["audio"]["sampling_rate"]

zero_shot_classifier = pipeline(
    task="zero-shot-audio-classification",
    model="./models/laion/clap-htsat-unfused")
# æ¨¡å‹æ”¯æŒçš„é‡‡æ ·ç‡
print(zero_shot_classifier.feature_extractor.sampling_rate)

# é‡‡æ ·ç‡å¯¹å…¶
dataset = dataset.cast_column(
    "audio",
     Audio(sampling_rate=48_000))

# éŸ³é¢‘åˆ†ç±»

candidate_labels = ["Sound of a dog",
                    "Sound of vacuum cleaner"]
zero_shot_classifier(audio_sample["audio"]["array"],
                     candidate_labels=candidate_labels)
# éŸ³é¢‘åˆ†ç±»æ¦‚ç‡
# [{'score': 0.9985589385032654, 'label': 'Sound of a dog'},
#  {'score': 0.0014411062002182007, 'label': 'Sound of vacuum cleaner'}]
```


### 2.5 ASRï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰
Automatic Speech Recognition

```python
from transformers import pipeline

from datasets import load_dataset
dataset = load_dataset("librispeech_asr",
                       split="train.clean.100",
                       streaming=True,
                       trust_remote_code=True)
# openAI whisper æ¨¡å‹
asr = pipeline(task="automatic-speech-recognition",
               model="distil-whisper/distil-small.en")

# å¯¹å…¶é‡‡æ ·ç‡
asr.feature_extractor.sampling_rate
example['audio']['sampling_rate']

# è¯­éŸ³è½¬æ–‡å­—
asr(example["audio"]["array"])["text"]
# åˆ†å—å¹¶è¡Œå¤„ç†
asr(
    audio_16KHz,
    chunk_length_s=30, # 30 seconds
    batch_size=4,
    return_timestamps=True,
)["text"]
```

### 2.6 TTSï¼ˆæ–‡æœ¬è½¬è¯­éŸ³ï¼‰
Text to Speech

```python
from transformers import pipeline

narrator = pipeline("text-to-speech",
                    model="kakao-enterprise/vits-ljs")
narrated_text = narrator(text)

from IPython.display import Audio as IPythonAudio

IPythonAudio(narrated_text["audio"][0],
             rate=narrated_text["sampling_rate"])
```

### 2.7 ç‰©ä½“æ£€æµ‹
Object Detection

```python
from transformers import pipeline
od_pipe = pipeline("object-detection", "facebook/detr-resnet-50")
```

### 2.8 å›¾åƒåˆ†å‰²(æŠ å›¾)
Image Segmentation

```python
from transformers import pipeline
sam_pipe = pipeline("mask-generation",
    "Zigeng/SlimSAM-uniform-77")
```

