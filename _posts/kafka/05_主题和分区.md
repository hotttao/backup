---
title: 5 主题和分区
date: 2020-04-05
categories:
    - 存储
tags:
    - Kafka
---
主题和分区
<!-- more -->

## 1. 主题与分区概述
主题是消息的集合，分区算是消息的二次分类。分区的划分不仅为Kafka提供了可伸缩性、水平扩展的功能，还通过多副本机制来为Kafka提供数据冗余以提高数据可靠性。

从底层来说，主题和分区都是逻辑概念。分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段（LogSegment），每个日志分段还可以细分为索引文件、日志存储文件和快照文件等。有关 Kafka 日志存储的内容我们将在下一节详述。

本节我们将聚焦于 Kafka 主题和分区的管理上，内容包括:
1. 主题的管理；
2. 初识KafkaAdminClient；
3. 分区的管理；
    - 优先副本的选举
    - 分区重分配
    - 复制限流
    - 修改副本因子

## 2. 主题的管理
主题的管理包括主题的增删改查。通过 Kafka提供的 kafka-topics.sh 脚本来执行这些操作，这个脚本位于$KAFKA_HOME/bin/目录下。其实质上是调用了kafka.admin.TopicCommand类来执行主题管理的操作。

除了 kafka-topics.sh 脚本，我们还可以通过KafkaAdminClient，这种方式实质上是通过发送 CreateTopicsRequest、DeleteTopicsRequest 等请求来实现。甚至我们还可以通过直接操纵日志文件和ZooKeeper节点来实现。

kafka 提供了如下命令行工具:

|序号|	脚本	|功能|
|:---|:---|:---|
|3	|kafka-topics.sh|topic管理脚本|
|3	|kafka-configs.sh|配置管理，包括主题，broker，客户端，用户|
|1	|kafka-perferred-replica-election.sh|对分区leader副本进行重新平衡|
|1	|kafka-reassign-partitions.sh|分区重分配/复制限流/修改副本因子|
|1	|kafka-server-start.sh|启动kafka服务|
|2	|kafka-server-stop.sh|停止kafka服务|
|4	|kafka-console-producer.sh|kafka生产者控制台|
|5	|kafka-replay-log-producer.sh|消费topic数据并转发到另外一个topic|
|5	|kafka-console-consumer.sh|kafka消费者控制台|
|7	|kafka-simple-consumer-shell.sh|获取指定consumer group的位移信息|
|8	|kafka-consumer-groups.sh|kafka消费者组相关信息|
|9	|kafka-producer-perf-test.sh|kafka生产者性能测试脚本|
|10|	kafka-consumer-perf-test.sh|kafka消费者性能测试脚本|
|11|	kafka-verifiable-consumer.sh|检验的kafka消费者|
|12|	kafka-verifiable-producer.sh|检验的kafka生产者|

#### kafka-topic.sh 命令
bin/kafka-topics.sh 
- 通用参数:
    --zookeeper: Zookeeper 连接地址，eg: node01:2181/kafka
    --topic: 主题名称 
- --create: 主题创建指令
    --partitions: 指定分区数
    --replication-factor: 指定副本数
    --replica-assignment: 手动指定分区副本的分配方案
    --config: 设置主题的配置参数
    --if-not-exists
    --broker.rack: 指定机架信息，可以让副本尽量分配到不同机架上的机器上
    --disable-rack-aware: 忽略机架信息
- --list
- --describe: 查看分区副本的分配细节
    - topics-with-overrides: 只会列出包含了与集群不一样配置的主题
    - under-replicated-partitions: 找出所有包含失效副本的分区
    - unavailable-partitions: 查看主题中没有 leader 副本的分区
- --alter
- --delete

### 2.1 创建主题
#### 主题的默认创建
当 `auto.create.topics.enable=true`，出现以下情况时会默认创建新的主题:
1. 生产者向一个尚未创建的主题发送消息时
2. 消费者开始从未知主题中读取消息时
3. 任意一个客户端向未知主题发送元数据请求时

而下面参数用于设置主题的分区和副本数:
- `num.partitions`: 默认分区数，默认值为 1
- `default.replication.factor`: 默认副本数，默认值为 1

自动创建主题的行为都是非预期的，通常 `auto.create.topics.enable` 都需要设置为 false。推荐的方式是使用 kafka-topics.sh

#### kafka-topics.sh 创建主题
kafka-topics.sh脚本在创建主题时还会检测是否包含`.`或`_` 字符。为什么要检测这两个字符呢？因为在Kafka的内部做埋点时会根据主题的名称来命名metrics的名称，并且会将点号“.”改成下画线“_”。假设遇到一个名称为“topic.1_2”的主题，还有一个名称为“topic_1.2”的主题，那么最后的metrics的名称都会为“topic_1_2”，这样就发生了名称冲突。

主题的命名同样不推荐（虽然可以这样做）使用双下画线`__`开头，因为以双下画线开头的主题一般看作Kafka的内部主题。

主题的名称必须由大小写字母、数字、点号“.”、连接线“-”、下画线“_”组成，不能为空，不能只有点号“.”，也不能只有双点号“..”，且长度不能超过249。

创建主题的命令示例如下:

```bash
# 1. 使用默认参数创建
bin/kafka-topics.sh --zookeeper node01:2181 --create --topic t_cdr --partitions 30  --replication-factor 2

# 2. 指定分区副本分配方案

# 3. 指定主题配置参数
```

#### 主题、分区、部分、日志之间的关系

在执行完 create 主题创建指令后，Kafka会在 log.dir 或 log.dirs 参数所配置的目录下创建相应的主题分区。

```
log.dir
    <topic>-<partition> # 文件夹
        .log            # 日志分段
        .index
        .timeindex
        ...
```

主题、分区、副本和 Log（日志）的关系入下图所示

![副本日志对应关系](/images/kafka/kafka_log.png)

主题和分区都是提供给上层用户的抽象，而在副本层面或更加确切地说是Log层面才有实际物理上的存在。

### 2.2 分区副本分配
在生产者和消费者中也都有分区分配的概念:
1. 生产者的分区分配是指为每条消息指定其所要发往的分区
2. 消费者中的分区分配是指为消费者指定其可以消费消息的分区

这里的分区分配是指为集群制定创建主题时的分区副本分配方案，即在哪个broker中创建哪些分区的副本。

kafka-topics.sh脚本创建主题时的内部分配逻辑按照机架信息划分成两种策略：未指定机架信息和指定机架信息。内部的分配逻辑还比较复杂，这里我们不在详述。

#### 主题创建时的 Zookeeper 操作
当创建一个主题时，无论通过kafka-topics.sh脚本，还是通过其他方式创建主题时，实质上是
1. 在ZooKeeper中的/brokers/topics节点下创建与该主题对应的子节点并写入分区副本分配方案
2. 并且在/config/topics/节点下创建与该主题对应的子节点并写入主题相关的配置信息（这个步骤可以省略不执行）
3. Kafka创建主题的实质性动作是交由控制器异步去完成的

### 2.3 主题查看
list和describe指令可以用来方便地查看主题信息。

```bash
# 查看所有主题
bin/kafka-topics.sh --zookeeper node01:2181 --list

# 查看指定主题信息
bin/kafka-topics.sh --zookeeper node01:2181 --describe --topic t_cdr
```

describe 指令的 under-replicated-partitions和unavailable-partitions参数都可以找出有问题的分区。

通过 under-replicated-partitions 参数可以找出所有包含失效副本的分区。包含失效副本的分区可能正在进行同步操作，也有可能同步发生异常，此时分区的ISR集合小于 AR 集合。对于通过该参数查询到的分区要重点监控，因为这很可能意味着集群中的某个broker已经失效或同步效率降低等。

通过 unavailable-partitions 参数可以查看主题中没有 leader 副本的分区，这些分区已经处于离线状态，对于外界的生产者和消费者来说处于不可用的状态。

### 2.4 修改主题
alter指令可以修改主题的配置和分区数。

#### 增加分区数

```bash
bin/kafka-topics.sh --zookeeper node01:2181  --alter --topic t_cdr --partitions 10
```

增加分区数，根据key计算分区的行为就会受到影响。如此还会影响既定消息的顺序，对于基于key计算的主题而言，建议在一开始就设置好分区数量，避免以后对其进行调整。

#### 减少分区数
目前Kafka只支持增加分区数而不支持减少分区数。为什么不支持与实现复杂度和语义保证有关。

比如删除的分区中的消息该如何处理？
1. 如果随着分区一起消失则消息的可靠性得不到保障；如果需要保留则又需要考虑如何保留
2. 直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于Spark、Flink这类需要消息时间戳（事件时间）的组件将会受到影响
3. 如果分散插入现有的分区，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障？与此同时，顺序性问题、事务性问题，以及分区和副本的状态机切换问题都是不得不面对

#### 更改配置
更改配置，使用的是与 create 相同的 --config 参数，还可以通过 --delete-config 参数来删除之前覆盖的配置，使其恢复原有的默认值。

使用kafka-topics.sh脚本的alter指令来变更主题配置的功能已经过时（deprecated），将在未来的版本中删除，推荐使用kafka-configs.sh脚本来实现相关功能。

### 2.5 删除主题
delete 指令用来删除主题。必须将delete.topic.enable参数配置为true才能够删除主题，这个参数的默认值就是true，如果配置为false，那么删除主题的操作将会被忽略。在实际生产环境中，建议将这个参数的值设置为true。

内部主题 __consumer_offsets和__transaction_state 是无法被删除的。

#### 主题删除时的 Zookeeper 操作
使用kafka-topics.sh脚本删除主题的行为本质上只是在ZooKeeper中的 **/admin/delete_topics** 路径下创建一个与待删除主题同名的节点，以此标记该主题为待删除的状态。与创建主题相同的是，真正删除主题的动作也是由Kafka的控制器负责完成的。

### 2.6 配置管理
kafka-configs.sh 脚本是专门用来对配置进行操作。其包含变更配置alter和查看配置describe这两种指令类型。

kafka-configs.sh脚本不仅可以支持操作主题相关的配置，还可以支持操作broker、用户和客户端这3个类型的配置。

kafka-configs.sh
- 操作对象指定:
    - entity-type: 指定操作配置的类型，可选值包括 topics、brokers、clients和users
    - entity-name: 指定操作配置的名称，不指定，会查看 entity-type 的所有配置
- alter: 变更指令
    - add-config: 实现配置增、改
    - delete-config: 实现配置删除，即恢复默认配置

```bash
bin/kafka-configs.sh --zookeeper localhost:2181/kafkacluster --alter --entity-type topics --entity-name topicName  --add-config 'max.message.bytes=50000000' --add-config 'flush.messages=50000'

bin/kafka-configs.sh --zookeeper localhost:2181/kafkacluster --entity-type topics --entity-name topicName --describe

```

#### 配置更改时的 Zookeeper 操作
使用kafka-configs.sh脚本来变更（alter）配置时，会在ZooKeeper中创建一个命名形式为`/config/<entity-type>/<entity-name>`的节点，，并将变更的配置写入这个节点。

变更配置时还会在ZooKeeper中的`/config/changes/`节点下创建一个以`config_change_`为前缀的持久顺序节点（PERSISTENT_SEQUENTIAL），节点命名形式可以归纳为`/config/changes/config_change_<seqNo>` seqNo是一个单调递增的10位数字的字符串，不足位则用0补齐。

查看（describe）配置时，就是从`/config/<entity-type>/<entity-name>` 节点中获取相应的数据内容。


### 2.7 主题端配置参数
与主题相关的所有配置参数在 broker 层面都有对应参数。如果没有修改过主题的任何配置参数，那么就会使用broker端的对应参数作为其默认值。

|主题端参数|描述|对应的broker端参数|
|:---|:---|:---|
|cleanup.policy	|日志压缩策略。默认值为delete，还可以配置为compact|	log.cleanup.policy|
|compression.type	|消息的压缩类型。默认值是producer，表示保留生产者中所使用的原始压缩类型。还可以配置为uncompressed、snappy、lz4、gzip	|compression.type|
|delete.retention.ms	|被标识为删除的数据能够保留多久。默认值是86400000，即1天|	log.clear.delete.retention.ms|
|file.delete.delay.ms	|清理文件之前可以等待多长时间，默认值是60000，即1分钟|	log.segment.delete.delay.ms|
|flush.messges	|需要收集多少消息才会将它们强制刷新到磁盘，默认值是Long.MAX_VALUE,即让操作系统来决定。建议不要修改此参数的默认值|	log.flush.interval.messges|
|flush.ms	|需要等待多久才会将消息强制刷新到磁盘，默认值是Long.MAX_VALUE,即让操作系统来决定。建议不要修改此参数的默认值|	log.flush.interval.ms|
|follower.replication.throttled.replicas	|用来配置被限制速率的主题所对应的follower副本列表|	follower.replication.throttled.replicas|
|index.interval.bytes	|用来控制添加索引项的频率。每超过这个参数所设置的消息字节数时就可以添加一个新的索引项，默认值是4096|	log.index.interval.bytes|
|leader.replication.throttled.replicas	|用来配置被限制速率的主题所对应的leader副本列表|	leader.replication.throttled.replicas|
|max.message.byte	|消息的最大字节数，默认值是1000012|	max.message.byte|
|message.format.version	|消息格式的版本，默认值为2.0-IV1|	log.message.format.version|
|message.timestamp.difference.max.ms	|消息中自带的时间戳与broker收到消息时的时间戳之间的最大差值，默认值为Long.MAX_VALUE。此参数只有在message.timestamp.type参数设置为CreteTime时才有效|	log.message.timestamp.difference.max.ms|
|message.timestamp.type	|消息的时间戳类型。默认值是CreteTime，还可以设置为LogAppendTime|	log.message.timestamp.type|
|min.cleanable.dirty.ratio	|日志清理时的最小污浊率，默认值是0.5|	log.cleaner.min.cleanable.ratio|
|min.compaction.lag.ms	|日志再被清理前的最小保留时间，默认值为0|	log.cleaner.min.compaction.lag.ms|
|min.insync.replicas	|分区ISR集合中至少有多少个副本，默认值为1|	min.insync.replicas|
|preallocate	|在创建日志分段的时候是否要预分配空间，默认值为false|	log.preallocate|
|retention.bytes	|分区中所能保留的消息总量，默认值为-1，即没有限制|	log.retention.bytes|
|retention.ms	|使用delete的日志清理策略时消息能够保留多长时间，默认值为604800000，即7天。如果设置为-1，则表示没有限制|	log.retention.ms|
|segment.bytes	|日志分段的最大值，默认值为1073741824，即1GB|	log.segment.bytes|
|segment.index.bytes	|日志分段索引的最大值，默认值为10485760，即10MB|	log.index.size.max.bytes|
|segment.jitter.ms	|滚动日志分段时，在segment.ms的基础之上增加的随机数，默认为0|	log.roll.jitter.ms|
|segment.ms	|最多多久滚动一次日志分段，默认值为604800000，即7天|	log.roll.ms|
|unclean.leader.election.enable	|是否可以从非ISR集合中选举leader副本，默认值为false，如果设置为true，则可能造成数据丢失|	unclean.leader.election.enable|

## 3. KafkaAdminClient

## 4. 分区的管理
分区相关的知识和操作，包括优先副本的选举、分区重分配、复制限流、修改副本因子等内容。

kafka 分区副本和节点有如下几个概念:
1. leader 节点: 将leader副本所在的broker节点叫作分区的leader节点
2. follower节点: follower副本所在的broker节点
3. 优先副本（preferred replica）:指在 AR 集合列表中的第一个副本，理想情况下，优先副本就是该分区的leader副本

分区使用多副本机制来提升可靠性，但只有leader副本对外提供读写服务，而follower副本只负责在内部进行消息的同步。如果一个分区的leader副本不可用，此时Kafka就从剩余的follower副本中挑选一个新的leader副本来继续对外提供服务。

### 4.1 kafka 的负载均衡
kafka 的负载均衡与集群中的分区分配均衡、leader 分配均衡，以及每个 leader 分区的负载有关。由于 Kafka 集群的 broker 节点不可避免地会遇到宕机或崩溃从而导致 kafka 失衡，因此需要自动平衡功能。

kafka 通过确保所有主题的优先副本在Kafka集群中均匀分布来保证 kafka 的负载均衡。所谓的优先副本的选举是指通过一定的方式促使优先副本选举为leader副本，以此来促进集群的负载均衡。但本质上是不够，我们需要其他的检测手段做进一步权衡。


### 4.2 kafka 自动平衡
broker 端参数 auto.leader.rebalance.enable，用于控制是否启用kafka 自动平衡功能，默认为 True 启用。如果开启分区自动平衡的功能，则 Kafka 的控制器会启动一个定时任务，这个定时任务会轮询所有的 broker节点，计算每个broker节点的分区不平衡率（broker中的不平衡率=非优先副本的leader个数/分区总数）是否超过leader.imbalance.per.broker.percentage参数配置的比值，默认值为 10%，如果超过设定的比值则会自动执行优先副本的选举动作以求分区平衡。执行周期由参数leader.imbalance.check.interval.seconds控制，默认值为300秒，即5分钟。

不过在生产环境中不建议将auto.leader.rebalance.enable设置为默认的true。因为自动均衡会引起客户端一定时间的zuse，可能在业务关键时期造成重大影响，而且是非预期不可控的。

### 4.3 手动均衡
`kafka-perferred-replica-election.sh` 脚本提供了对分区leader副本进行重新平衡的功能。

### 4.4 优先副本选举
在优先副本的选举过程中，具体的元数据信息会被存入 ZooKeeper的/admin/preferred_replica_election节点，如果这些数据超过了ZooKeeper节点所允许的大小，那么选举就会失败。默认情况下ZooKeeper所允许的节点数据大小为1MB。生产环境中一般分批、手动地执行优先副本的选举操作。同时，优先副本的选举操作也要注意避开业务高峰期，以免带来性能方面的负面影响。

## 5. 分区重分配
当集群中的一个节点突然宕机下线时，kafka 会自动对此节点上的 leader 副本转交到集群的其他follower副本中。但 Kafka 并不会将这些失效的分区副本自动地迁移到集群中剩余的可用broker节点上，因此需要手动进行分区副本的迁移。

当集群中新增broker节点时，只有新创建的主题分区才有可能被分配到这个节点上，而之前的主题分区并不会自动分配到新加入的节点中。

为了解决上述问题，需要让分区副本再次进行合理的分配，也就是所谓的分区重分配。Kafka提供了 `kafka-reassign-partitions.sh` 脚本来执行分区重分配的工作，它可以在集群扩容、broker节点失效的场景下对分区进行迁移。优先副本选举就属于分区重分配。

### 5.1 分区重分配的基本原理
分区重分配的基本原理是先通过控制器为每个分区添加新副本（增加副本因子），新的副本将从分区的leader副本那里复制。在复制完成之后，控制器将旧副本从副本清单里移除（恢复为原先的副本因子数）。

分区重分配对集群的性能有很大的影响，需要占用额外的资源，比如网络和磁盘。在实际操作中，我们将降低重分配的粒度，分成多个小批次来执行，以此来将负面的影响降到最低，这一点和优先副本的选举有异曲同工之妙。
还需要注意的是，如果要将某个broker下线，那么在执行分区重分配动作之前最好先关闭或重启broker。这样这个broker就不再是任何分区的leader节点了，它的分区就可以被分配给集群中的其他broker。这样可以减少broker间的流量复制，以此提升重分配的性能，以及减少对集群的影响。

## 6. 复制限流
分区重分配本质在于数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本来达到最终的目的。数据复制会占用额外的资源，这时就需要有一个限流的机制，可以对副本间的复制流量加以限制来保证重分配期间整体服务不会受太大的影响。

副本间的复制限流有两种实现方式：kafka-config.sh脚本和kafka-reassign-partitions.sh脚本。

### 6.1 kafka-configs.sh
kafka-config.sh脚本主要以动态配置的方式来达到限流的目的，在broker级别有两个与复制限流相关的配置参数：`follower.replication.throttled.rate`和`leader.replication.throttled.rate`，前者用于设置follower副本复制的速度，后者用于设置leader副本传输的速度，它们的单位都是B/s。

在主题级别也有两个相关的参数来限制复制的速度：`leader.replication.throttled.replicas` 和 `follower.replication.throttled.replicas`，它们分别用来配置被限制速度的主题所对应的leader副本列表和follower副本列表。

### 6.2 kafka-reassign-partitions.sh
kafka-reassign-partitions.sh脚本本身也提供了限流的功能。kafka-reassign-partitions.sh脚本提供的限流功能背后的实现原理就是配置与限流相关的那4个参数而已，没有什么太大的差别。

不过使用 kafka-config.sh 脚本的方式来实现复制限流的功能比较烦琐，并且在手动配置限流副本列表时也比较容易出错，推荐大家使用kafka-reassign-partitions.sh脚本配合throttle参数的方式，方便快捷且不容易出错。

kafka-reassign-partition.sh 还可以实现修改副本因子的功能。

## 7. 分区数选择
一味增加分区数并不能使吞吐量一直得到提升，并且如果分区数超过默认的配置值，还会引起kafka 奔溃。原因是 kafka 打开的文件描述符超过了系统配置的上线。对于线上环境，将文件描述符调至最大 65536 足以应对大多数情况。

文件描述符等资源限制可在 /etc/security/limits.conf 配置。也可以在/etc/profile 中通过 ulimit 命令配置。

分区数不是越多越好，大量分区会导致下面这些问题:
1. 分区进行 leader 角色切换的过程会变得不可用，如果集群某个 broker 节点宕机，那么会有大量分区同时进行 leader 角色切换，就会耗费可观的时间
2. 让 kafka 启动和关闭变得更慢
3. 增加日志清理的耗时
