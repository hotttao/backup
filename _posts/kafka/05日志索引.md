---
title: 1.5 日志索引
date: 2020-04-05
categories:
    - 存储
tags:
    - Kafka
---

本节我们来介绍 kafka 日志和索引相关部分内容，包括 kafka 日志索引的目录分布，日志清理和磁盘存储。
<!-- more -->

## 1. 文件目录布局
Kafka 中的消息是以主题为基本单位进行归类的，各个主题在逻辑上相互独立，从主题开始以此依次向下分为:
1. 一个或多个分区，分区是逻辑上的概念
2. 每个分区对应多个副本
3. 一个副本对应一个日志（Log）
4. 为了防止 Log 过大，Kafka 将 Log 切分为多个 LogSegment 日志分段

![kafka_log_dir](/images/kafka/kafka_log_dir.png)

上面是 kafka 日志在磁盘上的分布图，其中
1. 当一个Kafka服务第一次启动的时候，默认的根目录下就会创建以下5个文件：
    - log-start-offset-checkpoint
    - cleaner-offset-checkpoint: 
    - recovery-point-offset-checkpoint: 表示已经刷写到磁盘的记录，recoveryPoint: 以下的数据都是已经刷到磁盘上的了
    - replication-offset-checkpoint: 用来存储每个replica的 HW 高水位
    - meta.properties: broker.id 信息
1. Log 即每个分区副本对应了一个命名形式为＜topic＞-＜partition＞的文件夹。
2. 每个LogSegment 对应于磁盘上的一个日志文件和两个索引文件，以及可能的其他文件
    - 日志文件（以“.log”为文件后缀）
    - 偏移量索引文件（以“.index”为文件后缀）
    - 时间戳索引文件（以“.timeindex”为文件后缀）
    - 还可能包含
        - .deleted，.cleaned，.swap等临时文件
        - .snapshot，.txnindex(事务索引文件)，leader-epoch-checkpoint 等文件
3. 日志写入: 
    - 向Log 中追加消息时是顺序写入的，只有最后一个 LogSegment 才能执行写入操作
    - 最后一个 LogSegment 称为“activeSegment”，即表示当前活跃的日志分段。
    - 在创建主题的时候，如果当前 broker中不止配置了一个根目录，那么会挑选分区数最少的那个根目录来完成本次创建任务
4. 日志索引命名:
    - 每个 LogSegment 都有一个基准偏移量 baseOffset，用来表示当前 LogSegment中第一条消息的offset
    - 偏移量是一个64位的长整型数，日志文件和两个索引文件都是根据基准偏移量（baseOffset）命名的，名称固定为20位数字
    - Kafka 的每个日志对象中使用了ConcurrentSkipListMap来保存各个日志分段，每个日志分段的baseOffset作为key，这样可以根据指定偏移量来快速定位到消息所在的日志分段。
5. 内部主题 __consumer_offsets：
    - 消费者提交的位移是保存在 Kafka 内部的主题__consumer_offsets中的
    - 初始情况下这个主题并不存在，当第一次有消费者消费消息时会自动创建这个主题。

### 1.1 日志分段
日志分段文件达到一定的条件时需要进行切分，那么其对应的索引文件也需要进行切分。日志分段文件切分包含以下几个条件，满足其一即可。
1. 当前日志分段文件的大小超过了 broker 端参数 log.segment.bytes 配置的值。log.segment.bytes参数的默认值为1073741824，即1GB。
2. 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于 log.roll.ms或log.roll.hours参数配置的值。如果同时配置了log.roll.ms和log.roll.hours参数，那么log.roll.ms的优先级高。默认情况下，只配置了log.roll.hours参数，其值为168，即7天。
3. 偏移量索引文件或时间戳索引文件的大小达到broker端参数log.index.size.max.bytes配置的值。log.index.size.max.bytes的默认值为10485760，即10MB
4. 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于Integer.MAX_VALUE，即要追加的消息的偏移量不能转变为相对偏移量（offset-baseOffset＞Integer.MAX_VALUE）

对非当前活跃的日志分段而言，其对应的索引文件内容已经固定而不需要再写入索引项，所以会被设定为只读。而对当前活跃的日志分段（activeSegment）而言，索引文件还会追加更多的索引项，所以被设定为可读写。

在索引文件切分的时候，Kafka 会关闭当前正在写入的索引文件并置为只读模式，同时以可读写的模式创建新的索引文件，索引文件的大小由broker端参数 log.index.size.max.bytes 配置。Kafka 在创建索引文件的时候会为其预分配log.index.size.max.bytes 大小的空间，注意这一点与日志分段文件不同，只有当索引文件进行切分的时候，Kafka 才会把该索引文件裁剪到实际的数据大小。也就是说，与当前活跃的日志分段对应的索引文件的大小固定为 log.index.size.max.bytes，而其余日志分段对应的索引文件的大小为实际的占用空间。


## 2. 日志索引
kafka 日志的内容我们在上一节 kafka 消息格式已经详细介绍过了。接下来我们来看看，kafka 的两个索引文件: 
1. 偏移量索引
2. 时间戳索引

### 2.1 kafka 索引简介
偏移量索引文件用来建立消息偏移量（offset）到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置；时间戳索引文件则根据指定的时间戳（timestamp）来查找对应的偏移量信息。

Kafka 中的索引文件以稀疏索引（sparse index）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量（由 broker 端参数 log.index.interval.bytes指定，默认值为4096，即4KB）的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小log.index.interval.bytes的值，对应地可以增加或缩小索引项的密度。

稀疏索引通过MappedByteBuffer将索引文件映射到内存中，以加快索引的查询速度。偏移量索引文件中的偏移量是单调递增的，查询指定偏移量时，使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量。时间戳索引文件中的时间戳也保持严格的单调递增，查询指定时间戳时，也根据二分查找法来查找不大于该时间戳的最大偏移量，至于要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位。稀疏索引的方式是在磁盘空间、内存空间、查找时间等多方面之间的一个折中。

### 2.2 偏移量索引
```bash
relative Offset| position
    32         |    32 
```
偏移量索引项的格式如上所示。每个索引项占用8个字节，分为两个部分。
1. relativeOffset：
    - 相对偏移量，表示消息相对于baseOffset 的偏移量，占用4 个字节，当前索引文件的文件名即为baseOffset的值
    - 消息的偏移量（offset）占用8个字节，也可以称为绝对偏移量
2. position：物理地址，也就是消息在日志分段文件中对应的物理位置，占用4个字节

Kafka 强制要求索引文件大小必须是索引项大小的整数倍，对偏移量索引文件而言，必须为8的整数倍。如果broker端参数log.index.size.max.bytes配置为67，那么Kafka在内部会将其转换为64，即不大于67，并且满足为8的整数倍的条件。

### 1.2 时间戳索引
```bash
timestamp      | relative Offset
    32         |    32 
```

每个索引项占用12个字节，分为两个部分。
1. timestamp：当前日志分段最大的时间戳
2. relativeOffset：时间戳所对应的消息的相对偏移量

每个追加的时间戳索引项中的 timestamp 必须大于之前追加的索引项的 timestamp，否则不予追加。如果 broker 端参数 log.message.timestamp.type设置为LogAppendTime，那么消息的时间戳必定能够保持单调递增；相反，如果是 CreateTime 类型则无法保证。生产者可以使用类似 ProducerRecord（String topic，Integer partition，Long timestamp，K key，V value）的方法来指定时间戳的值。

即使生产者客户端采用自动插入的时间戳也无法保证时间戳能够单调递增，如果两个不同时钟的生产者同时往一个分区中插入消息，那么也会造成当前分区的时间戳乱序。

与偏移量索引文件相似，时间戳索引文件大小必须是索引项大小（12B）的整数倍，如果不满足条件也会进行裁剪。同样假设broker端参数log.index.size.max.bytes配置为67，那么对应于时间戳索引文件，Kafka在内部会将其转换为60。

我们已经知道每当写入一定量的消息时，就会在偏移量索引文件和时间戳索引文件中分别增加一个偏移量索引项和时间戳索引项。两个文件增加索引项的操作是同时进行的，但并不意味着偏移量索引中的relativeOffset和时间戳索引项中的relativeOffset是同一个值。

#### 查找步骤
入下图所示查找 targetTimeStamp=1526384718288开始的消息，分为如下几个步骤:
1. 将targetTimeStamp和每个日志分段中的最大时间戳largestTimeStamp逐一对比，直到找到不小于 targetTimeStamp 的 largestTimeStamp 所对应的日志分段。
2. 日志分段中的largestTimeStamp的计算是先查询该日志分段所对应的时间戳索引文件，找到最后一条索引项，若最后一条索引项的时间戳字段值大于0，则取其值，否则取该日志分段的最近修改时间。
3. 找到相应的日志分段之后，在时间戳索引文件中使用二分查找算法查找到不大于targetTimeStamp的最大索引项，即[1526384718283，28]，如此便找到了一个相对偏移量28
4. 在偏移量索引文件中使用二分算法查找到不大于28的最大索引项，即[26，838]
5. 从步骤1中找到日志分段文件中的838的物理位置开始查找不小于targetTimeStamp的消息


## 3. 日志清理
### 3.1 日志删除

### 3.2 日志压缩


## 4. 磁盘存储
