---
title: 6 日志存储
date: 2020-04-06
categories:
    - 存储
tags:
    - Kafka
---

本节我们来介绍 kafka ISR 同步(失效)副本与消息可靠性相关的问题。
<!-- more -->


## 1. 文件目录布局
Kafka 中的消息是以主题为基本单位进行归类的，各个主题在逻辑上相互独立，从主题开始以此依次向下分为:
1. 一个或多个分区，分区是逻辑上的概念
2. 每个分区对应多个副本
3. 一个副本对应一个日志（Log）
4. 为了防止 Log 过大，Kafka 将 Log 切分为多个 LogSegment 日志分段

![kafka_log_dir](/images/kafka/kafka_log_dir.png)

上面是 kafka 日志在磁盘上的分布图，其中
1. 当一个Kafka服务第一次启动的时候，默认的根目录下就会创建以下5个文件：
    - log-start-offset-checkpoint
    - cleaner-offset-checkpoint: 
    - recovery-point-offset-checkpoint: 表示已经刷写到磁盘的记录，recoveryPoint: 以下的数据都是已经刷到磁盘上的了
    - replication-offset-checkpoint: 用来存储每个replica的 HW 高水位
    - meta.properties: broker.id 信息
1. Log 即每个分区副本对应了一个命名形式为＜topic＞-＜partition＞的文件夹。
2. 每个LogSegment 对应于磁盘上的一个日志文件和两个索引文件，以及可能的其他文件
    - 日志文件（以“.log”为文件后缀）
    - 偏移量索引文件（以“.index”为文件后缀）
    - 时间戳索引文件（以“.timeindex”为文件后缀）
    - 还可能包含
        - .deleted，.cleaned，.swap等临时文件
        - .snapshot，.txnindex(事务索引文件)，leader-epoch-checkpoint 等文件
3. 日志写入: 
    - 向Log 中追加消息时是顺序写入的，只有最后一个 LogSegment 才能执行写入操作
    - 最后一个 LogSegment 称为“activeSegment”，即表示当前活跃的日志分段。
    - 在创建主题的时候，如果当前 broker中不止配置了一个根目录，那么会挑选分区数最少的那个根目录来完成本次创建任务
4. 日志索引命名:
    - 每个 LogSegment 都有一个基准偏移量 baseOffset，用来表示当前 LogSegment中第一条消息的offset
    - 偏移量是一个64位的长整型数，日志文件和两个索引文件都是根据基准偏移量（baseOffset）命名的，名称固定为20位数字
    - Kafka 的每个日志对象中使用了ConcurrentSkipListMap来保存各个日志分段，每个日志分段的baseOffset作为key，这样可以根据指定偏移量来快速定位到消息所在的日志分段。
5. 内部主题 __consumer_offsets：
    - 消费者提交的位移是保存在 Kafka 内部的主题__consumer_offsets中的
    - 初始情况下这个主题并不存在，当第一次有消费者消费消息时会自动创建这个主题。

### 1.1 日志分段
日志分段文件达到一定的条件时需要进行切分，那么其对应的索引文件也需要进行切分。日志分段文件切分包含以下几个条件，满足其一即可。
1. 当前日志分段文件的大小超过了 broker 端参数 log.segment.bytes 配置的值。log.segment.bytes参数的默认值为1073741824，即1GB。
2. 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于 log.roll.ms或log.roll.hours参数配置的值。如果同时配置了log.roll.ms和log.roll.hours参数，那么log.roll.ms的优先级高。默认情况下，只配置了log.roll.hours参数，其值为168，即7天。
3. 偏移量索引文件或时间戳索引文件的大小达到broker端参数log.index.size.max.bytes配置的值。log.index.size.max.bytes的默认值为10485760，即10MB
4. 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于Integer.MAX_VALUE，即要追加的消息的偏移量不能转变为相对偏移量（offset-baseOffset＞Integer.MAX_VALUE）

对非当前活跃的日志分段而言，其对应的索引文件内容已经固定而不需要再写入索引项，所以会被设定为只读。而对当前活跃的日志分段（activeSegment）而言，索引文件还会追加更多的索引项，所以被设定为可读写。

在索引文件切分的时候，Kafka 会关闭当前正在写入的索引文件并置为只读模式，同时以可读写的模式创建新的索引文件，索引文件的大小由broker端参数 log.index.size.max.bytes 配置。Kafka 在创建索引文件的时候会为其预分配log.index.size.max.bytes 大小的空间，注意这一点与日志分段文件不同，只有当索引文件进行切分的时候，Kafka 才会把该索引文件裁剪到实际的数据大小。也就是说，与当前活跃的日志分段对应的索引文件的大小固定为 log.index.size.max.bytes，而其余日志分段对应的索引文件的大小为实际的占用空间。


## 2. 日志索引
kafka 日志的内容我们在上一节 kafka 消息格式已经详细介绍过了。接下来我们来看看，kafka 的两个索引文件: 
1. 偏移量索引
2. 时间戳索引

### 2.1 kafka 索引简介
偏移量索引文件用来建立消息偏移量（offset）到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置；时间戳索引文件则根据指定的时间戳（timestamp）来查找对应的偏移量信息。

Kafka 中的索引文件以稀疏索引（sparse index）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量（由 broker 端参数 log.index.interval.bytes指定，默认值为4096，即4KB）的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小log.index.interval.bytes的值，对应地可以增加或缩小索引项的密度。

稀疏索引通过MappedByteBuffer将索引文件映射到内存中，以加快索引的查询速度。偏移量索引文件中的偏移量是单调递增的，查询指定偏移量时，使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量。时间戳索引文件中的时间戳也保持严格的单调递增，查询指定时间戳时，也根据二分查找法来查找不大于该时间戳的最大偏移量，至于要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位。稀疏索引的方式是在磁盘空间、内存空间、查找时间等多方面之间的一个折中。

### 2.2 偏移量索引
```bash
relative Offset| position
    32         |    32 
```
偏移量索引项的格式如上所示。每个索引项占用8个字节，分为两个部分。
1. relativeOffset：
    - 相对偏移量，表示消息相对于baseOffset 的偏移量，占用4 个字节，当前索引文件的文件名即为baseOffset的值
    - 消息的偏移量（offset）占用8个字节，也可以称为绝对偏移量
2. position：物理地址，也就是消息在日志分段文件中对应的物理位置，占用4个字节

Kafka 强制要求索引文件大小必须是索引项大小的整数倍，对偏移量索引文件而言，必须为8的整数倍。如果broker端参数log.index.size.max.bytes配置为67，那么Kafka在内部会将其转换为64，即不大于67，并且满足为8的整数倍的条件。

### 1.2 时间戳索引
```bash
timestamp      | relative Offset
    32         |    32 
```

每个索引项占用12个字节，分为两个部分。
1. timestamp：当前日志分段最大的时间戳
2. relativeOffset：时间戳所对应的消息的相对偏移量

每个追加的时间戳索引项中的 timestamp 必须大于之前追加的索引项的 timestamp，否则不予追加。如果 broker 端参数 log.message.timestamp.type设置为LogAppendTime，那么消息的时间戳必定能够保持单调递增；相反，如果是 CreateTime 类型则无法保证。生产者可以使用类似 ProducerRecord（String topic，Integer partition，Long timestamp，K key，V value）的方法来指定时间戳的值。

即使生产者客户端采用自动插入的时间戳也无法保证时间戳能够单调递增，如果两个不同时钟的生产者同时往一个分区中插入消息，那么也会造成当前分区的时间戳乱序。

与偏移量索引文件相似，时间戳索引文件大小必须是索引项大小（12B）的整数倍，如果不满足条件也会进行裁剪。同样假设broker端参数log.index.size.max.bytes配置为67，那么对应于时间戳索引文件，Kafka在内部会将其转换为60。

我们已经知道每当写入一定量的消息时，就会在偏移量索引文件和时间戳索引文件中分别增加一个偏移量索引项和时间戳索引项。两个文件增加索引项的操作是同时进行的，但并不意味着偏移量索引中的relativeOffset和时间戳索引项中的relativeOffset是同一个值。

需要注意的是即便日志索引内的时间戳不是单调递增的，也不会影响日志查找的准确性，因为每个追加的时间戳索引项中的 timestamp 必须大于之前追加的索引项的 timestamp，这就保证每个时间索引内的时间戳，在日志文件内，位于它之前的日志时间都小于这个时间戳，之后的可能大于也可能小于这个时间戳。这样总是能找到大于该时间戳的所有数据。

#### 查找步骤
![kafka_time_index](/images/kafka/kafka_time_index.png)

如图所示查找 targetTimeStamp=1526384718288开始的消息，分为如下几个步骤:
1. 将targetTimeStamp和每个日志分段中的最大时间戳largestTimeStamp逐一对比，直到找到不小于 targetTimeStamp 的 largestTimeStamp 所对应的日志分段。
2. 日志分段中的largestTimeStamp的计算是先查询该日志分段所对应的时间戳索引文件，找到最后一条索引项，若最后一条索引项的时间戳字段值大于0，则取其值，否则取该日志分段的最近修改时间。
3. 找到相应的日志分段之后，在时间戳索引文件中使用二分查找算法查找到不大于targetTimeStamp的最大索引项，即[1526384718283，28]，如此便找到了一个相对偏移量28
4. 在偏移量索引文件中使用二分算法查找到不大于28的最大索引项，即[26，838]
5. 从步骤1中找到日志分段文件中的838的物理位置开始查找不小于targetTimeStamp的消息


## 3. 日志清理
Kafka提供了两种日志清理策略。
1. 日志删除（Log Retention）：按照一定的保留策略直接删除不符合条件的日志分段
2. 日志压缩（Log Compaction）：针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本

与此相关的 broker 端参数包括:

log.cleanup.policy: 
- 作用: 设置日志清理策略
- 可选值包括:
    - delete: 默认值，采用日志删除的清理策略
    - compact: 采用日志压缩的清理策略，此时还需要将log.cleaner.enable（默认值为true）设定为true
    - delete，compact: 同时支持日志删除和日志压缩两种策略
- 主题相关参数:
    - 日志清理的粒度可以控制到主题级别，比如与log.cleanup.policy 对应的主题级别的参数为 cleanup.policy

log.cleaner.enable
- 作用: 启用日志压缩

### 3.1 日志删除
在Kafka的日志管理器中会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件的日志分段文件，这个周期可以通过broker端参数 log.retention.check.interval.ms 来配置，默认值为 300000 即 5 分钟。

当前日志分段的保留策略有3种：
1. 基于时间的保留策略
2. 基于日志大小的保留策略
3. 基于日志起始偏移量的保留策略

#### 基于时间的保留策略
日志删除任务会检查当前日志文件中是否有保留时间超过设定的阈值（retentionMs）来寻找可删除的日志分段文件集合（deletableSegments）。

retentionMs可以通过broker端以下参数设置:
1. log.retention.hours，优先级最高
2. log.retention.minutes
3. log.retention.ms，优先级最低
4. 默认情况下只配置了log.retention.hours参数，其值为168，默认情况下日志分段文件的保留时间为7天


![delete_by_time](/images/kafka/delete_by_time.png)

删除任务会根据日志分段中最大的时间戳 largestTimeStamp 来查找过期的日志分段，步骤分为:
1. 查询该日志分段所对应的时间戳索引文件，查找时间戳索引文件中最后一条索引项
2. 若最后一条索引项的时间戳字段值大于 0，则取其值，否则设置为最近修改时间lastModifiedTime
3. 使用文件的最后的修改时间是不准确的，因为这些文件的修改时间可能会被认为修改

日志分段删除步骤如下:
1. 如果所有的日志分段都过期，那至少要保证有一个活跃的日志分段，在此种情况下，会先切分出一个新的日志分段作为activeSegment，然后执行删除操作
2. 删除日志分段时，首先会从Log对象中所维护日志分段的跳跃表中移除待删除的日志分段，以保证没有线程对这些日志分段进行读取操作
3. 然后将日志分段所对应的所有文件添加上“.deleted”的后缀（当然也包括对应的索引文件）
4. 最后交由一个以“delete-file”命名的延迟任务来删除这些以“.deleted”为后缀的文件，这个任务的延迟执行时间可以通过file.delete.delay.ms参数来调配，此参数的默认值为60000，即1分钟

#### 基于日志大小
基于日志大小的删除策略通过检查当前日志的大小是否超过设定的阈值（retentionSize）来寻找可删除的日志分段的文件集合（deletableSegments）。
retentionSize 由以下参数控制:

log.retention.bytes
- 作用: 配置Log中所有日志文件的总大小，默认值为-1，表示无穷大

log.segment.bytes:
- 作用: 配置单个日志分段（确切地说应该为.log日志文件）的大小，默认值为1073741824，即1GB。

![delete_by_size](/images/kafka/delete_by_size.png)

查找可删除日志分段集合:
1. 首先计算日志文件的总大小size和retentionSize的差值diff，即计算需要删除的日志总大小
2. 然后从日志文件中的第一个日志分段开始进行查找可删除的日志分段的文件集合
3. 查找出 deletableSegments 之后就执行删除操作，删除操作同上


#### 基于偏移量
一般情况下，日志文件的起始偏移量 logStartOffset 等于第一个日志分段的 baseOffset，但这并不是绝对的，logStartOffset 的值可以通过 DeleteRecordsRequest 请求（比如使用KafkaAdminClient的deleteRecords（）方法、使用kafka-delete-records.sh脚本，具体用法参考9.1.3节）、日志的清理和截断等操作进行修改。

![delete_by_offset](/images/kafka/delete_by_offset.png)

基于日志起始偏移量的保留策略的判断依据是某日志分段的下一个日志分段的起始偏移量baseOffset 是否小于等于logStartOffset。


### 3.2 日志压缩
Log Compaction对于有相同key的不同value值，只保留最后一个版本。如果应用只关心key对应的最新value值，则可以开启Kafka的日志清理功能，Kafka会定期将相同key的消息进行合并，只保留最新的value值。

Log Compaction会生成新的日志分段文件，日志分段中每条消息的物理位置会重新按照新文件来组织。Log Compaction执行过后的偏移量不再是连续的，不过这并不影响日志的查询。

Log Compaction是针对key的，所以在使用时应注意每个消息的key值不为null。Kafka中用于保存消费者消费位移的主题__consumer_offsets使用的就是Log Compaction策略。

#### 压缩方法
kafka 每一个日志目录下都有一个名为 cleaner-offset-checkpoint 的文件，这个文件就是清理检查点文件，用来记录每个主题的每个分区中已清理的偏移量。通过清理检查点文件中的检查点cleaner checkpoint 将日志划分为:
1. 已经清理过的clean部分，消息偏移量是断续递增的
2. 一个还未清理过的 dirty 部分，消息偏移量是逐一递增的
3. 如果客户端总能赶上dirty部分，那么它就能读取日志的所有消息，反之就不可能读到全部的消息。

![log_compaction](/images/kafka/log_compaction.png)
1. firstDirtyOffset（与cleaner checkpoint相等）表示dirty部分的起始偏移量
2. 为了避免当前活跃的日志分段activeSegment成为热点文件，activeSegment 不会参与 Log Compaction 的执行
3. firstUncleanableOffset为dirty部分的截止偏移量，整个dirty部分的偏移量范围为[firstDirtyOffset，firstUncleanableOffset），注意这里是左闭右开区间。
4. Kafka 支持通过参数log.cleaner.min.compaction.lag.ms（默认值为0）来配置消息在被清理前的最小保留时间，默认情况下firstUncleanableOffset等于activeSegment的baseOffset。

#### 压缩策略
每个broker会启动`log.cleaner.thread`（默认值为1）个日志清理线程负责执行清理任务，这些线程会选择“污浊率”最高的日志文件进行清理:
1. cleanBytes 表示clean部分的日志占用大小
2. dirtyBytes 表示dirty部分的日志占用大小
3. 日志的污浊率（dirtyRatio）为：dirtyBytes = dirtyBytes/ (dirtyBytes + cleanBytes)

`log.cleaner.min.cleanable.ratio`（默认值为0.5）来限定可进行清理操作的最小污浊率。

#### 压缩实现
日志压缩是通过 SkimpyOffsetMap 实现的:
1. Kafka中的每个日志清理线程会使用一个名为“ SkimpyOffsetMap ”的对象来构建 key与offset 的映射关系的哈希表
2. 日志清理需要遍历两次日志文件，第一次遍历把每个key的哈希值和最后出现的offset都保存在SkimpyOffsetMap中
3. 第二次遍历会检查每个消息是否符合保留条件，如果符合就保留下来，否则就会被清理

SkimpyOffsetMap使用MD5来计算key的哈希值，使用线性探测解决哈希冲突，通过 broker 端参数 log.cleaner.io.buffer.load.factor（默认值为0.9）来调整负载因子。每个日志清理线程的SkimpyOffsetMap的内存占用大小为log.cleaner.dedupe.buffer.size/log.cleaner.thread，默认值为=128MB/1=128MB。

需要注意的是 SkimpyOffsetMap 中保存的是 key md5 之后的值与 offset 的对应关系。如果遇到两个不同的 key但哈希值相同的情况，那么其中一个key所对应的消息就会丢失。

#### 压缩分组
Kafka 在实际清理过程中并不对单个的日志分段进行单独清理，而是将日志文件中offset从0至firstUncleanableOffset的所有日志分段进行分组，每个日志分段只属于一组，分组策略为：按照日志分段的顺序遍历，每组中日志分段的占用空间大小之和不超过segmentSize（可以通过broker端参数`log.segment.bytes`设置，默认值为1GB），且对应的索引文件占用大小之和不超过 maxIndexSize（可以通过broker 端参数 `log.index.interval.bytes`设置，默认值为10MB）。同一个组的多个日志分段清理过后，只会生成一个新的日志分段。

#### 压缩过程
Log Compaction过程:
1. 首先将每个日志分组中需要保留的消息复制到一个以“.clean”为后缀的临时文件中，此临时文件以当前日志分组中第一个日志分段的文件名命名，例如 00000000000000000000.log.clean。
2. Log Compaction过后将 .clean 的文件修改为 .swap 后缀的文件，例如：00000000000000000000.log.swap
3. 然后删除原本的日志文件，最后才把文件的“.swap”后缀去掉
4. 整个过程中的索引文件的变换也是如此

## 4. 磁盘存储
kafka 高吞吐量依赖以下几个技术:
1. 顺序写: Kafka 在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且也不允许修改已写入的消息
2. 充分利用页缓存: 
    - kafka 写日志只写到文件系统的页缓存中，数据落盘由操作系统刷脏页控制
    - kafka 提供了 log.flush.interval.messages、log.flush.interval.ms 参数用于控制同步刷盘的频率
    - 刷盘任务就应交由操作系统去调配，消息的可靠性应该由多副本机制来保障，而不是由同步刷盘这种严重影响性能的行为来保障
    - 操作系统使用 vm.swappiness 参数用于控制内存的交换倾向，越大表示越倾向于使用 swap 分区来释放内存，swap 分区导致严重性能问题，应极力避免，建议将此参数设置为 1
    - 因为大量使用页缓存，kafka 重启和迭机并不会导致数据丢失，但是主机的迭机有可能导致数据丢失
3. sendfile: 提高数据的网络发送效率

### 4.1 操作系统的脏页控制
Linux 中有如下参数用于控制系统刷脏页
1. vm.dirty_background_ratio: 指定当脏页数量达到系统内存的百分之多少之后就会触发 pdflush/flush/kdmflush 等后台回写进程的运行来处理脏页，一般设置为小于10的值即可，但不建议设置为0
2. vm.dirty_ratio: 指定当脏页数量达到系统内存的百分之多少之后就不得不开始对脏页进行处理，在此过程中，新的 I/O 请求会被阻挡直至所有脏页被冲刷到磁盘中
3. vm.dirty_expire_centisecs
4. vm.dirty_writeback.centisecs

