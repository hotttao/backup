---
title: 1.4 消费者客户端
date: 2020-04-03
categories:
    - 存储
tags:
    - Kafka
---
Kafka 的生产者客户端

<!-- more -->
## 1. 消费者客户端概述
接下来我们将介绍 kafka 消费者客户端，内容包括:
1. 消费者与消费者组
2. 消费者客户端开发，包括
    - 主题订阅
    - 反序列化
    - 消费者拦截器
    - 消息消费和消息确认
    - 再均衡

与生产者客户端一样，消费者客户端也分成两个版本，我们只介绍新版本，并依旧使用 Python 语言来编写示例代码。

## 2. 消费者与消费者组
kafka 通过消费者组（Consumer Group）来同时实现消息传递的两种模式: 负载均衡和扇出。当消息发布到主题后，只会被投递给订阅它的**每个消费组**中的**一个消费者**。消费者组中的每个消费者只能消费所分配到的分区中的消息。换言之，每一个分区只能被一个消费组中的一个消费者所消费。通过消费者客户端参数**partition.assignment.strategy**可以来设置消费者与订阅主题之间的分区分配策略，分区分配策略的细节我们之后在深入学习 kafka 相关原理时会详细讲解。

消费者组是一个逻辑上的概念，每一个消费者只隶属于一个消费组。每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，通过消费者客户端参数**group.id**来配置，默认值为空字符串。

## 2. 消费者客户端开发
一个正常的消费逻辑需要具备以下几个步骤：
1. 配置消费者客户端参数及创建相应的消费者实例。
2. 订阅主题
3. 拉取消息并消费
4. 消息确认，即提交消费位移
5. 关闭消费者实例

```python
from confluent_kafka import Consumer

conf = {'bootstrap.servers': "host1:9092,host2:9092",
        'group.id': "foo",
        'auto.offset.reset': 'smallest'}

consumer = Consumer(conf)

running = True

def basic_consume_loop(consumer, topics):
    try:
        # 订阅主题，一个或多个
        consumer.subscribe(topics)

        while running:
            msg = consumer.poll(timeout=1.0)
            if msg is None: continue

            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    # End of partition event
                    sys.stderr.write('%% %s [%d] reached end at offset %d\n' %
                                     (msg.topic(), msg.partition(), msg.offset()))
                elif msg.error():
                    raise KafkaException(msg.error())
            else:
                msg_process(msg)
    finally:
        # Close down consumer to commit final offsets.
        consumer.close()

def shutdown():
    running = False
```

### 2.1 必要的连接参数
Kafka消费者客户端有四个参数是必填的
1. bootstrap.servers：
    - 作用: 该参数用来指定生产者客户端连接Kafka集群所需的broker地址清单
    - 默认: 默认值为 ""
    - 格式: 具体的内容格式为host1：port1，host2：port2
    - 说明: 不需要指定所有的broker地址，因为消费者会从给定的broker里查找到其他broker的信息
2. group.id:
    - 作用: 消费者隶属的消费者组名称
    - 默认: 默认值为 ""，设置为空，则会报出异常
    - 说明: 需要设置成具有一定的业务意义的名称
3. key.deserializer: 指定键的反序列化器
4. value.deserializer: 指定值的反序列化器
5. client.id:
    - 作用: 设定KafkaConsumer对应的客户端id
    - 默认: 默认值为 ""，非必须参数
    - 说明: 客户端不设置，则KafkaConsumer会自动生成一个非空字符串，内容形式如“consumer-1”

Python kafka 客户端实现与 Java 略有不同，自定义反序列化器是通过Producer子类实现的，还有一些使用特殊序列化协议的序列化/反序列化器。

### 2.2 订阅主题和分区
`consumer.subscribe(topics[, on_assign=None][, on_revoke=None])`
- 作用: 主题订阅
- topics: 
    - 指定订阅的主题，一个或多个
    - 如果前后两次订阅了不同的主题，以最后一次的为准
    - 正则表达式的主题名称需要以 "^" 开头
    - 如果在订阅主题之后，又有人创建了新的主题，并且与正则表达式的主题匹配，消费者可以消费到新添加的主题中的消息
    - 在Kafka 和其他系统之间进行数据复制时，这种正则表达式的方式就显得很常见
- on_assign:
    - 可调用函数，用于在 partition re-assignment 成功后提供自定义偏移量
- on_revoke: 
    - 可调用函数，用于在再均衡开始前，提供对偏移量的处理，并提交至服务端

```Python
# 1. 正则表达式的主题名称
consumer.subscribe(["^my_topic.*", "^another[0-9]-?[a-z]+$", "not_a_regex"])
```

`consumer.assign(partitions)`
- 作用: 直接订阅主题的分区
- partitions: TopicPartition 的 List 指定需要订阅的分区集合

`TopicPartition(topic [, partition][, offset])`
- 作用: 保存主题单个分区的类
- topic: 所属主题
- partition: 分区ID
- offset: 初始分区偏移量

`consumer.assignment()`
- 作用: 返回主题的分区元数据，类型为 TopicPartition 的 List

`consumer.unsubscribe()`
- 作用: 删除当前订阅

subscribe(topics)、正则表达式订阅的方式subscribe(Pattern)和指定分区的订阅方式 assign(TopicPartition)分表代表了三种不同的订阅状态：AUTO_TOPICS、AUTO_PATTERN和USER_ASSIGNED。这三种状态是互斥的，在一个消费者中只能使用其中的一种，否则会报错。

通过 subscribe（）方法订阅主题具有消费者自动再均衡的功能，在多个消费者的情况下可以根据**分区分配策略**来自动分配各个**消费者与分区的关系**。当消费组内的消费者增加或减少时，分区分配关系会自动调整，以实现消费负载均衡及故障自动转移。而通过assign()方法订阅分区时，是不具备消费者自动均衡的功能的。

### 2.3 反序列化

### 2.4 消费者拦截器

## 3. 消息消费
**Kafka中的消费是基于拉模式的**。如示例所示，消费的过程是不断调用 poll() 方法，poll 返回的是所订阅主题(分区)上的一组消息。

`consumer.poll([timeout=None])`
- 作用: 一次消费一个消息
- 返回: Message 或者 None
    - 对于poll（）方法而言，如果某些分区中没有可供消费的消息，那么此分区对应的消息拉取的结果就为空
    - 如果订阅的所有分区中都没有可供消费的消息，那么poll（）方法返回为空的消息集合。
- timeout: 
    - 控制poll 方法的阻塞时间，在消费者的缓冲区里没有可用数据时会发生阻塞
    - timeout的设置取决于应用程序对响应速度的要求，比如需要在多长时间内将控制权移交给执行轮询的应用线程
    - 如果应用线程唯一的工作就是从Kafka中拉取并消费消息，则可以将这个参数设置为最大值Long.MAX_VALUE。

`classconfluent_kafka.Message`
- 作用: 返回的消息包装类

`consumer.consume([num_messages=1][, timeout=-1])`
- 作用: 一次消费多条消息
- 返回: list(Message)
- 参数:
    - num_messages: 一次获取的最大消息数量，默认为 1
    - timeout: 获取消息时的超时时间

到目前为止，可以简单地认为poll（）方法只是拉取一下消息而已，但就其内部逻辑而言并不简单，它涉及消费位移、消费者协调器、组协调器、消费者的选举、分区分配的分发、再均衡的逻辑、心跳等内容，在后面的章节中会循序渐进地介绍这些内容。

### 3.1 位移提交
每个消息在 Kafka 分区中都有一个 offset，相当于唯一ID，表示消息在分区中对应的位置。对于消费者，也有一个offset，消费者使用offset来表示消费到分区中某个消息所在的位置。

在每次调用poll（）方法时，它返回的是还没有被消费过的消息集。要做到这一点，就需要记录上一次消费时的消费位移。保存消费者位移的目的是为了在消费者重启或者再均衡之后，消费者知道从何处开始消费。

在旧消费者客户端中，消费位移是存储在ZooKeeper中的。而在新消费者客户端中，消费位移存储在Kafka内部的主题 **__consumer_offsets** 中。把将消费位移存储起来（持久化）的动作称为“提交”，消费者在消费完消息之后需要执行消费位移的提交。

如下图所示，假设消费者已经消费了 x 位置的消息:
1. 我们称消费者的消费位移为 x，用 lastConsumedOffset 标识
2. 消费者需要提交的消费位移是 x+1，即 position，它表示下一条需要拉取的消息的位置
3. 还有一个committed offset的概念，它表示已经提交过的消费位移

![消费位移](/images/kafka/commit_position.jpg)


位移提交的具体时机很有讲究，这决定了是可能造成重复消费和还是可能造成消息丢失。

位移提交有两种，手动提交和自动提交。自动提交由以下两个参数控制:
1. `enable.auto.commit`: 默认值为 True 表示自动提交
2. `auto.commit.interval.ms`: int 表示自动提交的周期间隔，默认值为 5s

在默认的方式下，消费者每隔5秒会将拉取到的每个分区中最大的消息位移进行提交。自动位移提交的动作是在poll（）方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交，如果可以，那么就会提交上一次轮询的位移。

自动提交消费位移的方式非常简便，但随之而来的是重复消费和消息丢失的问题(注意是都有可能发生，因为消息会缓存在客户端)。与此同时，自动位移提交也无法做到精确的位移管理。因此大多数情况下，我们需要手动位移提交。

手动提交可以细分为同步提交和异步提交。同步异步提交与 commit 方法有关

`comsumer.commit([message=None][, offsets=None][, asynchronous=True])`
- 作用: 提交位移
- 参数:
    - message: 提交位移等于 消息的偏移量 + 1
    - offsets: list(TopicPartition)，主题列表 + 分区 + 提交偏移量
    - asynchronous: 是否异步提交，默认是 True 异步提交
- 注意: 
    - message 与 offset 是互斥的，如果都没有设置，则提交当前批次对应的 position 值
    - 大多数情况下我们是按照分区的粒度划分提交位移的界限，此时需要 offsets 参数

#### 同步位移提交

```python
def consume_loop(consumer, topics):
    try:
        consumer.subscribe(topics)

        msg_count = 0
        while running:
            msg = consumer.poll(timeout=1.0)
            if msg is None: continue

            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    # End of partition event
                    sys.stderr.write('%% %s [%d] reached end at offset %d\n' %
                                     (msg.topic(), msg.partition(), msg.offset()))
                elif msg.error():
                    raise KafkaException(msg.error())
            else:
                msg_process(msg)
                msg_count += 1
                if msg_count % MIN_COMMIT_COUNT == 0:
                    consumer.commit(async=False)
    finally:
        # Close down consumer to commit final offsets.
        consumer.close()
```

#### 异步位移提交
commit_completed 为异步提交设置有一个回调函数，用于处理异步提交失败的情况。我们可以在这个回调函数中进行位移提交的重试。但这样有可能覆盖掉后面发起的位移提交。为此我们可以设置一个递增的序号来维护异步提交的顺序，每次位移提交之后就增加序号相对应的值。在遇到位移提交失败需要重试的时候，可以检查所提交的位移和序号的值的大小，如果前者小于后者，则说明有更大的位移已经提交了，不需要再进行本次重试；如果两者相同，则说明可以进行重试提交。

在一般情况下，位移提交失败的情况很少发生，不重试也没有关系，后面的提交也会有成功的。重试会增加代码逻辑的复杂度，不重试会增加重复消费的概率。如果消费者正常退出或发生再均衡的情况，那么可以在退出或再均衡执行之前使用同步提交的方式做最后的把关。

```python
from confluent_kafka import Consumer

def commit_completed(err, partitions):
    if err:
        print(str(err))
    else:
        print("Committed partition offsets: " + str(partitions))

conf = {'bootstrap.servers': "host1:9092,host2:9092",
        'group.id': "foo",
        'default.topic.config': {'auto.offset.reset': 'smallest'},
        'on_commit': commit_completed}

consumer = Consumer(conf)

def consume_loop(consumer, topics):
    try:
        consumer.subscribe(topics)

        msg_count = 0
        while running:
            msg = consumer.poll(timeout=1.0)
            if msg is None: continue

            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    # End of partition event
                    sys.stderr.write('%% %s [%d] reached end at offset %d\n' %
                                     (msg.topic(), msg.partition(), msg.offset()))
                elif msg.error():
                    raise KafkaException(msg.error())
            else:
                msg_process(msg)
                msg_count += 1
                if msg_count % MIN_COMMIT_COUNT == 0:
                    consumer.commit(async=True)
    finally:
        # Close down consumer to commit final offsets.
        consumer.close()
```

### 3.2 控制或关闭消费
consumer 还提供了了方法用来，暂停和恢复消息拉取，以及最终关闭消费以释放资源。

`consumer.pause(partitions)`
- 作用: 暂停对传入的分区进行消费
- 参数:
    - partitions: list(TopicPartition)，要暂停的主题分区列表

`consumer.esume(partitions)`
- 作用: 恢复对传入的分区的消费
- 参数:
    - partitions: list(TopicPartition)，要暂停的主题分区列表

`consumer.close()`
- 作用:
    - 停止消费
    - 离开消费者群体
    - 提交最终的位移

### 3.3 指定位移消费
在 Kafka 中每当消费者查找不到所记录的消费位移时，就会根据消费者客户端参数 **auto.offset.reset** 的配置来决定从何处开始进行消费：

auto.offset.reset
- 作用: 找不到消费者位移时，配置消费的起点
- 可选值:
    - latest: 表示从分区末尾开始消费消息
    - earliest: 从起始处，也就是0开始消费
    - None: 查到不到消费位移的时候报错
除了查找不到消费位移，位移越界也会触发 auto.offset.reset 参数的执行


## 4. 重要的消费者参数
2. group.id:
    - 作用:
    - 默认:
    - 说明: