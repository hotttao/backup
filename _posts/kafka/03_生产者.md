---
title: 1.3 生产者客户端
date: 2020-04-03
categories:
    - 存储
tags:
    - Kafka
---

<!-- more -->
Kafka 的生产者客户端

## 1. 生产者客户端概述
Kafka 生产者客户端一共有两大版本:
1. Scala 语言的旧版
2. Java 语言的新版

旧版几乎不再使用，我们接下来主要介绍新版 Java 客户端的使用，内容包括:
1. 生产者的客户端开发:
    - 编码步骤
    - 配置参数
    - 消息的发送
    - 序列化
    - 分区器
    - 生产者拦截器
2. 原理:
    - 生产者客户端的整体架构
    - 元数据更新
    - 重要的生产者配置参数

说明: Kafka 支持多语言，书中使用的是 Java，本人不会 Java，这里使用 Python 语言。

## 1. 客户端开发
一个正常的生产逻辑需要具备以下几个步骤：
1. 配置生产者客户端参数及创建相应的生产者实例
2. 构建待发送消息
3. 发送消息
4. 关闭生产者实例

```python
from confluent_kafka import Producer
import socket

conf = {'bootstrap.servers': "host1:9092,host2:9092",
        'client.id': socket.gethostname()}

producer = Producer(conf)
# 1. 同步提交
producer.produce(topic, key="key", value="value")
producer.flush()

# 2.异步提交
def acked(err, msg):
    if err is not None:
        print("Failed to deliver message: %s: %s" % (str(msg), str(err)))
    else
        print("Message produced: %s" % (str(msg)))

producer.produce(topic, key="key", value="value", callback=acked)

# Wait up to 1 second for events. Callbacks will be invoked during
# this method call if the message is acknowledged.
producer.poll(1)
```

### 1.1 消息设置
这里有必要单独说明的是构建的消息对象 ProducerRecord(Java 的客户端里把消息抽象成了一个独立的类，但是在 confluent_kafka 里并没有，这些参数直接放在了 produce 方法中) 

`produce(topic[, value][, key][, partition][, on_delivery][, timestamp][, headers])`
- topic: 消息要发送到的主题
- parition: 消息要发送到的分区
- headers: 消息的头部，用来设定一些与应用相关的信息，如无需要也可以不用设置
- key: 
    - 指定消息的键，用来计算分区号进而可以让消息发往特定的分区
    - 有key的消息还可以支持日志压缩的功能
- value: 消息体，一般不为空，如果为空则表示特定的消息—墓碑消息，
- timestamp: 
    - int 消息的时间戳，默认为当前时间
    - 消息的时间戳一般有CreateTime(消息创建的时间) LogAppendTime(消息追加到日志文件的时间) 两种类型，confluent_kafka 还未找到设置的方式
- on_delivery/callback:
    - 指定消息发送的回调函数

### 1.2 生产者配置参数
实例化生产者时需要配置相应的参数，即上面的 conf 对象，Producer 的 conf 至少需要如下参数:
1. bootstrap.servers：
    - 作用: 该参数用来指定生产者客户端连接Kafka集群所需的broker地址清单
    - 默认: 默认值为 ""
    - 格式: 具体的内容格式为host1：port1，host2：port2
    - 说明: 不需要执行所有的broker地址，因为生产者会从给定的broker里查找到其他broker的信息
2. client.id:
    - 作用: 设定KafkaProducer对应的客户端id
    - 默认: 默认值为""，如果客户端不设置，则KafkaProducer会自动生成一个非空字符串，内容形式如“producer-1”“producer-2”

### 1.3 消息发送
发送消息主要有三种模式：
1. 发后即忘（fire-and-forget）
    - 只管往Kafka中发送消息而并不关心消息是否正确到达
    - 可能会造成消息丢失，性能最好，可靠性最差
2. 同步（sync）
3. 异步（async）

消息在通过send（）方法发往broker的过程中，有可能需要经过拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）的一系列作用之后才能被真正地发往 broker。

### 1.4 序列化
broker 端接收的消息必须以字节数组（byte[]）的形式存在。因此在发往broker之前需要将消息中对应的key和value做相应的序列化操作来转换成字节数组。序列化需要使用序列化器（Serializer）。

### 1.5 分区器
拦截器一般不是必需的，而序列化器是必需的。消息经过序列化之后就需要确定它发往的分区，如果消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。如果消息ProducerRecord中没有指定partition字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。

### 1.6 拦截器
生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。


## 2. 生产者客户端原理
接下来我们将通过了解生产者客户端的整体脉络，以便能更好的使用它。

### 2.1 整体架构
![kafka-producer](/images/kafka/kafka-producer.jpg)

如上图所示，生产者客户端由两个线程协调运行:
1. 主线程: 将消息缓存到消息累加器（RecordAccumulator，也称为消息收集器）中
2. Sender线程: 从RecordAccumulator中获取消息并将其发送到Kafka中

#### RecordAccumulator 
RecordAccumulator 主要用来缓存消息以便 Sender 线程可以批量发送:
1. RecordAccumulator 缓存的大小可以通过生产者客户端参数 **buffer.memory** 配置，默认值为 33554432B，即 32MB
2. 如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这个时候KafkaProducer的send（）方法调用要么被阻塞，要么抛出异常，这个取决于参数max.block.ms的配置，此参数的默认值为60000，即60秒。

RecordAccumulator 由如下几个部分组成:
1. 主线程中发送过来的消息都会被追加到RecordAccumulator的某个双端队列（Deque）中
2. 在 RecordAccumulator 的内部为每个分区都维护了一个双端队列，队列中的内容就是ProducerBatch，即 **Deque＜ProducerBatch＞** 
3. 消息写入缓存时，追加到双端队列的尾部；Sender读取消息时，从双端队列的头部读取
4. 注意 **ProducerBatch不是ProducerRecord** ，ProducerBatch中可以包含一至多个 ProducerRecord。通俗地说，ProducerRecord 是生产者中创建的消息，而 **ProducerBatch是指一个消息批次** ，ProducerRecord会被包含在ProducerBatch中，这样可以使字节的使用更加紧凑。与此同时，将较小的ProducerRecord拼凑成一个较大的ProducerBatch，也可以 **减少网络请求的次数以提升整体的吞吐量** 

ProducerBatch:
1. ProducerBatch和消息的具体格式有关，后面我们会详细介绍 kafka 各个消息的消息格式。如果生产者客户端需要向很多分区发送消息，则可以将buffer.memory如果生产者客户端需要向很多分区发送消息，则可以将buffer.memory参数适当调大以增加整体的吞吐量
2. BufferPool 与 batch.size: 消息在网络上都是以字节（Byte）的形式传输的，在发送之前需要创建一块内存区域来保存对应的消息，这块区域通常由 io.Buffer 创建和释放，为了 io.Buffer 的利用效率可以 BufferPool 对 io.Buffer 进行复用。(Java客户端中)BufferPool只针对特定大小的ByteBuffer进行管理，而其他大小的ByteBuffer不会缓存进BufferPool中，这个特定的大小由 **batch.size** 参数来指定，默认值为16384B，即16KB。
3. 消息的发送也与 batch.size 有关，当一条消息（ProducerRecord）流入RecordAccumulator时，会先寻找与消息分区所对应的双端队列（如果没有则新建），再从这个双端队列的尾部获取一个 ProducerBatch（如果没有则新建），查看 ProducerBatch 中是否还可以写入这个 ProducerRecord，如果可以则写入，如果不可以则需要创建一个新的ProducerBatch。在新建ProducerBatch时评估这条消息的大小是否超过batch.size参数的大小，如果不超过，那么就以 batch.size 参数的大小来创建 ProducerBatch，这样在使用完这段内存区域之后，可以通过BufferPool 的管理来进行复用；如果超过，那么就以评估的大小来创建ProducerBatch，这段内存区域不会被复用。

#### Sender
Sender 的发送过程分为如下步骤:
1. Sender 从 RecordAccumulator 中获取缓存的消息之后，首先会将 **＜分区，Deque＜ProducerBatch＞＞**的保存形式转变成 **＜Node，List＜ ProducerBatch＞** 的形式。因为对于网络连接来说，客户端连接的是具体的 broker，而不关心消息属于哪个分区。
2. **＜Node，List＜ ProducerBatch＞** 进一步被转换为 **＜Node，Request＞**，这样就可以发送 Request。这里的Request是指Kafka的各种协议请求，对于消息发送而言就是指具体的 ProduceRequest。
3. 请求在从Sender线程发往Kafka之前还会保存到 **InFlightRequests** 中，InFlightRequests保存对象的具体形式为 **Map＜NodeId，Deque＜Request＞＞**，的主要作用是缓存了已经发出去但还没有收到响应的请求
4. InFlightRequests还提供了许多管理类的方法。比如通过配置 **max.in.flight.requests.per.connection** 可以限制每个连接最多缓存的请求数，默认值为 5。超过这个值之后就不能继续发送请求，除非缓存的请求收到了响应。通过比较。通过比较Deque＜Request＞的size与这个参数的大小来判断对应的Node中是否已经堆积了很多未响应的消息，如果真是如此，那么说明这个 Node 节点负载较大或网络连接有问题。

InFlightRequests还可以获得leastLoadedNode，即所有Node中负载最小的那一个。这里的负载最小是通过每个Node在InFlightRequests中还未确认的请求决定的，未确认的请求越多则认为负载越大。选择leastLoadedNode发送请求可以使它能够尽快发出，避免因网络拥塞等异常而影响整体的进度。leastLoadedNode的概念可以用于多个应用场合，比如元数据请求、消费者组播协议的交互。

### 2.2 元数据更新
#### 为什么需要元数据
当我们发送消息时，除了主题，通常对其他必要信息一无所知。kafka 将消息发送到指定主题的某个分区的leader 副本之前，需要知道:
1. 主题的分区数量，然后经过计算得出（或者直接指定）目标分区
2. 之后KafkaProducer需要知道目标分区的leader副本所在的broker 节点的地址、端口等信息才能建立连接，最终才能将消息发送到 Kafka

bootstrap.servers 参数只需要配置部分broker节点的地址即可，不需要配置所有broker节点的地址，因为客户端可以自己发现其他broker节点的地址，这一过程也属于元数据相关的更新操作。与此同时，分区数量及leader副本的分布都会动态地变化，客户端也需要动态地捕捉这些变化。

#### 元数据是什么
元数据是指Kafka集群的元数据，这些元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的leader副本分配在哪个节点上，follower副本分配在哪些节点上，哪些副本在AR、ISR等集合中，集群中有哪些节点，控制器节点又是哪一个等信息。

#### 元数据何时更新
当客户端中没有需要使用的元数据信息时，比如没有指定的主题信息，或者超过 **metadata.max.age.ms** 时间没有更新元数据都会引起元数据的更新操作。客户端参数metadata.max.age.ms的默认值为300000，即5分钟。元数据更新过程对外部使用者不可见。

当需要更新元数据时，会先挑选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。更新操作是由Sender线程发起的，在创建完**MetadataRequest** 之后同样会存入InFlightRequests，之后的步骤就和发送消息时的类似。元数据虽然由Sender线程负责更新，但是主线程也需要读取这些信息，这里需要数据同步。

## 3. 重要的生产者客户端参数
生产者客户有很的参数，涉及到消息的顺序性、性能和可靠性，重要的参数列示如下:
1. `bootstrap.servers`：前面已介绍
2. `client.id`: 前面已介绍
3. `acks`: **非常重要**
    - 作用: 指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的
    - 可选值: 字符串类型
        - acks=1
            - 响应时点: 生产者发送消息之后，只要分区的leader副本成功写入消息，那么它就会收到来自服务端的成功响应
            - 丢失可能: 如果消息成功写入 Leader副本，并响应给生产者，在被副本拉取之前，Leader 副本崩溃，则消息丢失。
        - acks=0
            - 响应时点: 生产者发送消息之后不需要等待任何服务端的响应
            - 丢失可能: 如果消息在发送过程中就出现异常，那么消息就会丢失
        - acks=-1或acks=all
            - 响应时点: 生产者在消息发送之后，需要等待ISR中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应
            - 丢失可能: 这并不意味着消息就一定可靠，因为ISR中可能只有leader副本。要获得更高的消息可靠性需要配合 **min.insync.replicas** 等
    - 默认: 默认值 acks=1
    - 说明: 生产者客户端在请求超时或者发生异常时，是需要进行重试的，这样才能保证消息不丢失，但由此也可能就导致了消息重复发送
3. max.request.size: **重要**
    - 作用: 限制生产者客户端能发送的消息的最大值
    - 默认: 默认值为 1048576B，即 1MB
    - 说明: 不建议读者盲目地增大这个参数的配置值。因为这个参数还涉及一些其他参数的联动，比如broker端的**message.max.bytes** 参数。如果配置错误会引起不必要的有异常
3. retries 和 retry.backoff.ms:
    - 作用: 
        - 生产者内部重试的次数和重试间隔
        - 配置这两个参数时，最好先估算一下可能的异常恢复时间，总的重试时间大于这个异常恢复时间，这样才能避免生产者过早地放弃重试。
    - 默认: 
        - retries 默认值为0，表示不重试
        - retry.backoff.ms，默认值为100 
    - 说明: 一些临时性的异常可以通过重试来解决，比如网络抖动、leader副本的选举等，其他异常是不行的，比如配置错误
3. compression.type:
    - 作用: 指定消息的压缩方式
    - 可选值: gzip、snappy、lz4
    - 默认: 默认值为 none，不压缩
    - 说明: 消息压缩是一种使用时间换空间的优化方式，如果对时延有一定的要求，则不推荐对消息进行压缩。
3. connections.max.idle.ms:
    - 作用: 指定在多久之后关闭限制的连接
    - 默认: 默认值是540000（ms），即9分钟
    - 说明:
3. linger.ms:
    - 作用: 指定生产者发送 ProducerBatch 之前等待更多消息（ProducerRecord）加入ProducerBatch 的时间
    - 默认: 默认值为 0
    - 说明: 增大这个参数的值会增加消息的延迟，但是同时能提升一定的吞吐量
3. receive.buffer.bytes:
    - 作用: 设置Socket接收消息缓冲区（SO_RECBUF）的大小
    - 默认: 
        - 默认值为32768（B），即32KB
        - 设置为-1，则使用操作系统的默认值
    - 说明: 如果Producer与Kafka处于不同的机房，则可以适地调大这个参数值
3. send.buffer.bytes: 
    - 作用: 设置Socket发送消息缓冲区（SO_SNDBUF）的大小
    - 默认: 
        - 默认值为131072（B），即128KB
        - 设置为-1，则使用操作系统的默认值
4. request.timeout.ms
    - 作用: 配置 Producer 等待请求的最长时间
    - 默认: 默认值为30000（ms）
    - 说明: 这个参数需要比broker端参数 **replica.lag.time.max.ms** 的值要大，这样可以减少因客户端重试而引起的消息重复的概率。


### 3.1 kafka 消息有序性
Kafka 可以保证同一个分区中的消息是有序的。对于某些应用来说，顺序性非常重要，比如MySQL的binlog传输。消息的有序性需要:
1. 生产者按照一定顺序发送消息，保证消息顺序地写入分区
2. 消费者需要按照同样的顺序消费消息

如果将acks参数配置为非零值，并且max.in.flight.requests.per.connection参数配置为大于 1，那么就有可能出现乱序。因此在需要保证消息顺序时，需要把参数max.in.flight.requests.per.connection配置为1，而不是把acks配置为0。不过这样也会影响整体的吞吐。
