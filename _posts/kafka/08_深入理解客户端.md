---
title: 8 深入理解客户端
date: 2020-04-08
categories:
    - 存储
tags:
    - Kafka
---

从客户端入手，深入地挖掘Kafka的实现原理

<!-- more -->

## 1. 内容概述
本章我们将从客户端的角度入手，同时涉及客户端和服务端的内容，以便深入地挖掘Kafka的实现原理，内容包括:
1. 分区分配策略
2. 消费者协调器和组协调器
3. _consumer_offset

## 2. 分区分配策略
前面我们讲解了消费者和消费组的模型，客户端参数`partition.assignment.strategy`来设置消费者与订阅主题之间的分区分配策略，它如下几个策略:
1. RangeAssignor: 默认策略，值为 org.apache.kafka.clients.consumer.RangeAssignor
2. RoundRobinAssignor 值为 org.apache.kafka.clients.consumer.RoundRobinAssignor
3. StickyAssignor

消费者客户端参数 partition.assignment.strategy可以配置多个分配策略，彼此之间以逗号分隔。

### 2.1 RangeAssignor
RangeAssignor 分配策略的原理是
1. 按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者
3. 对于每一个主题，RangeAssignor策略会将消费组内所有订阅这个主题的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围

假设消费组内有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有3个分区，则RangeAssignor 分区分配结果是

```bash
消费者C0: t0p0, t0p1, t1p0, t1p1
消费者C1: t0p2, t1p2
```

### 2.2 RoundRobinAssignor
RoundRobinAssignor分配策略的原理是将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，然后通过轮询方式逐个将分区依次分配给每个消费者。

如果同一个消费组内所有的消费者的订阅信息都是相同的，那么RoundRobinAssignor分配策略的分区分配会是均匀的。

如果同一个消费组内的消费者订阅的信息是不相同的，那么在执行分区分配的时候就不是完全的轮询分配，有可能导致分区分配得不均匀。如果某个消费者没有订阅消费组内的某个主题，那么在分配分区的时候此消费者将分配不到这个主题的任何分区。

### 2.3 StickyAssignor
引入 StickyAssignor 策略，主要有两个目的:
1. 分区的分配要尽可能均匀。
2. 分区的分配尽可能与上次分配的保持相同。

当两者发生冲突时，第一个目标优先于第二个目标。使用StickyAssignor分配策略的一个优点就是可以使分区重分配具备“黏性”，减少不必要的分区移动（即一个分区剥离之前的消费者，转而分配给另一个新的消费者）。

## 3. 消费者协调器和组协调器
多个消费者之间的分区分配是需要协同的，协调过程由消费者协调器（ConsumerCoordinator）和组协调器（GroupCoordinator）来完成，它们之间使用一套组协调协议进行交互。

新版客户端将全部消费组分成多个子集，每个消费组的子集在服务端对应一个 GroupCoordinator 对其进行管理:
1. GroupCoordinator 是 Kafka 服务端中用于管理消费组的组件
2. 而消费者客户端中的 ConsumerCoordinator 组件负责与 GroupCoordinator进行交互

ConsumerCoordinator与GroupCoordinator之间最重要的职责就是负责执行消费者再均衡的操作，包括前面提及的分区分配的工作也是在再均衡期间完成的。就目前而言，一共有如下几种情形会触发再均衡的操作：
1. 有新的消费者加入消费组。
2. 有消费者宕机下线，这个下线指的是因为各种原因，包括迭机、网络延迟、GC 等导致消费者长时间未向GroupCoordinator发送心跳
3. 有消费者主动退出消费组（发送 LeaveGroupRequest 请求）。比如客户端调用了unsubscrible（）方法取消对某些主题的订阅。
4. 消费组所对应的GroupCoorinator节点发生了变更
5. 消费组内所订阅的任一主题或者主题的分区数量发生变化

## 4. 再均衡原理
我们就以有消费者加入消费组为例来简单介绍一下再均衡的具体内容，消费者、消费组及组协调器之间会经历一下几个阶段:
1. 第一阶段（FIND_COORDINATOR）
    - 目的: 消费者需要确定它所属的消费组对应的GroupCoordinator所在的broker，并创建与该broker相互通信的网络连接
2. 第二阶段（JOIN_GROUP）: 进入加入消费组
3. 第三阶段（SYNC_GROUP）: leader 消费者将分区分配的方案同步给各个消费者
4. 第四阶段（HEARTBEAT）：确定拉取消息的起始位置

### 4.1 FIND_COORDINATOR
如果消费者已经保存了与消费组对应的 GroupCoordinator 节点的信息，并且与它之间的网络连接是正常的，那么就可以进入第二阶段。否则需要向集群中的某个节点发送 FindCoordinatorRequest 请求来查找对应的 GroupCoordinator，这里的“某个节点”并非是集群中的任意节点，而是负载最小的节点。

FindCoordinatorRequest 请求体的结构如下，它只有两个域（Field）：
1. coordinator_key 在这里就是消费组的名称，即 groupId
2. coordinator_type置为0

![FindCoordinatorRequest](/images/kafka/find_coordinator.png)

Kafka 在收到 FindCoordinatorRequest 请求之后，会根据 coordinator_key（也就是groupId）查找对应的GroupCoordinator节点，如果找到对应的GroupCoordinator则会返回其相对应的node_id、host和port信息。

GroupCoordinator的查找大体会经过如下这样一个过程:
1. 先根据消费组groupId的哈希值计算__consumer_offsets中的分区编号
2. 找到对应的__consumer_offsets中的分区之后，再寻找此分区leader副本所在的broker节点，该broker节点即为这个groupId所对应的GroupCoordinator节点

消费者groupId最终的**分区分配方案**及**组内消费者所提交**的消费位移信息都会发送给此分区leader副本所在的broker节点，让此broker节点既扮演GroupCoordinator的角色，又扮演保存分区分配方案和组内消费者位移的角色，可以省去很多不必要的中间轮转所带来的开销。

### 4.2 JOIN_GROUP
**JoinGroupRequest**
消费者会向GroupCoordinator发送 JoinGroupRequest 请求，并处理响应。

![JoinGroupRequest](/images/kafka/join_request.png)

JoinGroupRequest的结构包含多个域：
1. group_id: 
    - 就是消费组的id，通常也表示为groupId。
2. session_timout: 
    - 对应消费端参数 session.timeout.ms，默认值为 10000，即10秒
    - GroupCoordinator超过session_timeout指定的时间内没有收到心跳报文则认为此消费者已经下线
3. rebalance_timeout 
    - 对应消费端参数 max.poll.interval.ms，默认值为300000，即 5 分钟
    - 表示当消费组再平衡的时候，GroupCoordinator 等待各个消费者重新加入的最长等待时间
4. member_id 
    - 表示 GroupCoordinator 分配给消费者的 id 标识
    - 消费者第一次发送JoinGroupRequest请求的时候此字段设置为null。
5. protocol_type:
    - 表示消费组实现的协议，对于消费者而言此字段值为“consumer”
6. group_protocols:
    - 数组类型，其中可以囊括多个分区分配策略
    - 主要取决于消费者客户端参数 `partition.assignment.strategy` 的配置

如果是原有的消费者重新加入消费组，那么在真正发送JoinGroupRequest 请求之前还要执行一些准备工作：
1. 如果消费端参数enable.auto.commit设置为true（默认值也为true），即开启自动提交位移功能，那么在请求加入消费组之前需要向 GroupCoordinator 提交消费位移。这个过程是阻塞执行的，要么成功提交消费位移，要么超时。
2. 如果消费者添加了自定义的再均衡监听器（ConsumerRebalanceListener），那么此时会调用onPartitionsRevoked（）方法在重新加入消费组之前实施自定义的规则逻辑
3. 因为是重新加入消费组，之前与GroupCoordinator节点之间的心跳检测也就不需要了，所以在成功地重新加入消费组之前需要禁止心跳检测的运作。

消费者在发送JoinGroupRequest请求之后会阻塞等待Kafka服务端的响应。服务端在收到JoinGroupRequest 请求后会交由 GroupCoordinator 来进行处理。

**选举消费组的leader**
GroupCoordinator需要为消费组内的消费者选举出一个消费组的leader:
1. 如果消费组内还没有 leader，那么第一个加入消费组的消费者即为消费组的 leader
2. 如果 leader 消费者退出，选择消费者保存数组中的第一个消费者为 leader

**选举分区分配策略**
每个消费者都可以设置自己的分区分配策略，对消费组而言需要从各个消费者呈报上来的各个分配策略中选举一个彼此都“信服”的策略来进行整体上的分区分配。

这个分区分配的选举并非由leader消费者决定，而是根据消费组内的各个消费者投票来决定的。所谓投票是根据各个消费者呈报的分配策略来实施。最终选举的分配策略基本上可以看作被各个消费者支持的最多的策略。

如果有消费者并不支持选出的分配策略，那么就会报出异常 IllegalArgumentException。消费者所支持的分配策略”是指 partition.assignment.strategy 参数配置的策略，如果这个参数值只配置了RangeAssignor，那么这个消费者客户端只支持 RangeAssignor 分配策略

**JoinGroupResponse**
在此之后，Kafka服务端就要发送 JoinGroupResponse 响应给各个消费者，leader消费者和其他普通消费者收到的响应内容并不相同。

JoinGroupResponse 的结构如下:

![JoinGroupResponse](/images/kafka/join_response.png)


JoinGroupResponse 包含了多个域:
1. generation_id
    - 用来标识当前消费组的年代信息，避免受到过期请求的影响
2. leader_id
    - 表示消费组leader消费者的member_id
3. members
    - 发送给普通消费者的JoinGroupResponse中的members内容为空
    - leader消费者的JoinGroupResponse中的members包含有效数据。members为数组类型，其中包含各个成员信息。
    - member_metadata 为消费者的订阅信息，与 JoinGroupRequest 中的protocol_metadata内容相同，是对应选举完成后的结果

Kafka把分区分配的具体分配交还给客户端，自身并不参与具体的分配细节，这样即使以后分区分配的策略发生了变更，也只需要重启消费端的应用即可，而不需要重启服务端。

### 4.3 SYNC_GROUP

leader 消费者根据在第二阶段中选举出来的分区分配策略来实施具体的分区分配，在此之后需要将分配的方案同步给各个消费者，此时leader消费者并不是直接和其余的普通消费者同步分配方案，而是通过 GroupCoordinator 这个“中间人”来负责转发同步分配方案的。在第三阶段，也就是同步阶段，各个消费者会向GroupCoordinator发送 SyncGroupRequest 请求来同步分配方案，如下图。

![分区分配方案同步过程](/images/kafka/syn_request.png)


![SyncGroupRequest](/images/kafka/syn_request_s.png)


只有leader消费者发送的 SyncGroupRequest 请求中才包含具体的分区分配方案，其余消费者发送的SyncGroupRequest请求中的group_assignment为空。

其余消费者发送的SyncGroupRequest请求中的group_assignment为空。它是一个数组类型，其中包含了各个消费者对应的具体分配方案：member_id表示消费者的唯一标识，而member_assignment是与消费者对应的分配方案
。

服务端在收到消费者发送的SyncGroupRequest请求之后会交由GroupCoordinator来负责具体的逻辑处理。GroupCoordinator同样会先对SyncGroupRequest请求做合法性校验，在此之后会将从 leader 消费者发送过来的分配方案提取出来，连同整个消费组的元数据信息一起存入Kafka的__consumer_offsets主题中，最后发送响应给各个消费者以提供给各个消费者各自所属的分配方案。

**SyncGroupResponse**
SyncGroupRequest请求对应的是 SyncGroupResponse，里面包含的就是消费者对应的所属分配方案

![SyncGroupResponse](/images/kafka/syn_response.png)

当消费者收到所属的分配方案之后会调用PartitionAssignor中的onAssignment（）方法。随后再调用ConsumerRebalanceListener中的OnPartitionAssigned（）方法。之后开启心跳任务，消费者定期向服务端的GroupCoordinator发送HeartbeatRequest来确定彼此在线。

**消费组元数据信息**
消费组的元数据信息也保存在 __consumer_offsets主题中。每个消费组的元数据信息都是一条消息，不过这类消息并不依赖于具体版本的消息格式。具体的格式如下:

![消费者元信息](/images/kafka/consumer_meta.png)

key和 value 中的 version 表示版本，就目前版本而言，key的version为2，而value的version为1。

key中的 group 字段，就是消费组的名称，确定这条信息所要存储的分区还是根据单独的group字段来计算的，这样就可以保证消费组的元数据信息与消费组对应的GroupCoordinator处于同一个broker节点上，省去了中间轮转的开销。

value 中包含的内容有很多
1. protocol_type：消费组实现的协议，这里的值为“consumer”。
2. generation：标识当前消费组的年代信息，避免收到过期请求的影响。
3. protocol：消费组选取的分区分配策略。
4. leader：消费组的leader消费者的名称。
5. members：数组类型，其中包含了消费组的各个消费者成员信息，其中subscription和assignment这两个字段，分别代码消费者的订阅信息和分配信息。

### 4.4 HEARTBEAT
进入这个阶段之后，消费组中的所有消费者就会处于正常工作状态。在正式消费之前，消费者还需要确定拉取消息的起始位置。消费者可以通过OffsetFetchRequest请求获取上次提交的消费位移并从此处继续消费。

消费者通过向 GroupCoordinator 发送心跳来维持它们与消费组的从属关系，以及它们对分区的所有权关系。

**心跳线程是一个独立的线程，可以在轮询消息的空档发送心跳**。如果消费者停止发送心跳的时间足够长，则整个会话就被判定为过期，GroupCoordinator 也会认为这个消费者已经死亡，就会触发一次再均衡行为。消费者的心跳间隔时间由参数`heartbeat.interval.ms`指定，默认值为3000，即3秒，这个参数必须比`session.timeout.ms`参数设定的值要小，一般情况下heartbeat.interval.ms的配置值不能超过session.timeout.ms配置值的1/3。这个参数可以调整得更低，以控制正常重新平衡的预期时间。

如果一个消费者发生崩溃，并停止读取消息，那么 GroupCoordinator 会等待一小段时间，确认这个消费者死亡之后才会触发再均衡。在这一小段时间内，死掉的消费者并不会读取分区里的消息。这个一小段时间由 `session.timeout.ms` 参数控制，该参数的配置值必须在broker端参数 `group.min.session.timeout.ms`（默认值为 6000，即 6 秒）和 `group.max.session.timeout.ms`（默认值为300000，即5分钟）允许的范围内。

还有一个参数 `max.poll.interval.ms`，它用来指定使用消费者组管理时 `poll（）`方法调用之间的最大延迟，也就是消费者在获取更多消息之前可以空闲的时间量的上限。如果此超时时间期满之前poll（）没有调用，则消费者被视为失败，并且分组将重新平衡，以便将分区重新分配给别的成员。

除了被动退出消费组，还可以使用 LeaveGroupRequest 请求主动退出消费组，比如客户端调用了unsubscrible（）方法取消对某些主题的订阅。

## 5. __consumer_offsets剖析
对于主题__consumer_offsets的深度掌握也可以让我们更好地理解和使用好位移提交。一般情况下，当集群中第一次有消费者消费消息时会自动创建主题 __consumer_offsets。

__consumer_offsets 有如下几个控制参数:
1. offsets.topic.replication.factor: 设置副本数，默认值为 3
2. offsets.topic.num.partitions: 设置分区数，默认值为 50

### 5.1 OffsetCommitRequest
客户端提交消费位移是使用 OffsetCommitRequest 请求，其结构如下:

![OffsetCommitRequest](/images/kafka/offset_commit_request.png)

OffsetCommitRequest 包含多个域:
1. retention_time 
    - 表示当前提交的消费位移所能保留的时长，不过对于消费者而言这个值保持为-1
    - 也就是说，按照 broker 端的配置 offsets.retention.minutes 来确定保留时长
    - offsets.retention.minutes的默认值为10080，即7天，超过这个时间后消费位移的信息就会被删除（使用墓碑消息和日志压缩策略）
2. 其余字段大抵也是按照分区的粒度来划分消费位移的：
    - topic表示主题名称
    - partition表示分区编号等
    - 注意这里还有一个metadata字段
    - metadata是自定义的元数据信息，不设置默认为空字符串，其长度不能超过 offset.metadata.max.bytes 参数（broker 端配置，默认值为4096）所配置的大小


### 5.2 消费位移对应的消息格式
同消费组的元数据信息一样，最终提交的消费位移也会以消息的形式发送至主题__consumer_offsets，与消费位移对应的消息也只定义了 key 和 value 字段的具体内容，它不依赖于具体版本的消息格式，以此做到与具体的消息格式无关。

![OffsetCommitRequest](/images/kafka/offset_message.png)

key和value中都包含了version字段，这个用来标识具体的key和value的版本信息。目前key和value的version值都为1。

key
1. 包含 group、topic、partition字段，分别表示消费组的groupId、主题名称和分区编号
2. 虽然key中包含了4个字段，但最终确定这条消息所要存储的分区还是根据单独的 group 字段来计算的，这样就可以保证消费位移信息与消费组对应的GroupCoordinator 处于同一个 broker 节点上，省去了中间轮转的开销，这一点与消费组的元数据信息的存储是一样的。

value:
1. 包含 offset、metadata、commit_timestamp、expire_timestamp字段分别表示消费位移、自定义的元数据信息、位移提交到 Kafka 的时间戳、消费位移被判定为超时的时间戳。
2. 其中 offset 和 metadata 与OffsetCommitRequest 请求体中的 offset 和 metadata 对应
3. expire_timestamp 和OffsetCommitRequest 请求体中的 retention_time 也有关联，
4. commit_timestamp 值与offsets.retention.minutes参数值之和即为expire_timestamp（默认情况下）

### 5.3 OffsetCommitResponse
在处理完消费位移之后，Kafka返回OffsetCommitResponse给客户端，OffsetCommitResponse的结构如下图:

![OffsetCommitRequest](/images/kafka/offset_commit_response.png)


### 5.4 位移查看工具
可以通过 kafka-console-consumer.sh 脚本来查看__consumer_offsets 中的内容。

```bash
bin/kafka-console-consumer.sh /
    --bootstrap-server localhost:9092 /
    --topic __consumer_offset /
    --partition 20 /
    --formatter "kafka.coordinator.group.GroupMetadataManager$OffsetsMessageFormatter"
```

### 5.5 消费位移清理
在Kafka中有一个名为“delete-expired-group-metadata”的定时任务来负责清理过期的消费位移，这个定时任务的执行周期由参数 `offsets.retention.check.interval.ms` 控制，默认值为600000，即10分钟。

最后，如果有若干消费者消费了某个主题中的消息，并且也提交了相应的消费位移，那么在删除这个主题之后会一并将这些消费位移信息删除。
