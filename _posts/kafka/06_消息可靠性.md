title: 1.6 消息可靠性
date: 2020-04-06
categories:
    - 存储
tags:
    - Kafka
---

本节我们来介绍 kafka ISR 同步(失效)副本与消息可靠性相关的问题。
<!-- more -->

## 1. 失效副本
Kafka从0.9.x版本开始就通过唯一的broker端参数`replica.lag.time.max.ms`来抉择，当ISR集合中的一个follower副本滞后leader副本的时间超过此参数指定的值时则判定为同步失败，需要将此follower副本剔除出ISR集合。replica.lag.time.max.ms参数的默认值为10000。

Kafka 在启动的时候会开启两个与 ISR 相关的定时任务，名称分别为“isr-expiration”和“isr-change-propagation”。isr-expiration任务会周期性地检测每个分区是否需要缩减其ISR集合。这个周期和replica.lag.time.max.ms参数有关，大小是这个参数值的一半，默认值为5000ms。

如果某个分区的ISR集合发生变更，则会将变更后的数据记录到 ZooKeeper 对应的`/brokers/topics/＜topic＞/partition/＜parititon＞/state`节点中。

### 1.2 失效副本恢复
追赶上leader副本的判定准则是此副本的LEO是否不小于leader副本的HW。

## 1.3 kafka 为什么不支持读写分离


## 2. 日志同步机制
在分布式系统中，日志同步机制既要保证数据的一致性，也要保证数据的顺序性。虽然有许多方式可以实现这些功能，但最简单高效的方式还是从集群中选出一个leader来负责处理数据写入的顺序性。kafka isa 集合的同步方式是一个类 Quorum 机制，假设 ISR 集合的副本数是 n，那么写是 n，读是 1，可以保证读取到最新的消息。但是ISR 集合是动态的，不一定等于设置的总副本数。通过这种方式在吞吐量和可靠性之间进行权衡。


日志同步机制的一个基本原则就是：如果告知客户端已经成功提交了某条消息，那么即使 leader宕机，也要保证新选举出来的leader中能够包含这条消息。


## 3. 可靠性分析
首先对于消息中间件，数据的可靠性包括如下几个方面:
1. 消息不能重复 
2. 消息不能丢失
3. 消息之间要保证有序

### 3.1 数据不丢失
要尽可能保证数据不丢失，可以通过如下方式:
1. 增加副本数
2. 将生产者客户端的 ack 参数设置为 -1，即，生产者将消息发送到leader副本，leader副本在成功写入本地日志之后还要等待 ISR 中的 follower 副本全部同步完成才能够告知生产者已经成功提交
3. 通过生产者客户端重试机制，提高数据发送的成功率:
    - retries: 设置重试次数
    - retry.backoff.ms: 用来设定两次重试之间的时间间隔，以此避免无效的频繁重试
4. ack=-1 不能限制 ISR 中同步副本的个数，极端情况下  ISR 集合中可能只有 leader 副本，通过 `min.insync.replicas` 参数指定了ISR集合中最小的副本数
5. 与可靠性和ISR集合有关的还有一个参数—unclean.leader.election.enable。这个参数的默认值为false，如果设置为true就意味着当leader下线时候可以从非ISR集合中选举出新的 leader，这样有可能造成数据的丢失。
6. 在broker端还有两个参数`log.flush.interval.messages`和`log.flush.interval.ms`，用来调整同步刷盘的策略，默认是不做控制而交由操作系统本身来进行处理。同步刷盘是增强一个组件可靠性的有效方式
7. 对于消息的可靠性，很多人都会忽视消费端的重要性，如果一条消息成功地写入 Kafka，并且也被Kafka完好地保存，而在消费时由于某些疏忽造成没有消费到这条消息，那么对于应用来说，这条消息也是丢失的。enable.auto.commit 参数的默认值为 true，即开启自动位移提交的功能，虽然这种方式非常简便，但它会带来重复消费和消息丢失的问题，对于高可靠性要求的应用来说显然不可取，所以需要将 enable.auto.commit 参数设置为 false 来执行手动位移提交。

### 3.2 消息有序性
retries 参数值大于 0 可能会影响消息的顺序性,对此要么放弃客户端内部的重试功能，要么将`max.in.flight.requests.per.connection`参数设置为1，这样也就放弃了吞吐 min.insync.replicas参数在提升可靠性的时候会从侧面影响可用性。 min.insync.replicas参数在提升可靠性的时候会从侧面影响可用性。


## 4. 共识，复制和主从
如果我们假设网络始终稳定，且不存在单点故障(类似单机情况下)通过锁就可以解决并发问题。但是这些问题无法避免单点故障可能导致数据丢失，这就需要多台机器提供冗余，此时就需要对同一项配置达成共识，我们需要共识算法。

共识算法需要解决的另一个问题是，当配置发生变化时，如何让客户端感知到共识发生了变化。我们可以让所有节点抖注册监听器，但是这样会引起惊群效应。因此我们只能让少量节点，即所谓的主节点注册监听器。然后通过版本向量，让与主节点同步的从节点感知配置的变化。

kafka 为什么要引入 Zookeeper 是因为如果对所有 kafka 的节点都通过共识算法解决数据一致性问题，效率将非常低。数据一致性是以吞吐量为代价的。