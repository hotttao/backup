---
title: 7 服务端
date: 2020-04-07
categories:
    - 存储
tags:
    - Kafka
---

Kafka 服务端的核心设计和运行机制
<!-- more -->

## 1. Kafka 服务端概述
前面我们已经介绍了，Kafka 生产者、消费者客户端、主题与分区管理、日志存储。但对于Kafka 服务端的一些核心设计与运行机理还未涉及。那么本节我们来介绍 kafka 服务端的相关设计，包括:
1. 网络协议设计
2. 时间轮
3. 延迟操作
4. 控制器及参数解密

尤其是协议设计和控制器的介绍，这些是深入了解Kafka的必备知识点。

## 1. 协议设计
Kafka自定义了一组基于TCP的二进制协议，在 Kafka 2.0.0 中，一共包含了 43 种协议类型，每种协议类型都有对应的请求（Request）和响应（Response）

#### Request
每种类型的Request都包含相同结构的协议请求头（RequestHeader）和不同结构的协议请求体。

![request](/images/kafka/request_base.png)

协议请求头中包含 4 个域（Field）:
1. api_key: API 标识，标识请求的类型
2. api_version: API 版本号
3. correlation_id: 客户端生成的唯一请求 ID 标识，服务器端在处理完请求后也会将此 ID 写到 Response，这样客户端就能将请求和响应关联起来
4. client_id: 客户端 ID 

#### Response
每种类型的 Response 也包含相同结构的协议响应头（ResponseHeader）和不同结构的响应体（ResponseBody）

![request](/images/kafka/response_base.png)

协议响应头中只有一个 correlation_id，这是客户端请求中的请求 ID。

#### 请求响应所使用的基础类型
Kafka中所有协议类型的Request和Response的结构都是具备固定格式的，并且它们都构建于多种基本数据类型之上。这些基础类型如下图所示:

|类型|描述|
|:---|:---|
|boolean||
|int8、int16、int32、int64||
|uint32||
|varint|变长整型，值在 -2^31 - 2^31-1，ZigZag编码|
|varlong|变长长整型，值在 -2^63 - 2^63-1，ZigZag编码|
|string|字符串，开头是int16的长度字段，代表字符串长度 N，后面包含 N 个UTF8编码的字符串|
|nullable_string|可为空的字符串，空字符串用-1表示，其他同string|
|bytes|字节序列，开头是int32的长度字段，代表字节序列长度 N，后面包含 N 个字节|
|nullable_bytes|可为空的字节序列，空为 -1|
|records|表示kafka 中的一个消息序列，可以看做 nullable_bytes|
|array|给定类型T的数组，T可以是基础类型或基础类型组成的结构体，开头是int32的长度字段，表示有 N 个T示例，后面在跟 N 个 T 实例；空数组表示为 -1|

下面就以最常见的消息发送和消息拉取的两种协议类型做细致的讲解:
1. 消息发送的协议类型: 
    - ProduceRequest/ProduceResponse，对应的api_key=0，表示PRODUCE
    - 经历了 7 个版本(V0-V6)，我们将讲解最新版本（V6，即api_version=6）
2. 拉取消息的协议类型:
    - FetchRequest/FetchResponse，对应的api_key=1，表示FETCH
    - 经历了 9 个版本(V0-V8)，我们将讲解最新版本（V8，即api_version=8）

### 1.1 ProduceRequest/ProduceResponse
#### ProduceRequest
ProduceRequest 的组织结构如下图所示:

![ProduceRequest](/images/kafka/produce_request.png)

除了请求头中的4个域，其余ProduceRequest请求体中各个域的含义如下:

![ProduceRequest字段含义](/images/kafka/produce_request_mean.png)

在讲解生产者客户端时我们了解到:
1. 消息累加器 RecordAccumulator 中的消息是以＜分区，Deque＜ProducerBatch＞＞的形式进行缓存的
2. 之后由Sender线程转变成＜Node，List＜ProducerBatch＞＞的形式
3. 针对每个Node，Sender线程在发送消息前会将对应的List＜ProducerBatch＞形式的内容转变成 ProduceRequest 的具体结构
4. List＜ProducerBatch＞中的内容首先会按照主题名称进行分类（对应ProduceRequest中的域topic），然后按照分区编号进行分类（对应ProduceRequest中的域partition），分类之后的ProducerBatch集合就对应ProduceRequest中的域record_set

每个分区中的消息是顺序追加的，那么在客户端中按照分区归纳好之后就可以省去在服务端中转换的操作了，这样就将负载分摊到客户端，减轻了服务端的压力

#### ProducerResponse
V6版本中ProduceResponse的组织结构如下图所示:

![ProduceResponse](/images/kafka/producer_response.png)

除了响应头中的correlation_id，其余ProduceResponse各个域的含义如下:

![ProduceResponse字段含义](/images/kafka/producer_response_mean.png)


### 1.2 FetchRequest/FetchResponse
#### FetchRequest
FetchRequest的组织结构如下图所示:

![FetchRequest](/images/kafka/fetch_request.png)

除了请求头中的4个域，其余FetchRequest中各个域的含义如下

![FetchRequest字段含义](/images/kafka/fetch_request_mean1.png)
![FetchRequest字段含义](/images/kafka/fetch_request_mean2.png)

如果要拉取某个分区中的消息，就需要指定详细的拉取信息，也就是需要设定 partition、fetch_offset、log_start_offset和max_bytes这4个域的具体值，那么对每个分区而言，就需要占用4B+8B+8B+4B=24B的空间。

一般情况下，不管是 follower 副本还是普通的消费者，它们的订阅信息是长期固定的。也就是说，FetchRequest 中的 topics 域的内容是长期固定的，只有在拉取开始时或发生某些异常时会有所变动。

Kafka从1.1.0版本开始针对FetchRequest引入了session_id、epoch和forgotten_topics_data等域，session_id和epoch确定一条拉取链路的fetch session，当session建立或变更时会发送全量式的 FetchRequest，所谓的全量式就是指请求体中包含所有需要拉取的分区信息；当session稳定时则会发送增量式的FetchRequest请求，里面的topics域为空，因为topics域的内容已经被缓存在了session链路的两侧。如果需要从当前fetch session中取消对某些分区的拉取订阅，则可以使用forgotten_topics_data字段来实现。

这个改进在大规模（有大量的分区副本需要及时同步）的Kafka集群中非常有用，它可以提升集群间的网络带宽的有效使用率。不过对客户端而言效果不是那么明显，一般情况下单个客户端不会订阅太多的分区，不过总体上这也是一个很好的优化改进。

#### FetchResponse

FetchResponse 的结构如下:

![FetchResponse](/images/kafka/fetch_response.png)

FetchResponse结构中的域也很多，它主要分为4层:
1. 第1层包含throttle_time_ms、error_code、session_id 和 responses
2. 第二层 reponse 包括具体的响应内容
3. 第3层中包含分区的元数据信息（partition、error_code 等）及具体的消息内容（record_set），aborted_transactions和事务相关


## 2. 时间轮
Kafka中存在大量的延时操作，比如延时生产、延时拉取和延时删除等。Kafka并没有使用JDK自带的Timer或DelayQueue来实现延时的功能，而是基于时间轮的概念自定义实现了一个用于延时功能的定时器（SystemTimer）。JDK中Timer和DelayQueue的插入和删除操作的平均时间复杂度为O（nlogn），而基于时间轮可以将插入和删除操作的时间复杂度都降为O（1）

### 2.1 时间轮的数据结构

时间轮的数据结构如下:

![时间轮](/images/kafka/time_tick.jpg)

其由如下几个部分组成:
1. TimingWheel: 时间轮
    - 是一个存储定时任务的环形队列，底层采用数组实现
    - 数组中的每个元素可以存放一个定时任务列表（TimerTaskList）
    - 数组的每一项称为时间格，每个时间格代表当前时间轮的基本时间跨度（tickMs）
    - 时间轮的时间格个数是固定的，即数组长度，可用wheelSize来表示
    - 时间轮的总体时间跨度 = tickMs * wheelSize
2. TimerTaskList:
    - TimerTaskList是一个环形的双向链表
    - 链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务（TimerTask）
3. currentTime:
    - 表示事件轮的表盘指针，用来表示时间轮当前所处的时间，是tickMs的整数倍
    - currentTime可以将整个时间轮划分为到期部分和未到期部分
    - currentTime当前指向的时间格也属于到期部分，表示刚好到期，需要处理此时间格所对应的TimerTaskList中的所有任务。

### 2.2 定时任务的执行
时间轮的tickMs为1ms且wheelSize等于20，初始情况下表盘指针currentTime指向时间格0:
1. 定时为2ms的任务会存放到时间格为2的TimerTaskList中
2. 2ms 后，currentTime 向后推移到时间格2，此时就需要执行时间格2中 TimerTaskList 中的任务
3. 此时定时为 8ms 的任务到来，它将被插入到时间格10中
4. 定时为 19ms 的任务会复用原来的TimerTaskList，被插入原本已经到期的时间格1中

整个时间轮的总体跨度是不变的，随着指针currentTime的不断推进，当前时间轮所能处理的时间段也在不断后移，总体时间范围在currentTime和currentTime+interval之间。

### 2.3 多层时间轮
加入定时任务的到期事件为 100w ms，应该怎么办呢？很显然我们不能创建一个 100w 项的数组。

Kafka 为此引入了层级时间轮的概念，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中。

![时间轮](/images/kafka/multi_time_tick.png)

复用之前的案例:
1. 每一层时间轮的wheelSize是固定的，都是20
1. 第一层的时间轮tickMs=1ms、wheelSize=20、interval=20ms
2. 第二层的时间轮的tickMs为第一层时间轮的interval，即20ms，interval=400ms
3. 以此类推，第三层时间轮 tickMs=400ms，interval=8000ms

450ms的定时任务，的执行过程是这样的:
1. 450ms 超过了第二层能表示的最大范围 400ms，所以最终被插入第三层时间轮中时间格1的TimerTaskList。
2. 第三层的时间格1表示的时间范围[400ms，800ms），这个时间范围内可能有多个任务。当此TimerTaskList到期之时，原本定时为450ms的任务还剩下50ms的时间，还不能执行这个任务的到期操作。
3. 这里就有一个 **时间轮降级** 的操作，会将这个剩余时间为 50ms 的定时任务**重新提交到层级时间轮**中，此时第一层时间轮的总体时间跨度20ms不够，而第二层足够，所以该任务被放到第二层时间轮到期时间为[40ms，60ms）的时间格中
4. 再经历40ms之后，此任务还剩不到 10ms，将被再一次降级，被添加到第一层时间轮到期时间为[10ms，11ms）的时间格中
5. 再经历 10ms 后，此任务真正到期，最终执行相应的到期操作

### 2.4 kafka 实现
在 Kafka 中:
1. TimingWheel 在创建的时候以当前系统时间为第一层时间轮的起始时间（startMs）
2.  除了第一层时间轮，其余高层时间轮的起始时间（startMs）都设置为创建此层时间轮时前面第一轮的currentTime。
3. 每一轮的 currentTime=timeMs-（timeMs%tickMs），timeMs 为当前事件与 startMs 的插值，时间每推进一次，每个层级的时间轮的currentTime都会依据此公式执行推进。
4. Kafka 中的定时器只需持有 TimingWheel 的第一层时间轮的引用，但每一层时间轮都会有一个引用（overflowWheel）指向更高一层的应用

### 2.5 Kafka如何推进时间
在Kafka中到底是怎么推进时间的呢？Kafka中的定时器借了JDK中的DelayQueue来协助推进时间轮。

具体做法是
1. 对于每个使用到的TimerTaskList都加入DelayQueue，“每个用到的TimerTaskList”特指非哨兵节点的定时任务项TimerTaskEntry对应的TimerTaskList。
2. DelayQueue会根据TimerTaskList对应的超时时间expiration来排序，最短expiration的TimerTaskList会被排在DelayQueue的队头。
3. Kafka中会有一个线程来获取 DelayQueue 中到期的任务列表，线程所对应的名称叫作“ExpiredOperationReaper”，可以直译为“过期操作收割机”。
4. 当“收割机”线程获取 DelayQueue 中超时的任务列表 TimerTaskList之后，既可以根据 TimerTaskList 的 expiration 来推进时间轮的时间，也可以就获取的TimerTaskList执行相应的操作，对里面的TimerTaskEntry该执行过期操作的就执行过期操作，该降级时间轮的就降级时间轮

可以发现，Kafka 中的 **TimingWheel 专门用来执行插入和删除 TimerTaskEntry的操作**，而 **DelayQueue 专门负责时间推进的任务**。

## 3. 延时操作

在Kafka中有多种延时操作，比如延时生产，还有延时拉取（DelayedFetch）、延时数据删除（DelayedDeleteRecords）等。

延时由如下几个部分组成:
1. 首先他必须由一个超时时间，如果在这个超时时间内未完成任务，就要强制返回
2. ，延时操作不同于定时操作，定时操作是指在特定时间之后执行的操作，而**延时操作要在所设定的超时时间之前完成**，所以延时操作能够支持外部事件的触发
3. 外部事件的触发，要配备一个监听池来负责监听每个分区的外部事件
4. 而超时操作则需要一个定时器

前面我们提到，时间轮是由线程ExpiredOperationReaper来驱动的，所以: 定时器、ExpiredOperationReaper线程、延时管理器(DelayedOperationPurgatory)、监听池是一一对应的。

ExpiredOperationReaper不仅可以推进时间轮，还会定期清理监听池中已完成的延时操作。

### 3.1 延时生产
下图描绘了客户端在请求写入消息到收到响应结果的过程中与延时生产操作相关的细节:

![时间轮](/images/kafka/delay_write.png)

其中:
1. 如果客户端设置的 acks 参数不为-1，或者没有成功的消息写入，那么就直接返回结果给客户端
2. 否则就需要创建延时生产操作并存入延时操作管理器
3. 最终要么由外部事件触发，要么由超时触发而执行。

### 3.2 延时拉取
有延时生产就有延时拉取。两个follower副本都已经拉取到了leader副本的最新位置，此时又向leader副本发送拉取请求，而leader副本并没有新的消息写入，那么此时leader副本该如何处理呢？

如果 leader 没有新消息，而副本的拉取操作周而复始，只会平白消耗资源。

Kafka选择了延时操作来处理这种情况:
1. Kafka在处理拉取请求时，会先读取一次日志文件，如果收集不到足够多（fetchMinBytes，由参数fetch.min.bytes配置，默认值为1）的消息，那么就会创建一个延时拉取操作（DelayedFetch）以等待拉取到足够数量的消息
2. 当延时拉取操作执行时，会再读取一次日志文件，然后将拉取结果返回给 follower 副本
3. 如果拉取进度一直没有追赶上leader副本，那么在拉取leader副本的消息时一般拉取的消息大小都会不小于fetchMinBytes，这样Kafka也就不会创建相应的延时拉取操作，而是立即返回拉取结果

延时拉取操作也会有一个专门的延时操作管理器负责管理。延时拉取操作同样是由超时触发或外部事件触发而被执行的。外部事件触发就稍复杂了一些，因为拉取请求不单单由 follower 副本发起，也可以由消费者客户端发起，两种情况所对应的外部事件也是不同的。

follower副本的延时拉取，它的外部事件就是消息追加到了leader副本的本地日志文件中；如果是消费者客户端的延时拉取，它的外部事件可以简单地理解为HW的增长。

## 4. 控制器
在 Kafka 集群中会有一个或多个 broker，其中有一个 broker 会被选举为控制器（Kafka Controller），它负责
1. 管理整个集群中所有分区和副本的状态。当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。
2. 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。
3. 当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责分区的重新分配。

Kafka中的控制器选举工作依赖于ZooKeeper，成功竞选为控制器的broker会在ZooKeeper中创建/controller这个临时（EPHEMERAL）节点。

ZooKeeper 中还有一个与控制器有关的/controller_epoch 节点，这个节点是持久（PERSISTENT）节点，节点中存放的是一个整型的controller_epoch值。controller_epoch用于记录控制器发生变更的次数，即记录当前的控制器是第几代控制器，我们也可以称之为“控制器的纪元”。

### 4.1 控制职责

## 5. 重要参数解析
### 5.1 broker.id
服务器端参数 broker.id是broker在启动之前必须设定的参数之一，在Kafka集群中，每个broker都有唯一的 id值用来区分彼此。

broker 在启动时会在 ZooKeeper 中的 **/brokers/ids**路径下创建一个以当前brokerId为名称的虚节点，broker的健康状态检查就依赖于此虚节点。当 broker 下线时，该虚节点会自动删除，其他 broker 节点或客户端通过判断/brokers/ids路径下是否有此broker的brokerId节点来确定该broker的健康状态。

broker.id 有三种配置方式:
1. 配置文件 config/server.properties 里的 broker.id，默认值为-1， 在Kafka中，brokerId值必须大于等于0才有可能正常启动
2. meta.properties文件
3. 通过服务端如下参数自动生成新的brokerId:
    - broker.id.generation.enable: True 表示启用自动生成功能
    - reserved.broker.max.id: 自动生成的 brokerId 有一个基准值，即自动生成的 brokerId 必须超过这个基准值

他们的优先级是从上往下，优先级越来越低。

#### 自动生成 broker.id 的原理
自动生成的brokerId的原理是先往ZooKeeper中的 **/brokers/seqid** 节点中写入一个空字符串。然 后 获 取 返回的Stat 信息中的 version 值，进而将 version 的值和reserved.broker.max.id参数配置的值相加。

brokers/seqid节点在被更新后，dataVersion就自增1，表示数据发生了变更，这样通过ZooKeeper 的这个功能来实现集群层面的序号递增，整体上相当于一个发号器。

### 5.2 bootstrap.servers
客户端参数 bootstrap.servers 是Kafka Producer、Kafka Consumer客户端中的必备参数。

我们一般可以简单地认为 bootstrap.servers 这个参数所要指定的就是将要连接的Kafka集群的broker地址列表。不过从深层次的意义上来讲，这个参数配置的是用来**发现Kafka集群元数据信息的服务地址**。

![Kafka连接过程](/images/kafka/broker_server.png)

客户端连接Kafka集群要经历以下3个过程:
1. 与bootstrap.servers参数所指定的Server连接，并发送MetadataRequest请求来获取集群的元数据信息
2. Server 通过 MetadataResponse 返回元数据信息
3. 客户端KafkaProducer2收到的MetadataResponse之后解析出其中包含的集群元数据信息，然后与集群中的各个节点建立连接，之后就可以发送消息了

在绝大多数情况下，Kafka 本身就扮演着第一步和第二步中的 Server 角色，我们完全可以将这个Server的角色从Kafka中剥离出来，从而添加一些路由的功能、负载均衡的功能。

### 5.3 服务器端的配置参数

|主题端参数|描述|对应的broker端参数|
|:---|:---|:---|
|cleanup.policy	|日志压缩策略。默认值为delete，还可以配置为compact|	log.cleanup.policy|
|compression.type	|消息的压缩类型。默认值是producer，表示保留生产者中所使用的原始压缩类型。还可以配置为uncompressed、snappy、lz4、gzip	|compression.type|
|delete.retention.ms	|被标识为删除的数据能够保留多久。默认值是86400000，即1天|	log.clear.delete.retention.ms|
|file.delete.delay.ms	|清理文件之前可以等待多长时间，默认值是60000，即1分钟|	log.segment.delete.delay.ms|
|flush.messges	|需要收集多少消息才会将它们强制刷新到磁盘，默认值是Long.MAX_VALUE,即让操作系统来决定。建议不要修改此参数的默认值|	log.flush.interval.messges|
|flush.ms	|需要等待多久才会将消息强制刷新到磁盘，默认值是Long.MAX_VALUE,即让操作系统来决定。建议不要修改此参数的默认值|	log.flush.interval.ms|
|follower.replication.throttled.replicas	|用来配置被限制速率的主题所对应的follower副本列表|	follower.replication.throttled.replicas|
|index.interval.bytes	|用来控制添加索引项的频率。每超过这个参数所设置的消息字节数时就可以添加一个新的索引项，默认值是4096|	log.index.interval.bytes|
|leader.replication.throttled.replicas	|用来配置被限制速率的主题所对应的leader副本列表|	leader.replication.throttled.replicas|
|max.message.byte	|消息的最大字节数，默认值是1000012|	max.message.byte|
|message.format.version	|消息格式的版本，默认值为2.0-IV1|	log.message.format.version|
|message.timestamp.difference.max.ms	|消息中自带的时间戳与broker收到消息时的时间戳之间的最大差值，默认值为Long.MAX_VALUE。此参数只有在message.timestamp.type参数设置为CreteTime时才有效|	log.message.timestamp.difference.max.ms|
|message.timestamp.type	|消息的时间戳类型。默认值是CreteTime，还可以设置为LogAppendTime|	log.message.timestamp.type|
|min.cleanable.dirty.ratio	|日志清理时的最小污浊率，默认值是0.5|	log.cleaner.min.cleanable.ratio|
|min.compaction.lag.ms	|日志再被清理前的最小保留时间，默认值为0|	log.cleaner.min.compaction.lag.ms|
|min.insync.replicas	|分区ISR集合中至少有多少个副本，默认值为1|	min.insync.replicas|
|preallocate	|在创建日志分段的时候是否要预分配空间，默认值为false|	log.preallocate|
|retention.bytes	|分区中所能保留的消息总量，默认值为-1，即没有限制|	log.retention.bytes|
|retention.ms	|使用delete的日志清理策略时消息能够保留多长时间，默认值为604800000，即7天。如果设置为-1，则表示没有限制|	log.retention.ms|
|segment.bytes	|日志分段的最大值，默认值为1073741824，即1GB|	log.segment.bytes|
|segment.index.bytes	|日志分段索引的最大值，默认值为10485760，即10MB|	log.index.size.max.bytes|
|segment.jitter.ms	|滚动日志分段时，在segment.ms的基础之上增加的随机数，默认为0|	log.roll.jitter.ms|
|segment.ms	|最多多久滚动一次日志分段，默认值为604800000，即7天|	log.roll.ms|
|unclean.leader.election.enable	|是否可以从非ISR集合中选举leader副本，默认值为false，如果设置为true，则可能造成数据丢失|	unclean.leader.election.enable|
