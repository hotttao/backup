---
title: 7 服务端
date: 2020-04-07
categories:
    - 存储
tags:
    - Kafka
---

Kafka 服务端的核心设计和运行机制
<!-- more -->

## 1. Kafka 服务端概述
前面我们已经介绍了，Kafka 生产者、消费者客户端、主题与分区管理、日志存储。但对于Kafka 服务端的一些核心设计与运行机理还未涉及。那么本节我们来介绍 kafka 服务端的相关设计，包括:
1. 网络协议设计
2. 时间轮
3. 延迟操作
4. 控制器及参数解密

尤其是协议设计和控制器的介绍，这些是深入了解Kafka的必备知识点。

## 1. 协议设计
Kafka自定义了一组基于TCP的二进制协议，在 Kafka 2.0.0 中，一共包含了 43 种协议类型，每种协议类型都有对应的请求（Request）和响应（Response）

#### Request
每种类型的Request都包含相同结构的协议请求头（RequestHeader）和不同结构的协议请求体。

![request](/images/kafka/request_base.png)

协议请求头中包含 4 个域（Field）:
1. api_key: API 标识，标识请求的类型
2. api_version: API 版本号
3. correlation_id: 客户端生成的唯一请求 ID 标识，服务器端在处理完请求后也会将此 ID 写到 Response，这样客户端就能将请求和响应关联起来
4. client_id: 客户端 ID 

#### Response
每种类型的 Response 也包含相同结构的协议响应头（ResponseHeader）和不同结构的响应体（ResponseBody）

![request](/images/kafka/response_base.png)

协议响应头中只有一个 correlation_id，这是客户端请求中的请求 ID。

#### 请求响应所使用的基础类型
Kafka中所有协议类型的Request和Response的结构都是具备固定格式的，并且它们都构建于多种基本数据类型之上。这些基础类型如下图所示:

|类型|描述|
|:---|:---|
|boolean||
|int8、int16、int32、int64||
|uint32||
|varint|变长整型，值在 -2^31 - 2^31-1，ZigZag编码|
|varlong|变长长整型，值在 -2^63 - 2^63-1，ZigZag编码|
|string|字符串，开头是int16的长度字段，代表字符串长度 N，后面包含 N 个UTF8编码的字符串|
|nullable_string|可为空的字符串，空字符串用-1表示，其他同string|
|bytes|字节序列，开头是int32的长度字段，代表字节序列长度 N，后面包含 N 个字节|
|nullable_bytes|可为空的字节序列，空为 -1|
|records|表示kafka 中的一个消息序列，可以看做 nullable_bytes|
|array|给定类型T的数组，T可以是基础类型或基础类型组成的结构体，开头是int32的长度字段，表示有 N 个T示例，后面在跟 N 个 T 实例；空数组表示为 -1|

下面就以最常见的消息发送和消息拉取的两种协议类型做细致的讲解:
1. 消息发送的协议类型: 
    - ProduceRequest/ProduceResponse，对应的api_key=0，表示PRODUCE
    - 经历了 7 个版本(V0-V6)，我们将讲解最新版本（V6，即api_version=6）
2. 拉取消息的协议类型:
    - FetchRequest/FetchResponse，对应的api_key=1，表示FETCH
    - 经历了 9 个版本(V0-V8)，我们将讲解最新版本（V8，即api_version=8）

### 1.1 ProduceRequest/ProduceResponse
#### ProduceRequest
ProduceRequest 的组织结构如下图所示:

![ProduceRequest](/images/kafka/produce_request.png)

除了请求头中的4个域，其余ProduceRequest请求体中各个域的含义如下:

![ProduceRequest字段含义](/images/kafka/produce_request_mean.png)

在讲解生产者客户端时我们了解到:
1. 消息累加器 RecordAccumulator 中的消息是以＜分区，Deque＜ProducerBatch＞＞的形式进行缓存的
2. 之后由Sender线程转变成＜Node，List＜ProducerBatch＞＞的形式
3. 针对每个Node，Sender线程在发送消息前会将对应的List＜ProducerBatch＞形式的内容转变成 ProduceRequest 的具体结构
4. List＜ProducerBatch＞中的内容首先会按照主题名称进行分类（对应ProduceRequest中的域topic），然后按照分区编号进行分类（对应ProduceRequest中的域partition），分类之后的ProducerBatch集合就对应ProduceRequest中的域record_set

每个分区中的消息是顺序追加的，那么在客户端中按照分区归纳好之后就可以省去在服务端中转换的操作了，这样就将负载分摊到客户端，减轻了服务端的压力

#### ProducerResponse
V6版本中ProduceResponse的组织结构如下图所示:

![ProduceResponse](/images/kafka/producer_response.png)

除了响应头中的correlation_id，其余ProduceResponse各个域的含义如下:

![ProduceResponse字段含义](/images/kafka/producer_response_mean.png)


### 1.2 FetchRequest/FetchResponse
#### FetchRequest
FetchRequest的组织结构如下图所示:

![FetchRequest](/images/kafka/fetch_request.png)

除了请求头中的4个域，其余FetchRequest中各个域的含义如下

![FetchRequest字段含义](/images/kafka/fetch_request_mean1.png)
![FetchRequest字段含义](/images/kafka/fetch_request_mean2.png)

如果要拉取某个分区中的消息，就需要指定详细的拉取信息，也就是需要设定 partition、fetch_offset、log_start_offset和max_bytes这4个域的具体值，那么对每个分区而言，就需要占用4B+8B+8B+4B=24B的空间。

一般情况下，不管是 follower 副本还是普通的消费者，它们的订阅信息是长期固定的。也就是说，FetchRequest 中的 topics 域的内容是长期固定的，只有在拉取开始时或发生某些异常时会有所变动。

Kafka从1.1.0版本开始针对FetchRequest引入了session_id、epoch和forgotten_topics_data等域，session_id和epoch确定一条拉取链路的fetch session，当session建立或变更时会发送全量式的 FetchRequest，所谓的全量式就是指请求体中包含所有需要拉取的分区信息；当session稳定时则会发送增量式的FetchRequest请求，里面的topics域为空，因为topics域的内容已经被缓存在了session链路的两侧。如果需要从当前fetch session中取消对某些分区的拉取订阅，则可以使用forgotten_topics_data字段来实现。

这个改进在大规模（有大量的分区副本需要及时同步）的Kafka集群中非常有用，它可以提升集群间的网络带宽的有效使用率。不过对客户端而言效果不是那么明显，一般情况下单个客户端不会订阅太多的分区，不过总体上这也是一个很好的优化改进。

#### FetchResponse

FetchResponse 的结构如下:

![FetchResponse](/images/kafka/fetch_response.png)

FetchResponse结构中的域也很多，它主要分为4层:
1. 第1层包含throttle_time_ms、error_code、session_id 和 responses
2. 第二层 reponse 包括具体的响应内容
3. 第3层中包含分区的元数据信息（partition、error_code 等）及具体的消息内容（record_set），aborted_transactions和事务相关


## 2. 时间轮
延时操作的实现

## 3. 延时操作
### 3.1 延时生产

### 3.2 延时拉取

## 4. 控制器
在 Kafka 集群中会有一个或多个 broker，其中有一个 broker 会被选举为控制器（Kafka Controller），它负责
1. 管理整个集群中所有分区和副本的状态。当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。
2. 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。
3. 当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责分区的重新分配。

Kafka中的控制器选举工作依赖于ZooKeeper，成功竞选为控制器的broker会在ZooKeeper中创建/controller这个临时（EPHEMERAL）节点。

ZooKeeper 中还有一个与控制器有关的/controller_epoch 节点，这个节点是持久（PERSISTENT）节点，节点中存放的是一个整型的controller_epoch值。controller_epoch用于记录控制器发生变更的次数，即记录当前的控制器是第几代控制器，我们也可以称之为“控制器的纪元”。

### 4.1 控制职责
