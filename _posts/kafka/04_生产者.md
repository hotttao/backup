---
title: 1.4 kafka 消息格式
date: 2020-04-04
categories:
    - 存储
tags:
    - Kafka
---
本节我们来介绍 kafka 消息格式相关内容。

<!-- more -->

## 1. 消息格式演进
Kafka的消息格式也经历了3个版本：v0版本、v1版本和v2版本(如无特殊说明，下面都是消息未压缩的情形)。与消息对应的还有消息集的概念，消息集中包含一条或多条消息，消息集不仅是存储于磁盘及在网络上传输（Produce＆Fetch）的基本形式，而且是Kafka中压缩的基本单元。接下来我们会一次介绍 v0，v1，v2 三种消息的具体格式以及相应的消息集格式。

## 2. 消息格式 v0
v0版本 的消息及消息集格式如下:
![kafka_msg_v0](/images/kafka/kafka_msg_v0.png)

其中:
1. LOG_OVERHEAD: 固定为12B
    - offset 用来标志它在分区中的偏移量，这个offset是逻辑值，而非实际物理偏移值 8B
    - message size表示消息的大小 4B
2. RECORD: 最小大小为 4B+1B+1B+4B+4B=14B，不包括 key 和 value
    -  crc32（4B）：crc32校验值。校验范围为magic至value之间
    -  magic（1B）：消息格式版本号，此版本的magic值为0。
    -  attributes（1B）：消息的属性。总共占1个字节，低3位表示压缩类型，其余位保留：
        -  0表示NONE
        -  1表示GZIP
        -  2表示SNAPPY
        -  3表示LZ4（LZ4自Kafka 0.9.x引入）
    -  key length（4B）：表示消息的key的长度。如果为-1，则表示没有设置key，即key=null
    -  key：可选，如果没有key则无此字段
    -  value length（4B）：实际消息体的长度。如果为-1，则表示消息为空。
    -  value：消息体。可以为空，比如墓碑（tombstone）消息。

## 3. 消息格式 v1
v1，比v0版本就多了一个timestamp字段，表示消息的时间戳。如下图所示:

![kafka_msg_v1](/images/kafka/kafka_msg_v1.png)

其中: 
1. magic字段的值为1。
2. attributes:
    - 低3位和v0版本的一样，表示压缩类型
    - 第4个位（bit）：
        - 0表示timestamp类型为CreateTime，
        - 1表示timestamp类型为LogAppendTime
    - 其他位保留。
    - timestamp类型由broker端参数log.message.timestamp.type来配置，默认值为CreateTime，即采用生产者创建消息时的时间戳。
    - 如果在创建 ProducerRecord 时没有显式指定消息的时间戳，那么 KafkaProducer也会在发送这条消息前自动添加上

v1 版本的RECORD 最小长度为 14 + 8 = 22B

## 4. v1 格式消息压缩
Kafka实现的压缩方式是将多条消息一起进行压缩，这样可以保证较好的压缩效果。。在一般情况下，生产者发送的压缩数据在broker中也是保持压缩状态进行存储的，消费者从服务端获取的也是压缩的消息，消费者在处理消息之前才会解压消息，这样保持了端到端的压缩。

参数 compression.type 用来配置压缩方式，可选值包括:
1. 默认值为“producer”，表示保留生产者使用的压缩方式
2. gzip、snappy、lz4，分别对应 GZIP、SNAPPY、LZ4 这 3 种压缩算法
3. uncompressed，则表示不压缩

当消息压缩时是将整个消息集进行压缩作为内层消息（inner message），内层消息整体作为外层（wrapper message）的 value，消息压缩后的格式如下图所示:

![kafka_msg_zip](/images/kafka/kafka_msg_zip.png)

其中:
1. 压缩后的外层消息（wrapper message）中的key为null，
2. value字段中保存的是多条压缩消息（inner message，内层消息）
3. Record表示的是从 crc32 到 value 的消息格式
4. 压缩消息消息集中的消息offset都是从0开始的，对 offset 的转换是在服务端进行的，客户端不需要做这个工作。
5. 外层消息保存了内层消息中最后一条消息的绝对位移（absolute offset），绝对位移是相对于整个分区而言的

### 4.1 compact message 与 compress message
compact message是针对日志清理策略而言的（cleanup.policy=compact），是指日志压缩（Log Compaction）后的消息。本节中的压缩消息单指compress message，即采用GZIP、LZ4等压缩工具压缩的消息。

### 4.2 数据压缩的 timestamp 字段
外层消息的timestamp设置：
- 如果timestamp类型是CreateTime，那么设置的是内层消息中最大的时间戳。
- 如果timestamp类型是LogAppendTime，那么设置的是Kafka服务器当前的时间戳。

内层消息的timestamp设置：
- 如果外层消息的timestamp类型是CreateTime，那么设置的是生产者创建消息时的时间戳。
- 如果外层消息的timestamp类型是LogAppendTime，那么所有内层消息的时间戳都会被忽略。

对 attributes 字段而言，它的 timestamp 位只在外层消息中设置，内层消息中的timestamp类型一直都是CreateTime。

## 5. 消息格式 v2
v2 参考 Protocol Buffer 引入了变长整型（Varints）和ZigZag编码。大家可以参考其他资料。

v2 的消息格式如下图所示:
![kafka_msg_v2](/images/kafka/kafka_msg_v2.png)
其中:
1. Record Batch: 消息集
2. Record Batch Header: 从first offset到records count，这些字段是不被压缩的
3. records: 表示被压缩的消息
4. Record: 表示单条消息

生产者客户端中的 ProducerBatch 对应这里的 RecordBatch ，而 ProducerRecord 对应这里的Record。下面我们分别来讲解各个部分的含义

### 5.1 Record
Record 包含如下字段:
1. key、key length、value、value length字段同v0和v1版本的一样
2. length：消息总长度
3. attributes：弃用，但还是在消息格式中占据1B的大小，以备未来的格式扩展
4. timestamp delta：时间戳增量。通常一个timestamp需要占用8个字节，如果像这里一样保存与RecordBatch的起始时间戳的差值，则可以进一步节省占用的字节数。
5. offset delta：位移增量。保存与 RecordBatch起始位移的差值，可以节省占用的字节数
6. headers：
    - 用来支持应用级别的扩展，而不需要像v0和v1版本一样不得不将一些应用级别的属性值嵌入消息体
    - Header的格式如图最右部分所示，包含key和value
    - 一个Record里面可以包含0至多个Header
7. 在 v2 版本中将 crc 的字段从 Record 中转移到了RecordBatch中

### 5.2 Record Batch
Record Batch 包含如下字段:
1. first offset：表示当前RecordBatch的起始位移
2. length：计算从partition leader epoch字段开始到末尾的长度
3. partition leader epoch：分区leader纪元，可以看作分区leader的版本号或更新次数
4. magic：消息格式的版本号，对v2版本而言，magic等于2
5. attributes：消息属性，注意这里占用了两个字节。
    - 低3位表示压缩格式，可以参考v0和v1；
    - 第4位表示时间戳类型
    - 第5位表示此RecordBatch是否处于事务中，0表示非事务，1表示事务
    - 第6位表示是否是控制消息（ControlBatch），0表示非控制消息，而1表示是控制消息，控制消息用来支持事务功能
6. last offset delta：
    - RecordBatch中最后一个Record的offset与first offset的差值
    - 主要被broker用来确保RecordBatch中Record组装的正确性
7. first timestamp：RecordBatch中第一条Record的时间戳
8. max timestamp：RecordBatch 中最大的时间戳，一般情况下是指最后一个 Record的时间戳，和last offset delta的作用一样，用来确保消息组装的正确性。
9. producer id：PID，用来支持幂等和事务
10. producer epoch：和producer id一样，用来支持幂等和事务
11. first sequence：和 producer id、producer epoch 一样，用来支持幂等和事务
12. records count：RecordBatch中Record的个数。

v2版本的消息不仅提供了更多的功能，比如事务、幂等性等，某些情况下还减少了消息的空间占用，总体性能提升很大。使用kafka-dump-log.sh 可以查看kafka日志的内容来验证所使用的消息格式。命令如下:

```bash
> bin/kafka-dump-log.sh --files /tmp/kafka/topic-0/0000000000000.log --print-data-log
````
kafka-dump-log.sh脚本也可以用来解析.index文件（还包括.timeindex、.snapshot、.txnindex等文件）

