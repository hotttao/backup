---
title: 4. 数据存储和检索
date: 2019-04-04
categories:
    - 分布式
tags:
    - 数据密集型应用
---

数据如何存储，如何检索

<!-- more -->

## 1. 存储引擎
上一节我们讨论了**数据模型和查询语言**，即应用开发人员向数据库执行数据格式并在之后如何查询的机制。接下来我们从数据的角度在此探讨同样的问题，即如何存储输入的数据，并在收到查询请求时，如何重新找到数据。

接下来我们将比较两个存储引擎家族: **日志结构**的存储引擎和**面向页**的存储引擎。

数据结构的核心是数据结构，为了高效的查询数据库中的数据，我们需要新的数据结构: 索引。索引背后的基本思想是保留一些额外的元数据，这些元数据作为路标，帮助定位想要的数据。索引是基于原始数据派生而来的额外数据结构，它只会影响查询性能，维护额外的结构势必会引入开销，由于每次写数据时，需要更新索引，因此任何类型的索引都会降低写速度。

一个存储引擎通常需要解决以下问题:
1. 文件格式: 数据存储的方式，影响数据解析的效率，影响索引的选择，数据增删改查的方式
2. 数据分段: 数据和日志不可能只保存在一个文件中
3. 奔溃恢复
4. 部分写入的处理
5. 并发控制

## 2. 索引
### 2.1 哈希索引
内存中的 hash map 把每个键一一映射到数据文件中特定的字节偏移量。只要所有的 key 可以放入内存，只需要一次磁盘寻址，就可以查询到key 对应的 value 值。

哈希索引也有其局限性:
1. 哈希表必须全部放入内存
2. 哈希变满时，继续增长代价昂贵，并且哈希冲突时需要复杂的处理逻辑
3. 不支持区间查询。

使用 hash map 的典型存储引擎是 Bitcash(Riak 中的默认存储引擎，是一个 key-value 键值数据库)。Bitcash 是如何解决存储引擎的上述问题的呢？
1. 文件格式: 二进制格式，首先以字节为单位来记录字符串的长度，之后跟上原始字符串
2. 数据分段: 
    - 数据被分解成一定大小的段，多个数据段可以**按键合并压缩**(数据也是以key-value存储的)
    - 每个段都有自己的内存哈希表，查询时按照新旧程度顺序索引哈希表
3. 增删改查: 数据删除需要使用墓碑，以便在合并数据段时丢弃删除的记录
4. 奔溃恢复: 
    - 数据库重启 hash map 需要重建，此时需要扫描整个数据库文件
    - Bitcash 通过将 hash map 的快照存储在磁盘上，来加速索引的重建
5. 部分写入: 记录需要添加校验来发现部分写入的记录
6. 并发控制: 由于 Bitcash 采用追加写的方式，严格按照写入的先后顺序进行写入，并且数据是不可修改的，通常的实现是只有一个写线程。

通过实践证明追加写的设计非常合理，理由是:
1. 追加和分段主要是顺序写，通常比随机写快很多
2. 如果段文件是追加的和不可变的，并发和崩溃恢复要简单的多
3. 合并旧段可以避免随着时间推移数据文件出现碎片化的问题。

### 2.2 SSLTable 和 LVS-Tree
前面介绍采用追加写的数据分段中，key-value 是按照顺序写入的，后出现的值将覆盖之前的值。除此之外文件中 key-value 的顺序并不重要。而 SSLTable(排序字符串表)要求**每个键在每个段中只能出现一次，且 key-value 是顺序排序的**。

SSLTable 相比哈希索引的数据分段具有以下优点:
1. 合并段更加简单高效，即使文件大于内存，也可以使用类似归并排序的算法进行合并
2. 查询时，不需要再内存中保存所有键的索引，因为键是有序的，使用间隔的稀疏内存索引和二分查找就可以快速检索数据
3. 由于读请求往往需要扫描请求范围内的多个key-value，可以考虑将这些记录保存到一个块中并在写磁盘之前将其压缩，然后稀疏内存索引的每个条目指向压缩块的开头。

#### 构建和维护 SSLTable
