---
title: 5. redis 拓展篇
date: 2020-05-05
categories:
    - 存储
tags:
    - Kafka
---

Redis 拓展应用

<!-- more -->

## 1. 拓展篇概述
拓展篇我们将介绍基于 Redis 的扩展应用
- Stream 消息流
- Info 指令，Redis 的监测
- 分布式锁的实现
- Redis 的惰性删除
- Redis 的加密


## 2. 消息队列
通过 List 实现的消息队列支持只有一组消费着，没有 ack 保证，不支持多播，消息无法持久化。为了解决这些问题，Redis 陆续引入了不同的消息队列实现。本节我们就来介绍 Redis 中队列实现的多种方式，包括:
1. list 实现的消息队列
2. zset 实现的延时队列
3. pubsub 发布订阅
4. Stream

### 2.1 Redis List 消息队列
最简单的消息队列，通过 list 和 list 操作指令(rpush，lpush，rpop，lpop) 实现。rpop，lpop 在 list 为空时会造成忙等待。Redis 提供了对应的阻塞读版本: blpop，brpop，这两个指令在list 为空时就会阻塞等待。这就是所谓的长轮询优化。

需要注意的是被 block 住的空闲连接可能会被服务器端断开，因此使用 brpop，blpop 时需要捕获连接异常并重试。

### 2.2 延时队列
延时队列需要记录消息的到期处理时间，以便及时对消息进行处理。可以通过 zset 来实现延时队列，将消息序列化成一个字符串作为 zset 的 value，到期处理时间作为 score。然后用多个线程轮询 zset 获取到期的任务进行处理。因为使用了多线程，此时需要考虑并发争抢，确保任务不会被多次执行。下面是实现的一个 demon

```bash
def loop():
    while 1:
        values = redis.zrangebyscore("delay-queue", 0, time.time(), start=0, num=1)
        if not values:
            time.sleep(1)
            continue
        value = values[0]
        success = redis.zrem("delay-queue", value)
        if success:
            msg = json.load(value)
            handle_msg(msg)
```

这个示例通过判断 zrem 有没有成功删除消息的方式来判断是否成功抢占任务，来避免多次执行一个任务。那些没有抢到的进程都白取了一次任务，可以考虑使用 lua 脚本来优化这个逻辑，将zrangebyscore 和 zrem 放到服务器端进行原子化操作，这样多个进程抢占任务就不会出现浪费了。

### 2.2 pubsub(发布/订阅)
list 实现的消息队列只支持一组消费者，不支持消息的多播(扇出)。Redis 使用了一个单独的模块来支持多个消费者组，叫做 PubSub。下面是 PubSub 使用的 Python 代码示例:

```Python
# 发布
client = redis.StrictRedis()
client.publish("code", "python")

# 订阅-非阻塞
client = redis.StrictRedis()
p = client.pubsub()
p.subscribe("code")
while True:
    msg = p.get_message() # 非阻塞的

# 订阅-阻塞
client = redis.StrictRedis()
p = client.pubsub()
p.subscribe("code")
for msg in p.listen():  # 阻塞监听
    print(msg)
```

Redis 支持对主题名称使用模糊匹配来订阅多个主题。如果生产者新增了同模式的主题，消费者可以立即收到消息，无须额外的订阅指令。

```bash
> psubscribe code*
```

#### pubsub 的缺点
pubsub 的消息是不会持久化的:
1. 如果消息没有对应的消费者，那么消息会被直接丢弃
2. 如果有多个消费者，其中一个消费者中间迭机掉线，等到它从新上线之间的所有消息，对于这个消费者就彻底丢失了

所以 Redis 的 pubsub 没有太多合适的适用场景。

## 2.3 Stream
#### Stream 结构
Stream支持多播的可持久化消息队列。其结构如下图所示:

![Stream数据结构](/images/redis/redis_stream.png)


Stream:
1. 是一个消息链表，具有唯一的名称(Redis key)，消息是持久化的
2. 每个消息都有唯一的ID
3. 每个 Stream 支持多个消费组

消费组:
1. 每个消费组会有一个游标 last_delivered_id 表示当前已经消费到哪条消息
4. 每个消费组都有一个 Stream 内唯一名称
5. 通过 xgroup create 创建消费者组，需要指定从哪个消息ID开始消费，这个ID用来初始化 last_delivered_id
6. 同一个消费组支持多个消费者

消费者:
1. 消费者之间属于竞争关系
2. 每个消费者在组内唯一
3. 消费者内部会有一个状态变量 pending_ids，记录了被客户端读取，但还没有 ack 的消息。
4. pending_ids 用来确保客户端至少消费了一次消息
5. pending_id是变量被Redis 称为 PEL

#### Stream 操作
消息的增删改查指令如下:
1. xadd: 向Stream 追加消息，提供了一个定长参数 maxlen，超过长度的老消息会被彻底删除
2. xdel: 标记删除
3. xrange: 按范围获取消息，自动过滤已经删除的消息
4. xlen: 获取Stream 消息的长度
5. del: 删除整个 Stream 消息列表中是所有消息
6. xinfo: 获取 stream 信息

```bash
# * 表示自动生成消息ID
> xadd codehole maxlen 3 * name xiaoshuo
```

消费组指令:
1. xgroup read: 创建消费组
2. xreadgroup: 
    - 消费者组的组内消费
    - 其实消息ID 一般设置为 0-0，表示读取所有 PEL 消息以及自 last_delivered_id 之后的新消息
3. xack: 确认消息

```bash
>  xgroup create codehole cg1 0-0
> xreadgroup GROUP cg2 c1 count 1 stream codehole
> xack codehole cg1 ID1 ID2
```

#### 独立消费者
使用 xread 可以定义独立消费者，在没有消费组的情况下直接读取Stream 中的消息。独立消费者将Stream 当做消息队列 list 来使用，设置可以在没有消息时阻塞等待。

客户端使用 xread 顺序消费是一定要保存 xread 返回的消息ID，下次调用时需要将此 ID 当做 xread 参数传入以便继续消费后面的消息。

```bash
# 从头部读取消息
> xread count 1 stream code 0-0 
# 从尾部读取消息，只接受新消息
> xread count 1 stream code $
# 阻塞读取
> xread block 0 count 1 stream code $ 
```

#### 分区
Redis 不支持消息分区，只能在客户端通过生产和消费多个 Stream 来手动分区。

## 2. Info 指令
在诊断 Redis 性能问题之前，需要了解 Redis 的运行状态，通过强大的 info 指令，可以查看 Redis 内部一系列的运行参数。info 的输出分为 9 大块:
1. Server: 服务器运行的环境参数
2. Clients: 客户端相关信息
3. Memory: 服务器运行内存统计数据
4. Persistence: 持久化信息
5. Stats: 通用统计数据
6. Replication: 主从复制相关信息
7. CPU: CPU 使用情况
8. Cluster: 集群信息
9. KeySpace: 键值对统计数量信息

info 可一次获取所有信息，也可分块获取。

## 3. 分布式锁
### 3.1 Redis 分布式锁的实现
用 redis 实现的分布式锁有如下几个要点:
1. 本质上就是在 redis 占一个"坑"，一般使用 setnx(set if not exists)，抢占成功即加锁成功，用完了在调用 del 指令删除键即释放锁
2. 为了避免因**del 删除指令**未被执行而导致的死锁，需要给锁加一个过期时间
3. 由于 setnx + expire 也不是原子的，因此加锁需要 set 指令的扩展  
4. 如果加锁和释放锁之间的逻辑执行太长，以至于超过锁的超时限制，就很好有可能出现并发问题，因此 Redis 分布式锁不适合较长时间的任务
5. 通过占位实现锁，可能会被未占用锁的进程误删除，稍微安全的做法是，将 set 指令的 value 设置为一个随机数，相当于版本号，释放锁时先验证，然后再删除 key。但是匹配 value 和 删除 key 不是一个原子操作，这里就需要 Lua 脚本处理了，因为 Lua 脚本可以保证连续多个指令的原子性执行(我觉得这里不能说是原子执行，只能说严格串行执行)

```bash
# 1. 可能死锁
> setnx lock:codehole true
> del lock:codehole

# 2. 异常完全有可能在 setnx 和 expire 之间发生 
> setnx lock:codehole true
> expire lock:codehole 5
> del lock:codehole

# 3. 正确的实现，创建和设置超时是一个原子操作
> set lock:codehole true ex 5 nx
> del lock:codehole
```

Redis 分布式锁如果要支持可重入，需要对客户端的 set 方法进行包装，使用线程的 Threadlocal 变量存储当前持有锁的计数。是否需要可重入依赖于业务逻辑，这里不再详述。


#### 锁冲突的处理
客户端加锁失败，一般有以下 3 中策略来处理:
1. 直接抛出异常: 比较适合客户端直接发送的请求
2. sleep: 阻塞并重试
3. 延时队列: 将当前冲突的请求放到消息队列中，稍后在重试，比较适合异步消息处理。


### 3.2 Redis 中的乐观锁
分布式锁是一种悲观锁， Redis 通过另一种机制 watch 提供了乐观锁，使用方式如下:

```bash
> watch books
> multi
> incr books
> exec
```

1. watch 会在事务开始之前监测一个或多个关键变量
2. 事务执行时，即开始顺序执行事务队列中的命令时，Redis 会先检查关键变量自 watch 以来是否被修改，包括当前事务所在的客户端
3. 如果关键变量被修改，exec 指令返回 NULL，表示事务执行失败
4. 否则执行事务

注意 watch 之后即便是当前事务所在的客户端对关键变量进行修改(指在 watch 和 multi 之间对关键变量的修改)，事务也会报错，同时Redis 禁止在 multi 和 exec 之间执行 watch 指令。

### 3.3 分布式锁
在集群环境下，主从切换可能会导致锁信息的丢失从而出现问题。为了解决这个问题，Redis 使用了 Redlock 算法。

为了使用 Redlock，需要提供多个 Redis 实例，这些实例之间相互独立，没有主从关系。加锁时客户端向过半节点发送set(key, value, nx=True, err=XXX)，只要过半节点 set 成功，加锁成功。释放锁是向所有节点发送 del 指令，不过Redlock 还需要考虑出错重试，时钟漂移等很多细节问题。


## 4. 惰性删除

## 5. Redis 加密
Redis 中的安全措施

### 5.1 指令安全
Redis 在配置文件中 rename-command 指令，用于将某些危险的指令修改成特别的名称，比如在配置文件的 security 块增加:

```bash
rename-command keys abckeysabc
rename-command flushall "" # 禁用指令
```

### 5.2 端口安全

### 5.3 增加密码访问限制

### 5.4 Lua 脚本安全
必须禁止Lua脚本由用户输入(UGC)生成

### 5.5 使用 spiped SSL 代理
Redis 不支持 SSL 连接，可以用 SSL 代理，官方推荐 spiped。