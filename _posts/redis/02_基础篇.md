---
title: 2. redis 基础篇
date: 2020-05-02
categories:
    - 存储
tags:
    - Kafka
---

Redis 基础篇: Redis 提供的那些数据结构

<!-- more -->

## 1. 基础篇概述
基础篇我们将介绍 Redis 的如下内容:
- Redis 基础数据结构
- 分布式锁的实现
- 延时队列的实现
- 位图
- HyperLogLog: 做不精确统计用的
- 布隆过滤器
- 限流
- GeoHash: 找附近的人
- scan: 字典扫描

## 1. Redis 基础数据结构


## 2. 分布式锁


## 3.延时队列
延时队列需要记录消息的到期处理时间，以便及时对消息进行处理。可以通过 zset 来实现延时队列，将消息序列化成一个字符串作为 zset 的 value，到期事件作为 score。因为使用的是 zset 不是 list，此时需要考虑并发争抢，确保任务不会被多次执行。下面是实现的一个 demon

```bash
def loop():
    while 1:
        values = redis.zrangebyscore("delay-queue", 0, time.time(), start=0, num=1)
        if not values:
            time.sleep(1)
            continue
        value = values[0]
        success = redis.zrem("delay-queue", value)
        if success:
            msg = json.load(value)
            handle_msg(msg)
```

这个示例通过判断 zrem 有没有成功删除消息的方式来判断是否成功抢占任务，来避免多次执行一个任务。那些没有抢到的进程都白取了一次任务，可以考虑使用 lua 脚本来优化这个逻辑，将zrangebyscore 和 zrem 放到服务器端进行原子化操作，这样多个进程抢占任务就不会出现浪费了。


## 4. 位图
### 4.1 位图实现
Redis 中的字符串是动态的字节数组，是可以修改的，所以可以直接把字符串当做 byte 数组来使用。

### 4.2 位图操作
Redis 提供一下指令进行位操作:
1. `setbit/getbit i 0|1` : 设置和读取特定位的值
2. `bitcount k [start, end]`: 统计指定范围内 1 的个数
3. `bitpos k 0|1 [start, end]`: 查找指定范围内出现的第一个 0 或 1
4. `bitfield`: 一次进行多个位操作


注: 
- byte 数组是自动扩展的，如果设置的偏移量超过了现在范围，redis 将自动对位数组进行 0 扩充。
- bitcount/bitpos 的范围参数 [start, end] 是字符索引，[0, 0] 表示第一个字符，即前 8 个位

```bash
# 1. 位设置和读取
> setbit s 1 1
> setbit s 2 1
> setbit s 4 1
> get s          # get 返回的是 bytes 对应的字符
"h"

> set w h        # 整存零取
> getbit w 1
(integer) 1

# 2. 位统计
> set w hello
> bitcount 0 0  # 第一个字符中 1 的个数
> bitpos w 1 1 1    # 从第二字符起，第一 1 的位置
```

#### bitfield
bitfield 有三个子命令，get、set、incrby 可以对指定位片段进行读写，但是最多只能处理 64 个连续的位。如果超过 64 位就要使用多个子命令，bitfield 可以一次执行多个子命令。


```bash
> set w hello
> bitfield w get u4 0   # 从第 1 位开始取 4 位作为无符号整数(u) 返回
> bitfield w get i3 2

> bitfield w set u8 8 97 # 从第 9 位开始将接下来的 8 个位用无符号整数 97 替代

#  incrby 用于执行自增操作
> bitfield w incrby u4 2 1 # 从第 3 位开始，对接下来的 4 位无符号整数 + 1
```
incrby 自增指令可能会导致溢出，bitfield 提供了 overflow 子命令用于选择溢出行为:
1. wrap: 折返，默认值
2. fail：报错不执行
3. sat：饱和截断，停留在最大或最小值。

overflow 只会影响下一个指令，下一个指令执行完成后溢出策略会变成默认的 wrap。

```bash
> set w hellp
> bitfield w overflow sat incrby u4 2 1
> bitfield w overflow fail incrby u4 2 1
```

## 5. HyperLogLog
HyperLogLog 提供不精确的去重计数方案，虽然不精确，但是也不是非常离谱，标准误差 0.81%。

HyperLogLog 需要占据 12KB 的存储空间(无论对多少数据去重，最多占用 12K)，所以不适合统计单个用户的相关数据。Redis 对 HyperLogLog 的存储进行了优化，在计数较小时，它的存储空间采用系数矩阵存储，空间占用很小，仅仅在计数慢慢变大，系数矩阵占用的空间渐渐超过阈值时，才会一次性转变成稠密矩阵。

### 5.1 使用
HyperLogLog 提供了三个指令:
1. pfadd: 增加计数
2. pfcount: 获取计数
3. pfmerge: 将多个 pf 计数值累加在一起

```bash
> pfadd codehole user1
> pfadd codehole user2
> pfcount codehole
2
```

## 5.2 原理
HyperLogLog 的计数利用了这样一个统计规律: 一堆随机数的数量N与随机数中低位连续零位的最大长度K满足这样一个关系: `N=2^K`。

Redis 使用 2^14 个桶，对随机数进行独立计数，每个桶使用 6bit 记录连续零位的最大长度。使用这些桶计算N并求平均值。所以一个 HyperLogLog 需要占用: `2^14 * 6 / 8=12KB`


## 6. 布隆过滤器
布隆过滤器，类似于不精确的 set 用于元素去重和快速判断元素是否在集合中。使用布隆过滤器空间上能节省 90%，当然过滤就不是特别准确，存在误判。

布隆过滤器判断某个值存在时，值可能不存在，但是判断某个值不存在时，肯定不存在。

### 6.1 使用
Redis 4.0 提供了插件功能之后，布隆过滤器通过插件的方式添加到 Redis 中。布隆过滤器有如下几个命令:
1. bf.add: 添加元素，只能一次添加一个元素
2. bf.madd: 用于一次添加多个元素
2. bf.exists: 查询元素是否存在
3. bf.mexists: 一次判断多个元素是否存在
4. `bf.reserve key error_rate initial_size`:
    - 作用: 自定义布隆过滤器，设置最大错误率，如果 key 已经存在会报错
    - 参数: 
        - error_rate: 最大错误率，越小，需要的空间越大
        - initial_size: 预计放入的元素数量，实际数量超过这个数量时，误判率会上升，所以需要预估一个合理的数值
    - 默认: 
        - error_rate=0.01
        - initial_size=100

```bash
> bf.add codehole user1
> bf.add codehole user2
> bf.exists codehole user1
1
> bf.madd codehole user10 user11 user12
> bf.mexists codehole user4 user5
0
0
```
### 6.2 原理
布隆过滤器就是大型的位数组和几个不一样的无偏 hash 函数。

### 6.3 空间占用估计
布隆过滤器的空间计算，
- 输入有两个参数:
    - n: 预计元素数量
    - f: 错误率
- 输出也有两个元素:
    - L: 位数组的长度
    - k: hash 函数的最佳数量

```bash
k=0.7*(L/n)
f=0.6185^(L/n)
```

在线的布隆计算器参见 https://krisives.github.io/bloom-calculator

### 6.4 实际数量超限事的错误率
实际数量超出预计元素时，错误率的变化参见公式: 

`f=(1-0.5^t)^k`
- f: 错误率
- k: hash 函数的最佳数量
- t: 实际元素数量与预计元素(initial_size) 的倍数

当实际数量超出预计元素时，错误率会随着倍数 t 显著增大。

### 6.5 应用
布隆过滤器在 NoSQL 中使用广泛，当用户查询某个 row 时，可先通过内存中的布隆过滤器过滤掉大量不存在 row 请求，然后再去磁盘进行查询，可以显著降低 IO 请求的数量。

布隆过滤器也长用在爬虫，对大量 URL 进行去重。


## 7 限流
本片文章我们来介绍如何使用 Redis 实现限流算法，包括两种实现方式:
1. 简单限流: 通过 zset 实现
2. 漏斗限流: Redis4.0 提供的限流模块，Redis-Cell

### 7.1 简单限流
使用 zset 结构记录用户的行为历史，每一个行为都会作为 zset 中的一个 key，使用 score 记录时间戳，用于计算滑动时间的窗口，value 为什么值不重要，只要唯一即可，也可使用时间戳。下面是一个实现示例:

```python
client = redis.StrictRedis()

def is_action_allow(user_id, action_key, period, max_count):
    key = 'hit:%s:%s' % (user_id, action_key)
    now_ts = int(time.time() * 1000)
    with client().pipeline() as pipe:
        pip.zadd(key, now_ts, now_ts)
        # 只保留窗口内的记录
        pipe.zremrangebyscore(key, 0, now_ts -  period * 1000)
        pipe.zcard(key)
        # 设置过期时间，避免冷用户持续占用内存
        pip.expire(key, period + 1) 
        _, _, current_count, _ = pipe.execute()
    return current_count < max_count
```

连续的 Redis 操作都是针对同一 key，使用 pipeline 可以显著提高 Redis 存储效率。

这种方案有个缺点，因为它要记录时间窗口内所有的行为记录，如果量很大，比如限定 60s 内不得超过 100万次，就会消耗大量的空间。

### 7.2 漏斗限流
Redis-Cell 提供了 cl.throttle 指令用于执行限流算法，使用示例如下:

```
> cl.throttle user_id:key 15 30 60 1
1) (interger) 0  # 0-允许，1-拒绝
1) (interger) 15 # 漏斗容量
1) (interger) 14 # 漏斗剩余空间
1) (interger) -1 # 如果被拒绝，需要多长时间后再试
1) (interger) 2  # 多长时间漏斗完全空
```

`cl.throttle user_id:key 15 30 60 1`
- 参数:
    - 15: capacity 漏斗的容量
    - 30 60: 每 60s 最多 30 次，漏水速率
    - 1: quota 可选参数默认值为 1


## 8. GeoHash
Redis3.2 增加了地理位置模块 Geo，我们可以实现类似附近的餐馆这样的功能。

### 8.1 附近的人计算方法
如果要计算“附近的人”，也就是给定一个元素的坐标，然后计算这个坐标附近的其他元素，按照距离进行排序，该如何处理？

如果现在元素的经纬度坐标使用关系数据库 （元素 id， 经度 x， 纬度 y） 存储，你该如何计算？

首先，你不可能通过遍历来计算所有的元素和目标元素的距离然后再进行排序，这个计算量太大了，性能指标肯定无法满足。一般的方法都是通过矩形区域来限定元素的数量，然后对区域内的元素进行全量距离计算再排序。这样可以明显减少计算量。如何划分矩形区域呢？可以指定一个半径 r，使用一条 SQL 就可以圈出来。

```bash
select id from position where x0-r < x < x0+r and y0-r < y < y0+r
```

但是数据库查询不适合大并发的场景。

### 8.2 GeoHash
业界比较通用的地理位置距离排序算法是 GeoHash 算法，GeoHash 算法将二维的经纬度数据映射到一维的整数，这样所有的元素都将挂载到一条线上，距离靠近的二维坐标映射到一维后的点之间距离也会很接近。当我们想要计算“附近的人”时，首先将目标位置映射到这条线上，然后在这个一维的线上获取附近的点就行了。

在 Redis 中，经纬度使用 52 位整数值编码，放在 zset 中，value 是元素的 key，score 是 GeoHash 的 52 位整数值。zset 的score 虽然是浮点数，但是对于 52 位整数值可以无损存储。通过 zset 的score 排序就可以得到坐标附近的其他元素。通过 score 可以还原坐标值就可以得到元素的原始坐标。

GeoHash 对二维坐标进行的一维映射时有损的，通过映射还原的值也会出现小的偏差。

### 8.3 Geo指令
Geo 有 6 个指令
1. geoadd: 添加经纬度，值为(经度，维度，元素)的三元组
2. zrem: 删除 Geo 元素(Geo 底层只是一个普通的 zset)
3. geolist：计算两个元素之间的距离，参数是(集合名称，元素A，元素B，距离单位)
4. geopos: 获取集合中任意元素的经纬度坐标，一次可获得多个
5. geohas: 获取元素经纬度编码字符串，base32编码
6. georadiusbymeember: 查询指定元素附近的其他元素
7. genradius: 根据经纬度查询附近的元素，参数与georadiusbymeember相同，只不过把元素换成经纬度

```bash
> geoadd company  116.88888 39.92343 juejin
> geoadd company  126.88888 49.92343 jd
> geoadd company  78.88888 20.92343 abc
> zrem company abc

> geolist company juejin jd km  

> geopos company juejin  jd

> geohash company jd

# 范围 20 公里以内最多 3 个元素按距离正排，不排除自身
> georadiusbymember company jd 20 km count 3 asc
# # 范围 20 公里以内最多 3 个元素按距离倒排
> georadiusbymember company jd 20 km count 3 asc

# withdist: 显示实际距离
# withhash: 显示距离编码信息
# withcoord: 显示经纬度
> georadiusbymember company jd 20 km withcoord withdist withhash count 3 asc

> genradius company 59.223, 46.134 20 km withdist count 3 asc
```

### 8.4 Geo 使用注意事项
如果将所有的地理的位置放在同一个 Geo 结构中，就会导致 zset 集合过大。Redis 集群环境中，集合可能从一个节点迁移到另一节点，如果单个 key 的数据过大，会对集群的迁移工作造成较大的影响，所以集群环境中一个单个 key 对应的数据量不宜超过 1MB，否则会导致集群迁移出现卡顿现象，影响线上服务的正常运行。

所以建议 Geo 的数据使用单独的Redis 实例部署，不使用集群环境。如果数据过大，可以按照省市区进行拆分。


## 9. key 查找
### 9.1 keys 和 scan 命令
Redis 提供了一个简答指令 keys 用于列出所有满足正则匹配的 key。但是 keys 指令有两个明显的缺点:
1. 没有 offset，limit，一次输出满足所有的 key
2. 复杂度 O(n)，如果实例中 key 太多，因为Redis 是单线程程序，就会导致Redis 服务卡顿，所有的读写操作就会被延迟。

Redis 为了解决这个问题，加入了 scan 指令，scan 相比 keys 有如下特点:
1. 复杂度O(n)，但是通过游标分步进行，不会阻塞线程
2. 提供 limit 参数，限制返回的最大条数，注意 limit 限制的是 Redis 遍历的条数不是返回条数
3. 服务器不维护游标状态，当前的位置是通过 scan 返回给客户端的游标整数
4. 返回结果**可能有重复**，需要客户端去重
5. 遍历过程中如有数据被修改，改动后的数据能不能被遍历具有不确定性
6. 单次返回结果为空不代表遍历结果，遍历结束只能通过 scan 返回的游标值判断。

```bash
> keys *
> keys code*

> scan 0  match key* count 1000
1) 8843
2)...

> scan 8843  match key* count 1000
```

scan 是一些列指令，除了 scan 本身还包括
1. zscan: 遍历 zset 集合元素
2. hscan: 遍历 hash 字典中的元素
3. sscan: 遍历 set 集合的元素

### 9.2 scan 原理
redis 中所有 Key 都存储在一个很大的字典中。字典由一位数组和二维链表组成。scan 指令返回的游标就是第一维数组的位置索引(又称槽)，不考虑扩缩容直接按照数组下标进行遍历即可，limit 参数控制的就是需要遍历的槽位数。

scan 的遍历顺序不是从数组 0 索引开始直至结尾，而是采用了**高位进位加法**来遍历。之所以采用这个方法是考虑到字典的扩缩容，避免槽位遍历的重复和遗漏(原因见下)。

### 9.3 Redis Key 扩缩容
Redis 存储所有 Key 的字典，一维数组的大小总是 2^n，扩容一次，空间加倍。因为数组长度总是 2^n 次方，字典哈希过程中对数组长度的取模运算，等价于位与操作:
```bash
a mod 8 == a & (8-1)
a mod 16 == a & (16-1)
```
假设当前的字典的数组长度由 8 扩容到 16，那么 3号槽位将被rehash 到 3号和 11 号槽位。11 的二进制 1011 就是对 3 的二进制 011 增加了一个高位。

所以采用高位进位加法:
1. 遍历顺序，rehash后的槽位在遍历顺序是相邻的
2. 扩容
    - 假设当前要即将遍历110这个位置，扩容后，当前槽位上所有的元素对应的新槽位是0110和1110
    - 此时可以直接从0110这个槽位开始往后继续遍历，0110槽位之前的所有槽位都已经遍历过了
    - 这样可以避免扩容后对已经遍历过的槽位进行重复遍历
3. 缩容
    - 假设当前即将遍历110这个位置，缩容后，当前槽位所有的元素对应的新槽位是10
    - 此时可以直接从10这个槽位开始往后继续遍历，10槽位之前的所有槽位都已经遍历过了，这样能避免缩容的重复遍历
    - 但是这会对010这个槽位上的元素进行重复遍历！！

### 9.4 渐进式 rehash
Redis采用渐进式rehash，需要同时保留旧数组和新数组，然后在定时任务中以及后续对hash的指令操作中渐渐地将旧数组中挂接的元素迁移到新数组上

意味着如果要操作处于rehash中的字典，需要同时访问新旧两个数组结构。
scan处于rehash中的字典，需要同时扫描新旧槽位，然后将结果融合后返回给客户端

### 9.5 大 Key 问题
有时候由于操作不当，会在Redis 生成很大的Key，很大的 Key 会导致:
1. 集群环境中，数据迁移卡顿
2. key 扩容时，一次性申请更大的内存，导致卡顿
3. Key被删除，内存会一次性回收，导致卡顿

在平时的业务开发中，要尽量避免大Key的产生！redis-cli 提供了 `–-bigkeys` 选项用于定位Redis 这个的大 Key。

```bash
# 可能会提升 Redis 的 ops，因为会使用 scan 扫描所有 Key
> redis-cli --bigkeys

# 限制 bigkeys 的扫描频率
# -i 0.1 表示每隔 100 条，scan 就会休眠 0.1s
> redis-cli --bigkeys -i 0.1
```
