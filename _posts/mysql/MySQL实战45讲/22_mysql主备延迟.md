---
title: 16 MySQL 主备延迟
date: 2020-03-16
categories:
    - 存储
tags:
    - 极客时间
    - MySQL实战45讲
---

MySQL 主备延迟与并行复制
<!-- more -->

## 1. 主备延迟
与数据同步有关的时间点主要包括以下三个：
1. 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;
2. 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;
3. 备库 B 执行完成这个事务，我们把这个时刻记为 T3。

所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。在网络正常的时候，日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的。也就是说，网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。

### 1.1 主备延迟的原因
慢的原因有以下几个:
1. 有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。这种部署现在比较少了,因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，是现在比较常见的情况。
2. 备库的压力大,一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。


备库的压力大的情况，我们一般可以这么处理：
1. 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。
2. 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。

其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。

除了上面这些因素，mysql 的下面这些操作也是造成主备延迟的重要因素:
1. 大事务: 因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。
2. 大表 DDL: 另一种典型的大事务，计划内的 DDL，建议使用 gh-ost 方案
3. 备库的并行复制能力

待会我们会详细讲解备库的并行复制能力是怎么影响主备延迟的。除了上面将的主库导致的主从延迟外，备库也可能导致主备延迟，就是备库起了一个长事务，比如

```bash
begin; 
select * from t limit 1;  # 不动了
```

这时候主库对表 t 做了一个加字段操作，即使这个表很小，这个 DDL 在备库应用的时候也会被堵住，从而导致主备延迟线性增长。


## 2. 备库的并行复制
在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。

而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。接下来我们就来看看 mysql 是如何从单线程演化成多线程复制的。

### 2.1 并行复制的原理
![parallel_sql_thread](/images/mysql/MySQL45讲/parallel_sql_thread.png)

多线程复制机制，就是把只有一个线程的 sql_thread，拆成多个线程:
1. coordinator: 就是原来的 sql_thread, 现在只负责读取中转日志和分发事务
2. worker 线程: 更新日志的，个数由参数 slave_parallel_workers 配置，对于32 核物理机，建议设置在 8-16 之间，毕竟备库还有可能要提供读查询，不能把 CPU 都吃光了

需要注意的是事务是不能按照轮询的方式分发给各个 worker 的。因为不同的 worker 就独立执行了。但是，由于 CPU 的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。同理为了满足事务要求，同一个事务的多个更新语句，也不能分给不同的 worker 来执行

coordinator 在分发的时候，需要满足以下这两个基本要求：
1. 不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。
2. 同一个事务不能被拆开，必须放到同一个 worker 中。

### 2.2 并行复制策略
#### 按表分发:
按表分发的基本操作是这样的:
- 每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。
- 随着每个 worker 的执行，会把已完成事务涉及的表从 hash 表中删除 
- 如果两个事务更新不同的表，它们就可以并行。
- 如果有跨表的事务，还是要把两张表放在一起考虑的
- 如果事务 T 跟多于一个 worker 冲突(worker 的hash 表内有与事务 T 操作相同的表)，coordinator 线程就进入等待，直至只与 1 个worker 进程冲突，并发 T 分配给它

这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。如果碰到热点表，就变成了单线程复制。

### 按行分发
按行复制的核心思路是：
1. 如果两个事务没有更新相同的行，它们在备库上可以并行执行。这要求 binlog 格式必须是 row
2. 判断一个事务 T 和 worker 是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。
3. worker hash 表的 key，就必须是“库名 + 表名 + 唯一键的值”
4. 基于行的策略，事务 hash 表中还需要考虑唯一键(假设唯一索引名为 a)，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。因为唯一索引会引发唯一键错误，必须考虑事务执行顺序

因此假设要在表 t1 上执行 `update t1 set a=1 where id=2` 语句，a 是唯一索引列，原来的值为 2。coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项:
1. `key=hash_func(db1+t1+“PRIMARY”+2), value=2`; 这里 value=2 是因为修改前后的行 id 值不变，出现了两次。
2. `key=hash_func(db1+t1+“a”+2), value=1`，表示会影响到这个表 a=2 的行。
3. `key=hash_func(db1+t1+“a”+1), value=1`，表示会影响到这个表 a=1 的行。

如果是要操作很多行的大事务的话，按行分发的策略有两个问题：
1. 耗费内存
2. 耗费 CPU

因此需要为单个事务设置行数阈值，比如，如果单个事务更新的行数超过 10 万行，就暂时退化为单线程模式，退化过程的逻辑大概是这样的：
1. coordinator 暂时先 hold 住这个事务；
2. 等待所有 worker 都执行完成，变成空队列；
3. coordinator 直接执行这个事务；
4. 恢复并行模式。

### 分发策略的约束
相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。你可能也发现了，这两个方案其实都有一些约束条件：
1. 要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；
2. 表必须有主键；
3. 不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。


### 2.3 MySQL 5.6 版本的并行复制策略
只是支持的粒度是按库并行:
1. hash 表里，key 就是数据库名，库的数量相对于表和行少的多，因此也不会耗费什么内存和 CPU
2. 并行效果，取决于压力模型。如果在主库上有多个 DB，并且压力均衡，使用这个策略的效果会很好
3. 不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。

### 2.4 MariaDB 的并行复制策略
MariaDB 的并行复制 利用了 redo log 组提交 (group commit) 优化:
1. 能够在同一组里提交的事务，一定不会修改同一行；
2. 主库上可以并行执行的事务，备库上也一定是可以并行执行的。

在实现上，MariaDB 是这么做的：
1. 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；
2. commit_id 直接写到 binlog 里面；
3. 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；
4. 这一组全部执行完成后，coordinator 再去取下一批。

是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。另外，这个方案很容易被大事务拖后腿。

### 2.4 MySQL 5.7 的并行复制策略
由参数 slave-parallel-type 来控制并行复制策略：
1. 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；
2. 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。

这里面的思考逻辑是这样的:
1. 同时处于“执行状态”的所有事务，不是可以并行的，因为这里面包括了由于锁冲突而处于锁等待状态的事务，他们必须严格按照顺序执行
2. MariaDB 优化策略的核心，是“所有处于 commit”状态的事务可以并行。事务处于 commit 状态，表示已经通过了锁冲突的检验了
3. 根据两阶段提交，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了

MySQL 5.7 并行复制策略的思想是：
1. 同时处于 prepare 状态的事务，在备库执行时是可以并行的；
2. 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。

binlog 的组提交的时候，介绍过两个参数：
1. binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。

这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在 MySQL 5.7 处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。

### 2.5 MySQL 5.7.22 的并行复制策略
MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。它有三个值:
1. COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。
2. WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。
3. WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。

WRITESET 就是我们前面介绍的基于行的并行复制，不过，MySQL 官方的这个实现还是有很大的优势：
1. writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；
2. 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；
3. 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。

当然，对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。

官方 MySQL5.7 版本新增的备库并行策略，修改了 binlog 的内容，也就是说 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要把这个因素也考虑进去。

### 2.6 大事务的影响
大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一