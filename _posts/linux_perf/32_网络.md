---
title: 4.13 网络
date: 2020-01-28
categories:
    - 运维
tags:
    - Linux性能调优
---
本节我们讲解网络相关的操作系统原理。网络分析的目的除了改进网络延时和吞吐量外，另一个常见的任务是消除可能由丢包引起的延时异常。网络分析是跨硬件和软件的。硬件指的是物理网络包括网络接口卡，交换机，路由器和网管。软件指的是内核协议栈。
<!-- more -->

## 1. 网络
本节我们将从以下几个方面介绍网络相关的操作系统原理:
1. 网络协议栈
2. TCP 连接状态转移
3. TCP 拥塞控制
4. 操作系统的网络栈

最后我们会介绍网络相关的检测指标。想对网络深入了解，推荐大家阅读:
1. [CCNA学习指南](https://book.douban.com/subject/2968802/)
2. [TCP/IP详解 卷1：协议](https://book.douban.com/subject/1088054/)

## 1. 网络协议栈
网络的五层和七层模型想必大家都听过，下面是这两个协议栈模型的示意图:

![network_model](/images/linux_pf/network_model.png)

数据经过网络协议栈时，通过包封装将每层协议的元数据添加到负载前(包头)，之后(包后)，或者二者，但不会修改负载数据。下面展示了以太网 TCP/IP 的栈封装过程:

![tcp_encapsulation](/images/linux_pf/tcp_encapsulation.png)

数据就是这样经过封装，并通过路由器等网络设备在网络上进行传播，并最后被目标主机接收和解析。

![network_trans](/images/linux_pf/network_trans.png)

## 2. TCP 状态转移
[TCP 状态转移](http://www.pianshen.com/article/9701265948/)


### 2.1 长连接和短连接
长连接和短连接除了关闭连接的时机，更重要的是长连接需要有一个保活机制。

## 3. TCP 拥塞控制
TCP 的滑动窗口，拥塞控制可以看这篇文章[图解TCP 重传、滑动窗口、流量控制、拥塞控制发愁](https://www.cnblogs.com/xiaolincoding/p/12732052.html)，图文并茂很容易理解。

## 4. 操作系统的网络栈
网络通信软件包括网络栈、TCP和设备驱动程序。下面是一个通用的网络栈模型。

![network_stack](/images/linux_pf/network_stack.png)
- ARP: 地址解析协议
- Data Link(generic net driver): 数据链路，通用网络驱动软件

### 4.1 Linux
Linux 中 TCP，IP以及通用网络驱动软件是内核的核心组件，设备驱动程序是附加模块，数据包以 struct_sk_buff 数据类型穿过这些内核组件。通用驱动程序能通过合并中断提高性能。

数据包的高处理器率通过调用多个 CPU 处理包和 TCP/IP 栈。Linux3.7 记录了如下不同的方法:
1. RSS，接收端缩放: 现代 NIC 支持多个队列并且计算包哈希以放置不同的队列，而后依次按直接中断由不同的 CPU 处理。这个哈希值可能基于 IP和TCP 端口，因此源自同一连接的包能被同一个 CPU 处理。
2. RPS，接收数据包转向: 对于不支持多队列的NIC的RSS关键实现。一个短中断服务例行程序映射传入的数据包给 CPU 处理，用一个类似的哈希按数据包头的字段映射数据包到 CPU
3. RFS，接收流转向: 类似 RPS，不过偏向前一个处理套接字的CPU，以提高CPU缓存命中率和内存本地性
4. 加速接收数据流转向: 对于支持该功能的NIC，这是 RFS 的硬件实现。它用流信息更新NIC以确定中断哪个CPU
5. XPS，传输数据包转向: 对于支持多个传输队列的NIC，这支持多个 CPU传输队列

当缺乏数据包的CPU负载均衡时，NIC会中断同一个CPU，进而达到100% 的使用率并成为瓶颈。

基于例如RFS 实现的缓存一致性等因素而映射中断到多个 CPU，能显著提升网络性能。这样能通过 irqbalancer 进程实现，它能分配中断请求 IRQ 给 CPU。

注:NIC 是网络接口卡的简称

### 4.2 积压队列和缓冲
#### 积压队列
突发的链接由积压队列处理。这里有两个队列:
1. 一个在TCP 握手完成前处理未完成的连接，又称为SYN积压队列
2. 另一个处理等待应用程序接受的已建立的会话，又称为侦听积压队列

![backlog_queues](/images/linux_pf/backlog_queues.png)

有两个队列的情况下第一个可作为潜在的伪造连接的集结地，仅在连接建立后才迁移到第二个队列，此队列可以设置的很长以吸收海量 SYN，并且优化为仅存放最少的必要元数据
第二个队列可由应用程序 listent() 的积压队列参数设置。

#### 缓冲
利用套接字的发送和接收缓冲能够提升数据的吞吐量:

![socket_buffer](/images/linux_pf/socket_buffer.png)

对于写通道，数据缓冲在 TCP发送缓冲区，然后送往IP发送。尽管IP协议有能力分段数据包，TCP仍试图发送 MSS 长度的段给IP以避免这种情况。这意味重发送单位对应分段的单位，否则一个被丢弃的数据段会导致整个分段前的数据包被重新传输。由于避免了分段和组装常规数据包，这种实现方式提升了 TCP/IP 栈的效率。

缓冲区的大小是可调整的。Linux 会基于连接的活跃度自动调节缓冲区大小。

#### 网络设备驱动
网络设备驱动通常还有一个附加的缓冲区(环形缓冲区)用于在内核内存与NIC间发送和接收数据包。

随着10GbE以太网网的引入，利用**中断结合模式**的利于性能的功能愈发常见。一个中断仅仅在计时器激活或者达到一定数据量的包时才被发送，而不是每当有数据包达到就中断内核。这降低了内核与 NIC 通信的频率。允许缓冲更多的发送，从而达到更高的吞吐量。


## 网络监测
下面是网络常用的性能测量指标:
1. 延时
2. 使用率
3. 饱和度


### 延时
延时是一个重要的网络性能指标，并且有多种测量方法，包括:
1. 主机名解析延时
2. ping 延时
3. 连接延时
4. 首字节延时
5. 往返延时

### 使用率
网络连接口的使用率可以用当前的吞吐量除以最大带宽来计算。但是考虑到可变的带宽和自动协商的双工模式，计算不像看上去那么简单。对于全双工，使用率适合每个方向且用该方向当前的吞吐量除以当前协商的带宽来计算。

### 饱和度
测量连接积压队列导致的丢包是一种衡量网络连接饱和度的方法